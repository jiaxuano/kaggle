{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'project-group-6/train.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>loc</th>\n",
       "      <th>features</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>selltype</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.000 €</td>\n",
       "      <td>Piso Tallers. Piso con 2 habitaciones con asce...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>[85 m2, 2 hab., 1 baño, 3.647 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.000 €</td>\n",
       "      <td>Piso C/ de valència. Piso reformado en venta d...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>[65 m2, 2 hab., 1 baño, 5.000 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.000 €</td>\n",
       "      <td>Piso en Dreta de l´Eixample. Acogedor piso al ...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>[77 m2, 2 hab., 1 baño, 4.286 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.000 €</td>\n",
       "      <td>Piso Barcelona - corts catalanes. Soleado, cén...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>[96 m2, 3 hab., 2 baños, 4.531 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.000 €</td>\n",
       "      <td>Piso en Carrer de sardenya 271. Alto, reformad...</td>\n",
       "      <td>Barcelona - Sagrada Família</td>\n",
       "      <td>Carrer de Sardenya 271</td>\n",
       "      <td>[84 m2, 2 hab., 1 baño, 4.881 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price                                              title  \\\n",
       "0  320.000 €  Piso Tallers. Piso con 2 habitaciones con asce...   \n",
       "1  335.000 €  Piso C/ de valència. Piso reformado en venta d...   \n",
       "2  330.000 €  Piso en Dreta de l´Eixample. Acogedor piso al ...   \n",
       "3  435.000 €  Piso Barcelona - corts catalanes. Soleado, cén...   \n",
       "4  410.000 €  Piso en Carrer de sardenya 271. Alto, reformad...   \n",
       "\n",
       "                        loc_string                     loc  \\\n",
       "0          Barcelona - Sant Antoni                    None   \n",
       "1  Barcelona - Dreta de l´Eixample                    None   \n",
       "2  Barcelona - Dreta de l´Eixample                    None   \n",
       "3          Barcelona - Sant Antoni                    None   \n",
       "4      Barcelona - Sagrada Família  Carrer de Sardenya 271   \n",
       "\n",
       "                               features  type subtype     selltype  \\\n",
       "0   [85 m2, 2 hab., 1 baño, 3.647 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "1   [65 m2, 2 hab., 1 baño, 5.000 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "2   [77 m2, 2 hab., 1 baño, 4.286 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "3  [96 m2, 3 hab., 2 baños, 4.531 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "4   [84 m2, 2 hab., 1 baño, 4.881 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "\n",
       "                                                desc  \n",
       "0  Piso en última planta a reformar en calle Tall...  \n",
       "1  Ubicado en la zona del Camp de l’Arpa, cerca d...  \n",
       "2  En pleno centro de Barcelona, justo al lado de...  \n",
       "3  Vivienda espaciosa en Sant Antoni, cerca de Pl...  \n",
       "4  En el corazón de Barcelona, en una hermosa fin...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    training_data = pickle.load(file)\n",
    "training_data = pd.DataFrame(training_data)\n",
    "training_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>loc</th>\n",
       "      <th>features</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>selltype</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00 €</td>\n",
       "      <td>Piso Carrer de llull. Piso con 4 habitaciones ...</td>\n",
       "      <td>Barcelona - El Parc i la Llacuna del Poblenou</td>\n",
       "      <td>None</td>\n",
       "      <td>[87 m2, 4 hab., 1 baño]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Contactar con Camila 7. 3.\\n\\nLa Casa Agency E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00 €</td>\n",
       "      <td>Piso Diagonal. Luminoso piso de 4 habitaciones...</td>\n",
       "      <td>Barcelona - Poblenou</td>\n",
       "      <td>None</td>\n",
       "      <td>[78 m2, 4 hab., 1 baño]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>¡Un gran piso a reformar es una gran oportunid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00 €</td>\n",
       "      <td>Piso Carrer del consell de cent. Piso amueblad...</td>\n",
       "      <td>Barcelona - L´Antiga Esquerra de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>[65 m2, 1 hab., 1 baño]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>AUREA INMOBILIARIA PRESENTA, ACOGEDOR APARTAME...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00 €</td>\n",
       "      <td>Piso Castanys. Carrer castanys</td>\n",
       "      <td>Barcelona - Poblenou</td>\n",
       "      <td>None</td>\n",
       "      <td>[88 m2, 3 hab., 1 baño]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Piso en pleno centro de Poblenou, techos altos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00 €</td>\n",
       "      <td>Piso Carrer de casanova. Piso con 2 habitacion...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>[82 m2, 2 hab., 1 baño]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Punt Zona Franca presenta esta fantástica vivi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    price                                              title  \\\n",
       "0  0.00 €  Piso Carrer de llull. Piso con 4 habitaciones ...   \n",
       "1  0.00 €  Piso Diagonal. Luminoso piso de 4 habitaciones...   \n",
       "2  0.00 €  Piso Carrer del consell de cent. Piso amueblad...   \n",
       "3  0.00 €                     Piso Castanys. Carrer castanys   \n",
       "4  0.00 €  Piso Carrer de casanova. Piso con 2 habitacion...   \n",
       "\n",
       "                                      loc_string   loc  \\\n",
       "0  Barcelona - El Parc i la Llacuna del Poblenou  None   \n",
       "1                           Barcelona - Poblenou  None   \n",
       "2    Barcelona - L´Antiga Esquerra de l´Eixample  None   \n",
       "3                           Barcelona - Poblenou  None   \n",
       "4                        Barcelona - Sant Antoni  None   \n",
       "\n",
       "                  features  type subtype     selltype  \\\n",
       "0  [87 m2, 4 hab., 1 baño]  FLAT    FLAT  SECOND_HAND   \n",
       "1  [78 m2, 4 hab., 1 baño]  FLAT    FLAT  SECOND_HAND   \n",
       "2  [65 m2, 1 hab., 1 baño]  FLAT    FLAT  SECOND_HAND   \n",
       "3  [88 m2, 3 hab., 1 baño]  FLAT    FLAT  SECOND_HAND   \n",
       "4  [82 m2, 2 hab., 1 baño]  FLAT    FLAT  SECOND_HAND   \n",
       "\n",
       "                                                desc  \n",
       "0  Contactar con Camila 7. 3.\\n\\nLa Casa Agency E...  \n",
       "1  ¡Un gran piso a reformar es una gran oportunid...  \n",
       "2  AUREA INMOBILIARIA PRESENTA, ACOGEDOR APARTAME...  \n",
       "3  Piso en pleno centro de Poblenou, techos altos...  \n",
       "4  Punt Zona Franca presenta esta fantástica vivi...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pickle_file_path = 'project-group-6/test_kaggle.pickle'\n",
    "\n",
    "with open(test_pickle_file_path, 'rb') as file:\n",
    "    test_data = pickle.load(file)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "# test_data['price'] = \"0.00 €\"\n",
    "test_data.insert(0, 'price', \"0.00 €\")\n",
    "test_data = test_data.drop(columns=['id', 'description'])\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.concat([training_data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FLAT', 'STUDIO', 'GROUND_FLOOR', 'PENTHOUSE', 'APARTMENT', 'LOFT',\n",
       "       'DUPLEX'], dtype=object)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SECOND_HAND'], dtype=object)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data['selltype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(training_data['type'])\n",
    "training_data\n",
    "training_data_with_dummies = pd.concat([training_data, dummies], axis=1)\n",
    "training_data_with_dummies.drop('type', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = training_data_with_dummies['features'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['85 m2', '2 hab.', '1 baño', '3.647 €/m2']\n"
     ]
    }
   ],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>loc</th>\n",
       "      <th>features</th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>selltype</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.000 €</td>\n",
       "      <td>Piso Tallers. Piso con 2 habitaciones con asce...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>[85 m2, 2 hab., 1 baño, 3.647 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.000 €</td>\n",
       "      <td>Piso C/ de valència. Piso reformado en venta d...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>[65 m2, 2 hab., 1 baño, 5.000 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.000 €</td>\n",
       "      <td>Piso en Dreta de l´Eixample. Acogedor piso al ...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>[77 m2, 2 hab., 1 baño, 4.286 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.000 €</td>\n",
       "      <td>Piso Barcelona - corts catalanes. Soleado, cén...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>[96 m2, 3 hab., 2 baños, 4.531 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.000 €</td>\n",
       "      <td>Piso en Carrer de sardenya 271. Alto, reformad...</td>\n",
       "      <td>Barcelona - Sagrada Família</td>\n",
       "      <td>Carrer de Sardenya 271</td>\n",
       "      <td>[84 m2, 2 hab., 1 baño, 4.881 €/m2]</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>SECOND_HAND</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price                                              title  \\\n",
       "0  320.000 €  Piso Tallers. Piso con 2 habitaciones con asce...   \n",
       "1  335.000 €  Piso C/ de valència. Piso reformado en venta d...   \n",
       "2  330.000 €  Piso en Dreta de l´Eixample. Acogedor piso al ...   \n",
       "3  435.000 €  Piso Barcelona - corts catalanes. Soleado, cén...   \n",
       "4  410.000 €  Piso en Carrer de sardenya 271. Alto, reformad...   \n",
       "\n",
       "                        loc_string                     loc  \\\n",
       "0          Barcelona - Sant Antoni                    None   \n",
       "1  Barcelona - Dreta de l´Eixample                    None   \n",
       "2  Barcelona - Dreta de l´Eixample                    None   \n",
       "3          Barcelona - Sant Antoni                    None   \n",
       "4      Barcelona - Sagrada Família  Carrer de Sardenya 271   \n",
       "\n",
       "                               features  type subtype     selltype  \\\n",
       "0   [85 m2, 2 hab., 1 baño, 3.647 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "1   [65 m2, 2 hab., 1 baño, 5.000 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "2   [77 m2, 2 hab., 1 baño, 4.286 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "3  [96 m2, 3 hab., 2 baños, 4.531 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "4   [84 m2, 2 hab., 1 baño, 4.881 €/m2]  FLAT    FLAT  SECOND_HAND   \n",
       "\n",
       "                                                desc  \n",
       "0  Piso en última planta a reformar en calle Tall...  \n",
       "1  Ubicado en la zona del Camp de l’Arpa, cerca d...  \n",
       "2  En pleno centro de Barcelona, justo al lado de...  \n",
       "3  Vivienda espaciosa en Sant Antoni, cerca de Pl...  \n",
       "4  En el corazón de Barcelona, en una hermosa fin...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_features(lst):\n",
    "    # Initialize all variables with NaN to handle missing values\n",
    "    square_m = hab = bano = np.nan\n",
    "    \n",
    "    # Process each element in the list if it exists\n",
    "    if len(lst) > 0 and lst[0]:\n",
    "        square_m, _ = lst[0].split(' ')\n",
    "        square_m = float(square_m)\n",
    "    \n",
    "    if len(lst) > 1 and lst[1]:\n",
    "        hab, _ = lst[1].split(' ')\n",
    "        hab = float(hab)\n",
    "    \n",
    "    if len(lst) > 2 and lst[2]:\n",
    "        # Check if 'bano' information is available or it's the price per square meter\n",
    "        if 'baño' in lst[2]:\n",
    "            bano, _ = lst[2].split(' ')\n",
    "            bano = float(bano)\n",
    "        # else:\n",
    "        #     # If 'baño' is not in the string, it might be the price info in the 'bano' slot\n",
    "        #     price_per_s_m, _ = lst[2].split(' ')\n",
    "        #     price_per_s_m = float(price_per_s_m)\n",
    "    \n",
    "    # if len(lst) > 3 and lst[3]:\n",
    "    #     price_per_s_m, _ = lst[3].split(' ')\n",
    "    #     price_per_s_m = float(price_per_s_m)\n",
    "    \n",
    "    return square_m, hab, bano\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_euros(element):\n",
    "    price, _ = element.split(' ')\n",
    "    return float(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_m, hab, bano = clean_features(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "square_m_list , hab_list, bano_list, price_list= [], [], [], []\n",
    "for index, row in enumerate(training_data_with_dummies['features']):\n",
    "    square_m , hab, bano =clean_features(row)\n",
    "    square_m_list.append(square_m)\n",
    "    hab_list.append(hab)\n",
    "    bano_list.append(bano)\n",
    "    # price_per_s_m_list.append(price_per_s_m)\n",
    "for row in training_data_with_dummies['price']:\n",
    "    price = fix_euros(row)\n",
    "    price_list.append(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>loc</th>\n",
       "      <th>subtype</th>\n",
       "      <th>desc</th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>square_m</th>\n",
       "      <th>hab</th>\n",
       "      <th>bano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.0</td>\n",
       "      <td>Piso Tallers. Piso con 2 habitaciones con asce...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>Piso C/ de valència. Piso reformado en venta d...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>Piso en Dreta de l´Eixample. Acogedor piso al ...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>None</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>Piso Barcelona - corts catalanes. Soleado, cén...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>None</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>Piso en Carrer de sardenya 271. Alto, reformad...</td>\n",
       "      <td>Barcelona - Sagrada Família</td>\n",
       "      <td>Carrer de Sardenya 271</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                              title  \\\n",
       "0  320.0  Piso Tallers. Piso con 2 habitaciones con asce...   \n",
       "1  335.0  Piso C/ de valència. Piso reformado en venta d...   \n",
       "2  330.0  Piso en Dreta de l´Eixample. Acogedor piso al ...   \n",
       "3  435.0  Piso Barcelona - corts catalanes. Soleado, cén...   \n",
       "4  410.0  Piso en Carrer de sardenya 271. Alto, reformad...   \n",
       "\n",
       "                        loc_string                     loc subtype  \\\n",
       "0          Barcelona - Sant Antoni                    None    FLAT   \n",
       "1  Barcelona - Dreta de l´Eixample                    None    FLAT   \n",
       "2  Barcelona - Dreta de l´Eixample                    None    FLAT   \n",
       "3          Barcelona - Sant Antoni                    None    FLAT   \n",
       "4      Barcelona - Sagrada Família  Carrer de Sardenya 271    FLAT   \n",
       "\n",
       "                                                desc  APARTMENT  DUPLEX  FLAT  \\\n",
       "0  Piso en última planta a reformar en calle Tall...          0       0     1   \n",
       "1  Ubicado en la zona del Camp de l’Arpa, cerca d...          0       0     1   \n",
       "2  En pleno centro de Barcelona, justo al lado de...          0       0     1   \n",
       "3  Vivienda espaciosa en Sant Antoni, cerca de Pl...          0       0     1   \n",
       "4  En el corazón de Barcelona, en una hermosa fin...          0       0     1   \n",
       "\n",
       "   GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  square_m  hab  bano  \n",
       "0             0     0          0       0      85.0  2.0   1.0  \n",
       "1             0     0          0       0      65.0  2.0   1.0  \n",
       "2             0     0          0       0      77.0  2.0   1.0  \n",
       "3             0     0          0       0      96.0  3.0   2.0  \n",
       "4             0     0          0       0      84.0  2.0   1.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_with_dummies['price'] = price_list\n",
    "training_data_with_dummies['square_m'] = square_m_list\n",
    "training_data_with_dummies['hab'] = hab_list\n",
    "training_data_with_dummies['bano'] = bano_list\n",
    "# training_data_with_dummies['price_per_sm'] = price_per_s_m_list\n",
    "training_data_with_dummies.drop('features', axis=1, inplace=True)\n",
    "training_data_with_dummies.drop('selltype', axis=1, inplace=True)\n",
    "\n",
    "training_data_with_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def citys_neighbhoods(text):\n",
    "#     sliced = text.split(' - ') \n",
    "#     city = [sliced[0]]\n",
    "#     neighborhoods = sliced[1]\n",
    "#     return city, neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# city_list, neighborhoods_list = [], []\n",
    "# for i , row in enumerate(training_data_with_dummies['loc_string']):\n",
    "#     city, neighborhoods, = citys_neighbhoods(row)\n",
    "#     city_list.append(city)\n",
    "#     neighborhoods_list.append(neighborhoods)\n",
    "# df['city'] = pd.DataFrame(city_list)\n",
    "# df['neighborhood'] = neighborhoods_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['City_encoded'] = df['city'].astype('category').cat.codes\n",
    "# df['Neighborhood_encoded'] = df['neighborhood'].astype('category').cat.codes\n",
    "# training_data_with_dummies['City_encoded'] = df['City_encoded'] \n",
    "# training_data_with_dummies['Neighborhood_encoded'] = df['Neighborhood_encoded']\n",
    "# train_set = pd.get_dummies(training_data_with_dummies, columns=['City_encoded', 'Neighborhood_encoded'])\n",
    "# train_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 16)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_set.drop('loc_string', axis=1, inplace=True)\n",
    "# train_set.drop('title', axis=1, inplace=True)\n",
    "# train_set.drop('loc', axis=1, inplace=True)\n",
    "# train_set.drop('desc', axis=1, inplace=True)\n",
    "# train_set.drop('subtype', axis=1, inplace=True)\n",
    "train_set = training_data_with_dummies\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 998 entries, 0 to 997\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   price         998 non-null    float64\n",
      " 1   title         998 non-null    object \n",
      " 2   loc_string    998 non-null    object \n",
      " 3   loc           103 non-null    object \n",
      " 4   subtype       998 non-null    object \n",
      " 5   desc          998 non-null    object \n",
      " 6   APARTMENT     998 non-null    uint8  \n",
      " 7   DUPLEX        998 non-null    uint8  \n",
      " 8   FLAT          998 non-null    uint8  \n",
      " 9   GROUND_FLOOR  998 non-null    uint8  \n",
      " 10  LOFT          998 non-null    uint8  \n",
      " 11  PENTHOUSE     998 non-null    uint8  \n",
      " 12  STUDIO        998 non-null    uint8  \n",
      " 13  square_m      998 non-null    float64\n",
      " 14  hab           998 non-null    float64\n",
      " 15  bano          988 non-null    float64\n",
      "dtypes: float64(4), object(5), uint8(7)\n",
      "memory usage: 77.1+ KB\n"
     ]
    }
   ],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 16)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_set\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'title', 'loc_string', 'loc', 'subtype', 'desc', 'APARTMENT',\n",
       "       'DUPLEX', 'FLAT', 'GROUND_FLOOR', 'LOFT', 'PENTHOUSE', 'STUDIO',\n",
       "       'square_m', 'hab', 'bano'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2., nan,  3.,  4.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['bano'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loc', 'bano']\n"
     ]
    }
   ],
   "source": [
    "columns_with_nan = df.columns[df.isna().any()].tolist()\n",
    "print(columns_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in \"banos\": 10\n"
     ]
    }
   ],
   "source": [
    "nan_count_banos = df['bano'].isna().sum()\n",
    "print(f'Number of NaN values in \"banos\": {nan_count_banos}')\n",
    "df['bano'] = df['bano'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 15)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 15)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subtype'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>loc_string</th>\n",
       "      <th>subtype</th>\n",
       "      <th>desc</th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>square_m</th>\n",
       "      <th>hab</th>\n",
       "      <th>bano</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.0</td>\n",
       "      <td>Piso Tallers. Piso con 2 habitaciones con asce...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>Piso C/ de valència. Piso reformado en venta d...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>Piso en Dreta de l´Eixample. Acogedor piso al ...</td>\n",
       "      <td>Barcelona - Dreta de l´Eixample</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>Piso Barcelona - corts catalanes. Soleado, cén...</td>\n",
       "      <td>Barcelona - Sant Antoni</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>Piso en Carrer de sardenya 271. Alto, reformad...</td>\n",
       "      <td>Barcelona - Sagrada Família</td>\n",
       "      <td>FLAT</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price                                              title  \\\n",
       "0  320.0  Piso Tallers. Piso con 2 habitaciones con asce...   \n",
       "1  335.0  Piso C/ de valència. Piso reformado en venta d...   \n",
       "2  330.0  Piso en Dreta de l´Eixample. Acogedor piso al ...   \n",
       "3  435.0  Piso Barcelona - corts catalanes. Soleado, cén...   \n",
       "4  410.0  Piso en Carrer de sardenya 271. Alto, reformad...   \n",
       "\n",
       "                        loc_string subtype  \\\n",
       "0          Barcelona - Sant Antoni    FLAT   \n",
       "1  Barcelona - Dreta de l´Eixample    FLAT   \n",
       "2  Barcelona - Dreta de l´Eixample    FLAT   \n",
       "3          Barcelona - Sant Antoni    FLAT   \n",
       "4      Barcelona - Sagrada Família    FLAT   \n",
       "\n",
       "                                                desc  APARTMENT  DUPLEX  FLAT  \\\n",
       "0  Piso en última planta a reformar en calle Tall...          0       0     1   \n",
       "1  Ubicado en la zona del Camp de l’Arpa, cerca d...          0       0     1   \n",
       "2  En pleno centro de Barcelona, justo al lado de...          0       0     1   \n",
       "3  Vivienda espaciosa en Sant Antoni, cerca de Pl...          0       0     1   \n",
       "4  En el corazón de Barcelona, en una hermosa fin...          0       0     1   \n",
       "\n",
       "   GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  square_m  hab  bano  \n",
       "0             0     0          0       0      85.0  2.0   1.0  \n",
       "1             0     0          0       0      65.0  2.0   1.0  \n",
       "2             0     0          0       0      77.0  2.0   1.0  \n",
       "3             0     0          0       0      96.0  3.0   2.0  \n",
       "4             0     0          0       0      84.0  2.0   1.0  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FLAT', 'STUDIO', 'GROUND_FLOOR', 'PENTHOUSE', 'APARTMENT', 'LOFT',\n",
       "       'DUPLEX'], dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['subtype'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Barcelona - Sant Antoni', 'Barcelona - Dreta de l´Eixample',\n",
       "       'Barcelona - Sagrada Família', 'Barcelona - Fort Pienc',\n",
       "       'Barcelona - L´Antiga Esquerra de l´Eixample',\n",
       "       'Barcelona - La Nova Esquerra de l´Eixample',\n",
       "       'Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa',\n",
       "       'Barcelona - Dreta de l´Eixample\\nVer mapa',\n",
       "       'Barcelona - Poblenou',\n",
       "       'Barcelona - El Parc i la Llacuna del Poblenou',\n",
       "       'Barcelona - La Vila Olímpica del Poblenou',\n",
       "       'Barcelona - Poblenou\\nVer mapa',\n",
       "       'Barcelona - El Camp de l´Arpa del Clot',\n",
       "       'Barcelona - Besòs - Maresme',\n",
       "       'Barcelona - Diagonal Mar i el Front Marítim del Poblenou',\n",
       "       'Barcelona - Provençals del Poblenou', 'Barcelona - El Clot',\n",
       "       'Barcelona - Navas', 'Barcelona - Sagrada Família\\nVer mapa'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['loc_string'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuing encoding subtype and loc_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['subtype', 'loc_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>title</th>\n",
       "      <th>desc</th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>...</th>\n",
       "      <th>loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - La Vila Olímpica del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - L´Antiga Esquerra de l´Eixample</th>\n",
       "      <th>loc_string_Barcelona - Navas</th>\n",
       "      <th>loc_string_Barcelona - Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Poblenou\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Provençals del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Sant Antoni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.0</td>\n",
       "      <td>Piso Tallers. Piso con 2 habitaciones con asce...</td>\n",
       "      <td>Piso en última planta a reformar en calle Tall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>Piso C/ de valència. Piso reformado en venta d...</td>\n",
       "      <td>Ubicado en la zona del Camp de l’Arpa, cerca d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>Piso en Dreta de l´Eixample. Acogedor piso al ...</td>\n",
       "      <td>En pleno centro de Barcelona, justo al lado de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>Piso Barcelona - corts catalanes. Soleado, cén...</td>\n",
       "      <td>Vivienda espaciosa en Sant Antoni, cerca de Pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>Piso en Carrer de sardenya 271. Alto, reformad...</td>\n",
       "      <td>En el corazón de Barcelona, en una hermosa fin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Piso todo exterior con balcones en sant antoni</td>\n",
       "      <td>Encantador piso alto todo exterior con 2 balco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Piso Avila</td>\n",
       "      <td>Estupenda oportunidad en el Parc i La Llacuna ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Piso en Sagrada Família. Piso carrer de mallorca</td>\n",
       "      <td>¡OPORTUNIDAD EN SAGRADA FAMILIA!\\n\\nPiso situa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Apartamento en Poblenou. Apartamento con 3 hab...</td>\n",
       "      <td>Piso en venta, Barcelona, Poblenou, carrer del...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Piso Carrer de buenaventura muñoz. Piso con 4 ...</td>\n",
       "      <td>Oportunidad Única Inversión Barcelona! Piso 10...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>998 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price                                              title  \\\n",
       "0    320.0  Piso Tallers. Piso con 2 habitaciones con asce...   \n",
       "1    335.0  Piso C/ de valència. Piso reformado en venta d...   \n",
       "2    330.0  Piso en Dreta de l´Eixample. Acogedor piso al ...   \n",
       "3    435.0  Piso Barcelona - corts catalanes. Soleado, cén...   \n",
       "4    410.0  Piso en Carrer de sardenya 271. Alto, reformad...   \n",
       "..     ...                                                ...   \n",
       "993    0.0     Piso todo exterior con balcones en sant antoni   \n",
       "994    0.0                                         Piso Avila   \n",
       "995    0.0   Piso en Sagrada Família. Piso carrer de mallorca   \n",
       "996    0.0  Apartamento en Poblenou. Apartamento con 3 hab...   \n",
       "997    0.0  Piso Carrer de buenaventura muñoz. Piso con 4 ...   \n",
       "\n",
       "                                                  desc  APARTMENT  DUPLEX  \\\n",
       "0    Piso en última planta a reformar en calle Tall...          0       0   \n",
       "1    Ubicado en la zona del Camp de l’Arpa, cerca d...          0       0   \n",
       "2    En pleno centro de Barcelona, justo al lado de...          0       0   \n",
       "3    Vivienda espaciosa en Sant Antoni, cerca de Pl...          0       0   \n",
       "4    En el corazón de Barcelona, en una hermosa fin...          0       0   \n",
       "..                                                 ...        ...     ...   \n",
       "993  Encantador piso alto todo exterior con 2 balco...          0       0   \n",
       "994  Estupenda oportunidad en el Parc i La Llacuna ...          0       0   \n",
       "995  ¡OPORTUNIDAD EN SAGRADA FAMILIA!\\n\\nPiso situa...          0       0   \n",
       "996  Piso en venta, Barcelona, Poblenou, carrer del...          1       0   \n",
       "997  Oportunidad Única Inversión Barcelona! Piso 10...          0       0   \n",
       "\n",
       "     FLAT  GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  ...  \\\n",
       "0       1             0     0          0       0  ...   \n",
       "1       1             0     0          0       0  ...   \n",
       "2       1             0     0          0       0  ...   \n",
       "3       1             0     0          0       0  ...   \n",
       "4       1             0     0          0       0  ...   \n",
       "..    ...           ...   ...        ...     ...  ...   \n",
       "993     1             0     0          0       0  ...   \n",
       "994     1             0     0          0       0  ...   \n",
       "995     1             0     0          0       0  ...   \n",
       "996     0             0     0          0       0  ...   \n",
       "997     1             0     0          0       0  ...   \n",
       "\n",
       "     loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa  \\\n",
       "0                                                    0                 \n",
       "1                                                    0                 \n",
       "2                                                    0                 \n",
       "3                                                    0                 \n",
       "4                                                    0                 \n",
       "..                                                 ...                 \n",
       "993                                                  0                 \n",
       "994                                                  0                 \n",
       "995                                                  0                 \n",
       "996                                                  0                 \n",
       "997                                                  0                 \n",
       "\n",
       "     loc_string_Barcelona - La Vila Olímpica del Poblenou  \\\n",
       "0                                                    0      \n",
       "1                                                    0      \n",
       "2                                                    0      \n",
       "3                                                    0      \n",
       "4                                                    0      \n",
       "..                                                 ...      \n",
       "993                                                  0      \n",
       "994                                                  0      \n",
       "995                                                  0      \n",
       "996                                                  0      \n",
       "997                                                  0      \n",
       "\n",
       "     loc_string_Barcelona - L´Antiga Esquerra de l´Eixample  \\\n",
       "0                                                    0        \n",
       "1                                                    0        \n",
       "2                                                    0        \n",
       "3                                                    0        \n",
       "4                                                    0        \n",
       "..                                                 ...        \n",
       "993                                                  0        \n",
       "994                                                  0        \n",
       "995                                                  0        \n",
       "996                                                  0        \n",
       "997                                                  0        \n",
       "\n",
       "     loc_string_Barcelona - Navas  loc_string_Barcelona - Poblenou  \\\n",
       "0                               0                                0   \n",
       "1                               0                                0   \n",
       "2                               0                                0   \n",
       "3                               0                                0   \n",
       "4                               0                                0   \n",
       "..                            ...                              ...   \n",
       "993                             0                                0   \n",
       "994                             0                                0   \n",
       "995                             0                                0   \n",
       "996                             0                                1   \n",
       "997                             0                                0   \n",
       "\n",
       "     loc_string_Barcelona - Poblenou\\nVer mapa  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "..                                         ...   \n",
       "993                                          0   \n",
       "994                                          0   \n",
       "995                                          0   \n",
       "996                                          0   \n",
       "997                                          0   \n",
       "\n",
       "     loc_string_Barcelona - Provençals del Poblenou  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "..                                              ...   \n",
       "993                                               0   \n",
       "994                                               0   \n",
       "995                                               0   \n",
       "996                                               0   \n",
       "997                                               0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         1   \n",
       "..                                      ...   \n",
       "993                                       0   \n",
       "994                                       0   \n",
       "995                                       1   \n",
       "996                                       0   \n",
       "997                                       0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família\\nVer mapa  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "..                                                ...   \n",
       "993                                                 0   \n",
       "994                                                 0   \n",
       "995                                                 0   \n",
       "996                                                 0   \n",
       "997                                                 0   \n",
       "\n",
       "     loc_string_Barcelona - Sant Antoni  \n",
       "0                                     1  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     1  \n",
       "4                                     0  \n",
       "..                                  ...  \n",
       "993                                   0  \n",
       "994                                   0  \n",
       "995                                   0  \n",
       "996                                   0  \n",
       "997                                   0  \n",
       "\n",
       "[998 rows x 39 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop('title', axis=1, inplace=True)\n",
    "df2.drop('desc', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(998, 37)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>square_m</th>\n",
       "      <th>hab</th>\n",
       "      <th>...</th>\n",
       "      <th>loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - La Vila Olímpica del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - L´Antiga Esquerra de l´Eixample</th>\n",
       "      <th>loc_string_Barcelona - Navas</th>\n",
       "      <th>loc_string_Barcelona - Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Poblenou\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Provençals del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Sant Antoni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  APARTMENT  DUPLEX  FLAT  GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  \\\n",
       "0  320.0          0       0     1             0     0          0       0   \n",
       "1  335.0          0       0     1             0     0          0       0   \n",
       "2  330.0          0       0     1             0     0          0       0   \n",
       "3  435.0          0       0     1             0     0          0       0   \n",
       "4  410.0          0       0     1             0     0          0       0   \n",
       "\n",
       "   square_m  hab  ...  \\\n",
       "0      85.0  2.0  ...   \n",
       "1      65.0  2.0  ...   \n",
       "2      77.0  2.0  ...   \n",
       "3      96.0  3.0  ...   \n",
       "4      84.0  2.0  ...   \n",
       "\n",
       "   loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "3                                                  0                 \n",
       "4                                                  0                 \n",
       "\n",
       "   loc_string_Barcelona - La Vila Olímpica del Poblenou  \\\n",
       "0                                                  0      \n",
       "1                                                  0      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "\n",
       "   loc_string_Barcelona - L´Antiga Esquerra de l´Eixample  \\\n",
       "0                                                  0        \n",
       "1                                                  0        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   loc_string_Barcelona - Navas  loc_string_Barcelona - Poblenou  \\\n",
       "0                             0                                0   \n",
       "1                             0                                0   \n",
       "2                             0                                0   \n",
       "3                             0                                0   \n",
       "4                             0                                0   \n",
       "\n",
       "   loc_string_Barcelona - Poblenou\\nVer mapa  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   loc_string_Barcelona - Provençals del Poblenou  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "\n",
       "   loc_string_Barcelona - Sagrada Família  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       1   \n",
       "\n",
       "   loc_string_Barcelona - Sagrada Família\\nVer mapa  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "\n",
       "   loc_string_Barcelona - Sant Antoni  \n",
       "0                                   1  \n",
       "1                                   0  \n",
       "2                                   0  \n",
       "3                                   1  \n",
       "4                                   0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df2[df2['price'] != 0.0]\n",
    "test_df = df2[df2['price'] == 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'APARTMENT', 'DUPLEX', 'FLAT', 'GROUND_FLOOR', 'LOFT',\n",
       "       'PENTHOUSE', 'STUDIO', 'square_m', 'hab', 'bano', 'subtype_APARTMENT',\n",
       "       'subtype_DUPLEX', 'subtype_FLAT', 'subtype_GROUND_FLOOR',\n",
       "       'subtype_LOFT', 'subtype_PENTHOUSE', 'subtype_STUDIO',\n",
       "       'loc_string_Barcelona - Besòs - Maresme',\n",
       "       'loc_string_Barcelona - Diagonal Mar i el Front Marítim del Poblenou',\n",
       "       'loc_string_Barcelona - Dreta de l´Eixample',\n",
       "       'loc_string_Barcelona - Dreta de l´Eixample\\nVer mapa',\n",
       "       'loc_string_Barcelona - El Camp de l´Arpa del Clot',\n",
       "       'loc_string_Barcelona - El Clot',\n",
       "       'loc_string_Barcelona - El Parc i la Llacuna del Poblenou',\n",
       "       'loc_string_Barcelona - Fort Pienc',\n",
       "       'loc_string_Barcelona - La Nova Esquerra de l´Eixample',\n",
       "       'loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa',\n",
       "       'loc_string_Barcelona - La Vila Olímpica del Poblenou',\n",
       "       'loc_string_Barcelona - L´Antiga Esquerra de l´Eixample',\n",
       "       'loc_string_Barcelona - Navas', 'loc_string_Barcelona - Poblenou',\n",
       "       'loc_string_Barcelona - Poblenou\\nVer mapa',\n",
       "       'loc_string_Barcelona - Provençals del Poblenou',\n",
       "       'loc_string_Barcelona - Sagrada Família',\n",
       "       'loc_string_Barcelona - Sagrada Família\\nVer mapa',\n",
       "       'loc_string_Barcelona - Sant Antoni'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((866, 37), (132, 37))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>square_m</th>\n",
       "      <th>hab</th>\n",
       "      <th>...</th>\n",
       "      <th>loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - La Vila Olímpica del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - L´Antiga Esquerra de l´Eixample</th>\n",
       "      <th>loc_string_Barcelona - Navas</th>\n",
       "      <th>loc_string_Barcelona - Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Poblenou\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Provençals del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Sant Antoni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>320.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>335.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>435.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>410.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>342.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>315.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>360.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>225.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     price  APARTMENT  DUPLEX  FLAT  GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  \\\n",
       "0    320.0          0       0     1             0     0          0       0   \n",
       "1    335.0          0       0     1             0     0          0       0   \n",
       "2    330.0          0       0     1             0     0          0       0   \n",
       "3    435.0          0       0     1             0     0          0       0   \n",
       "4    410.0          0       0     1             0     0          0       0   \n",
       "..     ...        ...     ...   ...           ...   ...        ...     ...   \n",
       "861  342.0          0       0     1             0     0          0       0   \n",
       "862  315.0          0       0     1             0     0          0       0   \n",
       "863  360.0          0       0     1             0     0          0       0   \n",
       "864  270.0          0       0     1             0     0          0       0   \n",
       "865  225.0          0       0     1             0     0          0       0   \n",
       "\n",
       "     square_m  hab  ...  \\\n",
       "0        85.0  2.0  ...   \n",
       "1        65.0  2.0  ...   \n",
       "2        77.0  2.0  ...   \n",
       "3        96.0  3.0  ...   \n",
       "4        84.0  2.0  ...   \n",
       "..        ...  ...  ...   \n",
       "861     115.0  3.0  ...   \n",
       "862      82.0  3.0  ...   \n",
       "863      79.0  4.0  ...   \n",
       "864      63.0  1.0  ...   \n",
       "865      80.0  2.0  ...   \n",
       "\n",
       "     loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa  \\\n",
       "0                                                    0                 \n",
       "1                                                    0                 \n",
       "2                                                    0                 \n",
       "3                                                    0                 \n",
       "4                                                    0                 \n",
       "..                                                 ...                 \n",
       "861                                                  0                 \n",
       "862                                                  0                 \n",
       "863                                                  0                 \n",
       "864                                                  0                 \n",
       "865                                                  0                 \n",
       "\n",
       "     loc_string_Barcelona - La Vila Olímpica del Poblenou  \\\n",
       "0                                                    0      \n",
       "1                                                    0      \n",
       "2                                                    0      \n",
       "3                                                    0      \n",
       "4                                                    0      \n",
       "..                                                 ...      \n",
       "861                                                  0      \n",
       "862                                                  0      \n",
       "863                                                  0      \n",
       "864                                                  0      \n",
       "865                                                  0      \n",
       "\n",
       "     loc_string_Barcelona - L´Antiga Esquerra de l´Eixample  \\\n",
       "0                                                    0        \n",
       "1                                                    0        \n",
       "2                                                    0        \n",
       "3                                                    0        \n",
       "4                                                    0        \n",
       "..                                                 ...        \n",
       "861                                                  0        \n",
       "862                                                  0        \n",
       "863                                                  0        \n",
       "864                                                  0        \n",
       "865                                                  0        \n",
       "\n",
       "     loc_string_Barcelona - Navas  loc_string_Barcelona - Poblenou  \\\n",
       "0                               0                                0   \n",
       "1                               0                                0   \n",
       "2                               0                                0   \n",
       "3                               0                                0   \n",
       "4                               0                                0   \n",
       "..                            ...                              ...   \n",
       "861                             1                                0   \n",
       "862                             1                                0   \n",
       "863                             1                                0   \n",
       "864                             1                                0   \n",
       "865                             1                                0   \n",
       "\n",
       "     loc_string_Barcelona - Poblenou\\nVer mapa  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "..                                         ...   \n",
       "861                                          0   \n",
       "862                                          0   \n",
       "863                                          0   \n",
       "864                                          0   \n",
       "865                                          0   \n",
       "\n",
       "     loc_string_Barcelona - Provençals del Poblenou  \\\n",
       "0                                                 0   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "3                                                 0   \n",
       "4                                                 0   \n",
       "..                                              ...   \n",
       "861                                               0   \n",
       "862                                               0   \n",
       "863                                               0   \n",
       "864                                               0   \n",
       "865                                               0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         1   \n",
       "..                                      ...   \n",
       "861                                       0   \n",
       "862                                       0   \n",
       "863                                       0   \n",
       "864                                       0   \n",
       "865                                       0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família\\nVer mapa  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "..                                                ...   \n",
       "861                                                 0   \n",
       "862                                                 0   \n",
       "863                                                 0   \n",
       "864                                                 0   \n",
       "865                                                 0   \n",
       "\n",
       "     loc_string_Barcelona - Sant Antoni  \n",
       "0                                     1  \n",
       "1                                     0  \n",
       "2                                     0  \n",
       "3                                     1  \n",
       "4                                     0  \n",
       "..                                  ...  \n",
       "861                                   0  \n",
       "862                                   0  \n",
       "863                                   0  \n",
       "864                                   0  \n",
       "865                                   0  \n",
       "\n",
       "[866 rows x 37 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, 1:].values \n",
    "y = train_df.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=5)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df.drop('price', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APARTMENT</th>\n",
       "      <th>DUPLEX</th>\n",
       "      <th>FLAT</th>\n",
       "      <th>GROUND_FLOOR</th>\n",
       "      <th>LOFT</th>\n",
       "      <th>PENTHOUSE</th>\n",
       "      <th>STUDIO</th>\n",
       "      <th>square_m</th>\n",
       "      <th>hab</th>\n",
       "      <th>bano</th>\n",
       "      <th>...</th>\n",
       "      <th>loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - La Vila Olímpica del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - L´Antiga Esquerra de l´Eixample</th>\n",
       "      <th>loc_string_Barcelona - Navas</th>\n",
       "      <th>loc_string_Barcelona - Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Poblenou\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Provençals del Poblenou</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família</th>\n",
       "      <th>loc_string_Barcelona - Sagrada Família\\nVer mapa</th>\n",
       "      <th>loc_string_Barcelona - Sant Antoni</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>132 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     APARTMENT  DUPLEX  FLAT  GROUND_FLOOR  LOFT  PENTHOUSE  STUDIO  square_m  \\\n",
       "866          0       0     1             0     0          0       0      87.0   \n",
       "867          0       0     1             0     0          0       0      78.0   \n",
       "868          0       0     1             0     0          0       0      65.0   \n",
       "869          0       0     1             0     0          0       0      88.0   \n",
       "870          0       0     1             0     0          0       0      82.0   \n",
       "..         ...     ...   ...           ...   ...        ...     ...       ...   \n",
       "993          0       0     1             0     0          0       0      89.0   \n",
       "994          0       0     1             0     0          0       0      65.0   \n",
       "995          0       0     1             0     0          0       0      75.0   \n",
       "996          1       0     0             0     0          0       0      75.0   \n",
       "997          0       0     1             0     0          0       0      80.0   \n",
       "\n",
       "     hab  bano  ...  \\\n",
       "866  4.0   1.0  ...   \n",
       "867  4.0   1.0  ...   \n",
       "868  1.0   1.0  ...   \n",
       "869  3.0   1.0  ...   \n",
       "870  2.0   1.0  ...   \n",
       "..   ...   ...  ...   \n",
       "993  3.0   1.0  ...   \n",
       "994  3.0   1.0  ...   \n",
       "995  4.0   1.0  ...   \n",
       "996  3.0   2.0  ...   \n",
       "997  4.0   2.0  ...   \n",
       "\n",
       "     loc_string_Barcelona - La Nova Esquerra de l´Eixample\\nVer mapa  \\\n",
       "866                                                  0                 \n",
       "867                                                  0                 \n",
       "868                                                  0                 \n",
       "869                                                  0                 \n",
       "870                                                  0                 \n",
       "..                                                 ...                 \n",
       "993                                                  0                 \n",
       "994                                                  0                 \n",
       "995                                                  0                 \n",
       "996                                                  0                 \n",
       "997                                                  0                 \n",
       "\n",
       "     loc_string_Barcelona - La Vila Olímpica del Poblenou  \\\n",
       "866                                                  0      \n",
       "867                                                  0      \n",
       "868                                                  0      \n",
       "869                                                  0      \n",
       "870                                                  0      \n",
       "..                                                 ...      \n",
       "993                                                  0      \n",
       "994                                                  0      \n",
       "995                                                  0      \n",
       "996                                                  0      \n",
       "997                                                  0      \n",
       "\n",
       "     loc_string_Barcelona - L´Antiga Esquerra de l´Eixample  \\\n",
       "866                                                  0        \n",
       "867                                                  0        \n",
       "868                                                  1        \n",
       "869                                                  0        \n",
       "870                                                  0        \n",
       "..                                                 ...        \n",
       "993                                                  0        \n",
       "994                                                  0        \n",
       "995                                                  0        \n",
       "996                                                  0        \n",
       "997                                                  0        \n",
       "\n",
       "     loc_string_Barcelona - Navas  loc_string_Barcelona - Poblenou  \\\n",
       "866                             0                                0   \n",
       "867                             0                                1   \n",
       "868                             0                                0   \n",
       "869                             0                                1   \n",
       "870                             0                                0   \n",
       "..                            ...                              ...   \n",
       "993                             0                                0   \n",
       "994                             0                                0   \n",
       "995                             0                                0   \n",
       "996                             0                                1   \n",
       "997                             0                                0   \n",
       "\n",
       "     loc_string_Barcelona - Poblenou\\nVer mapa  \\\n",
       "866                                          0   \n",
       "867                                          0   \n",
       "868                                          0   \n",
       "869                                          0   \n",
       "870                                          0   \n",
       "..                                         ...   \n",
       "993                                          0   \n",
       "994                                          0   \n",
       "995                                          0   \n",
       "996                                          0   \n",
       "997                                          0   \n",
       "\n",
       "     loc_string_Barcelona - Provençals del Poblenou  \\\n",
       "866                                               0   \n",
       "867                                               0   \n",
       "868                                               0   \n",
       "869                                               0   \n",
       "870                                               0   \n",
       "..                                              ...   \n",
       "993                                               0   \n",
       "994                                               0   \n",
       "995                                               0   \n",
       "996                                               0   \n",
       "997                                               0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família  \\\n",
       "866                                       0   \n",
       "867                                       0   \n",
       "868                                       0   \n",
       "869                                       0   \n",
       "870                                       0   \n",
       "..                                      ...   \n",
       "993                                       0   \n",
       "994                                       0   \n",
       "995                                       1   \n",
       "996                                       0   \n",
       "997                                       0   \n",
       "\n",
       "     loc_string_Barcelona - Sagrada Família\\nVer mapa  \\\n",
       "866                                                 0   \n",
       "867                                                 0   \n",
       "868                                                 0   \n",
       "869                                                 0   \n",
       "870                                                 0   \n",
       "..                                                ...   \n",
       "993                                                 0   \n",
       "994                                                 0   \n",
       "995                                                 0   \n",
       "996                                                 0   \n",
       "997                                                 0   \n",
       "\n",
       "     loc_string_Barcelona - Sant Antoni  \n",
       "866                                   0  \n",
       "867                                   0  \n",
       "868                                   0  \n",
       "869                                   0  \n",
       "870                                   1  \n",
       "..                                  ...  \n",
       "993                                   0  \n",
       "994                                   0  \n",
       "995                                   0  \n",
       "996                                   0  \n",
       "997                                   0  \n",
       "\n",
       "[132 rows x 36 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        , -0.34065502],\n",
       "       [-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        , -0.34065502],\n",
       "       [-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        ,  2.93552107],\n",
       "       ...,\n",
       "       [-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        ,  2.93552107],\n",
       "       [-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        , -0.34065502],\n",
       "       [-0.1537956 , -0.1081125 ,  0.26744499, ..., -0.47823281,\n",
       "         0.        , -0.34065502]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.4175\n",
      "Mean Squared Error: 3167.8763\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=5)\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r2:.4f}')\n",
    "print(f'Mean Squared Error: {mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_new = test_df.values\n",
    "\n",
    "X_test_new_scaled = scaler.transform(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared scores for each fold: [0.48517918 0.38064532 0.60397579 0.49901514 0.47277148]\n",
      "Average R-squared: 0.4883173811910545\n"
     ]
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(rf_regressor, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "y_test_new_pred = rf_regressor.predict(X_test_new_scaled)\n",
    "\n",
    "print(\"R-squared scores for each fold:\", scores)\n",
    "print(\"Average R-squared:\", np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.018307136387151313\n",
      "Mean Squared Error: 18820.654018601417\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'df2' is your DataFrame\n",
    "# Separate features and target\n",
    "X = df2.drop('price', axis=1).values\n",
    "y = df2['price'].values\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features (LASSO works better when features are on the same scale)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create the LASSO regression object with an alpha value (regularization strength)\n",
    "lasso = Lasso(alpha=0.1)\n",
    "\n",
    "# Fit the model on the training data\n",
    "lasso.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lasso.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the R-squared and Mean Squared Error\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f'R-squared: {r2}')\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([326.39833333, 347.535     , 290.67071429, 382.5684    ,\n",
       "       317.67233333, 375.28016667, 315.47716667, 238.92      ,\n",
       "       309.61266667, 296.39804   , 380.6239    , 371.29871429,\n",
       "       344.7425    , 324.863     , 375.28016667, 253.052     ,\n",
       "       294.8       , 364.8869339 , 416.69833333, 296.45      ,\n",
       "       329.4845    , 337.11      , 316.08666667, 429.75208333,\n",
       "       253.15342857, 267.99583333, 375.28016667, 348.07      ,\n",
       "       369.76666667, 407.76856667, 381.14433333, 374.09106667,\n",
       "       368.90165385, 368.        , 423.77279304, 294.47185   ,\n",
       "       384.72785714, 276.75      , 423.91916667, 341.78666667,\n",
       "       414.92516667, 368.90165385, 339.287     , 371.6835    ,\n",
       "       375.28016667, 430.5672    , 337.49486667, 431.45      ,\n",
       "       383.739     , 429.75208333, 324.119     , 364.8615    ,\n",
       "       305.064     , 282.6425    , 399.134     , 252.0415    ,\n",
       "       433.11      , 369.76666667, 344.32166667, 397.99      ,\n",
       "       278.046     , 362.46163167, 379.5475    , 316.08666667,\n",
       "       372.10066667, 374.09106667, 341.78666667, 343.285     ,\n",
       "       386.04378095, 419.6475    , 376.46763333, 298.975     ,\n",
       "       406.33233333, 436.15119048, 244.70366667, 264.85825   ,\n",
       "       310.638     , 305.55      , 379.5475    , 384.5989    ,\n",
       "       403.71066667, 397.37156667, 220.7635    , 374.81833333,\n",
       "       379.5475    , 364.19256249, 324.89933333, 414.6752381 ,\n",
       "       133.86989   , 389.90916667, 432.28      , 253.15342857,\n",
       "       375.28016667, 379.5475    , 389.31026667, 314.12016667,\n",
       "       400.75      , 379.5475    , 387.5525    , 276.675     ,\n",
       "       418.4025    , 344.72433333, 241.2472619 , 319.50833333,\n",
       "       339.51      , 312.17166667, 329.99      , 376.64455149,\n",
       "       422.556     , 403.71066667, 344.32166667, 242.13642857,\n",
       "       251.5762619 , 355.69784762, 430.18333333, 349.113     ,\n",
       "       387.14216667, 378.18466667, 384.2988    , 433.85333333,\n",
       "       369.76666667, 307.819     , 334.18333333, 366.93166667,\n",
       "       129.85989   , 397.5448    , 305.599     , 375.28016667,\n",
       "       297.11066667, 299.49033333, 404.742     , 315.58333333])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_new_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Custom dataset for loading features and targets.\"\"\"\n",
    "    def __init__(self, features, targets):\n",
    "        \"\"\"\n",
    "        Initialize the dataset with features and targets.\n",
    "        \n",
    "        Args:\n",
    "            features (DataFrame or np.ndarray or torch.Tensor): The input features.\n",
    "            targets (DataFrame or np.ndarray or torch.Tensor): The target values.\n",
    "        \"\"\"\n",
    "        if isinstance(features, pd.DataFrame):\n",
    "            features = features.reset_index(drop=True).values\n",
    "        if isinstance(targets, pd.DataFrame) or isinstance(targets, pd.Series):\n",
    "            targets = targets.reset_index(drop=True).values\n",
    "        \n",
    "        if isinstance(features, np.ndarray):\n",
    "            features = torch.from_numpy(features).float()\n",
    "        if isinstance(targets, np.ndarray):\n",
    "            targets = torch.from_numpy(targets).float()\n",
    "        \n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the total number of samples in the dataset.\"\"\"\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        target = self.targets[idx]\n",
    "        return feature, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CustomDataset(features=X_train, targets=y_train)\n",
    "dataset_test = CustomDataset(features=X_test, targets=y_test)\n",
    "\n",
    "# Create a DataLoader to handle batching and shuffling\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() # First call the constructor for the parent class\n",
    "        self.dense1 = torch.nn.Linear(36,100)\n",
    "        self.dense8 = torch.nn.Linear(100,1)\n",
    "\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.dense8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork3(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() # First call the constructor for the parent class\n",
    "        self.dense1 = torch.nn.Linear(36,6)\n",
    "        self.dense8 = torch.nn.Linear(6,1)\n",
    "\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.dense8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork2(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__() # First call the constructor for the parent class\n",
    "        self.dense1 = torch.nn.Linear(36,36)\n",
    "        self.dense8 = torch.nn.Linear(36,1)\n",
    "\n",
    "\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    def forward(self, x): \n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.dense8(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Example model\n",
    "model1 = SimpleNeuralNetwork()\n",
    "model2 = SimpleNeuralNetwork2()\n",
    "model3 = SimpleNeuralNetwork3()\n",
    "optimizer = torch.optim.AdamW(model1.parameters(), lr=.002) \n",
    "num_epochs = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is:  0  Avg. loss (training data):  -5.148355745932344  Avg. loss (validation data):  -3.877066814190474\n",
      "epoch is:  1  Avg. loss (training data):  -3.8437539231858495  Avg. loss (validation data):  -2.5463397177209726\n",
      "epoch is:  2  Avg. loss (training data):  -2.0267432358654087  Avg. loss (validation data):  -1.5537336922955987\n",
      "epoch is:  3  Avg. loss (training data):  -0.7543017835790298  Avg. loss (validation data):  -0.33355498616177687\n",
      "epoch is:  4  Avg. loss (training data):  -0.09473628991178064  Avg. loss (validation data):  -0.05040141633798805\n",
      "epoch is:  5  Avg. loss (training data):  0.05612348873879301  Avg. loss (validation data):  -0.047182697407507135\n",
      "epoch is:  6  Avg. loss (training data):  0.023951091273459048  Avg. loss (validation data):  -0.0990797475538635\n",
      "epoch is:  7  Avg. loss (training data):  0.031603650344674945  Avg. loss (validation data):  -0.04130730612456563\n",
      "epoch is:  8  Avg. loss (training data):  0.05448103889328755  Avg. loss (validation data):  -0.11495490935831566\n",
      "epoch is:  9  Avg. loss (training data):  0.056634705901204535  Avg. loss (validation data):  -0.043579360464132876\n",
      "epoch is:  10  Avg. loss (training data):  0.03426760167865172  Avg. loss (validation data):  -0.13624525822776143\n",
      "epoch is:  11  Avg. loss (training data):  0.0376554946434668  Avg. loss (validation data):  -0.15046455783322318\n",
      "epoch is:  12  Avg. loss (training data):  0.04540743425845692  Avg. loss (validation data):  -0.3924546093859308\n",
      "epoch is:  13  Avg. loss (training data):  0.05833028413499778  Avg. loss (validation data):  -0.22082806358241483\n",
      "epoch is:  14  Avg. loss (training data):  0.03900340283832505  Avg. loss (validation data):  -0.1265729693113783\n",
      "epoch is:  15  Avg. loss (training data):  0.037662072682421874  Avg. loss (validation data):  -0.07764254676828605\n",
      "epoch is:  16  Avg. loss (training data):  0.04083504830759908  Avg. loss (validation data):  -0.04731247913081912\n",
      "epoch is:  17  Avg. loss (training data):  0.044230774219971895  Avg. loss (validation data):  -0.04951601353461001\n",
      "epoch is:  18  Avg. loss (training data):  0.06951048589671166  Avg. loss (validation data):  -0.03953895791690444\n",
      "epoch is:  19  Avg. loss (training data):  0.044682163576141375  Avg. loss (validation data):  -0.16107180464968043\n",
      "epoch is:  20  Avg. loss (training data):  0.06067765843345083  Avg. loss (validation data):  -0.04703520252003327\n",
      "epoch is:  21  Avg. loss (training data):  0.06239048553770703  Avg. loss (validation data):  -0.19271736800780234\n",
      "epoch is:  22  Avg. loss (training data):  0.06579806156907964  Avg. loss (validation data):  -0.11780661080027637\n",
      "epoch is:  23  Avg. loss (training data):  0.06740756881758844  Avg. loss (validation data):  -0.17417250345594776\n",
      "epoch is:  24  Avg. loss (training data):  0.06734522972135887  Avg. loss (validation data):  -0.04932636912443627\n",
      "epoch is:  25  Avg. loss (training data):  0.06342239466515082  Avg. loss (validation data):  -0.09870851747296534\n",
      "epoch is:  26  Avg. loss (training data):  0.06030533630408904  Avg. loss (validation data):  -0.12938084023649793\n",
      "epoch is:  27  Avg. loss (training data):  0.06854338328847141  Avg. loss (validation data):  -0.27582468836897034\n",
      "epoch is:  28  Avg. loss (training data):  0.06727934549779474  Avg. loss (validation data):  -0.027400121363957863\n",
      "epoch is:  29  Avg. loss (training data):  -0.03227014406856268  Avg. loss (validation data):  -0.003679203449397444\n",
      "epoch is:  30  Avg. loss (training data):  0.03499574095616144  Avg. loss (validation data):  -0.11455511921311097\n",
      "epoch is:  31  Avg. loss (training data):  0.07502901248687918  Avg. loss (validation data):  -0.050800474817999035\n",
      "epoch is:  32  Avg. loss (training data):  0.056009592158713685  Avg. loss (validation data):  -0.17875271989344912\n",
      "epoch is:  33  Avg. loss (training data):  0.06692767692546171  Avg. loss (validation data):  -0.08601899846953776\n",
      "epoch is:  34  Avg. loss (training data):  0.06934930558479464  Avg. loss (validation data):  -0.13857772801200313\n",
      "epoch is:  35  Avg. loss (training data):  0.07701279383983599  Avg. loss (validation data):  -0.0800571569164803\n",
      "epoch is:  36  Avg. loss (training data):  0.07245975268266994  Avg. loss (validation data):  -0.051088374535002715\n",
      "epoch is:  37  Avg. loss (training data):  0.07496215761911174  Avg. loss (validation data):  -0.10056361750687358\n",
      "epoch is:  38  Avg. loss (training data):  0.07743676081319496  Avg. loss (validation data):  -0.030932447525179145\n",
      "epoch is:  39  Avg. loss (training data):  0.07139153522767488  Avg. loss (validation data):  -0.17258085662045802\n",
      "epoch is:  40  Avg. loss (training data):  0.07265117038111342  Avg. loss (validation data):  -0.11593866537966495\n",
      "epoch is:  41  Avg. loss (training data):  0.06611446877847743  Avg. loss (validation data):  -0.22986027433054598\n",
      "epoch is:  42  Avg. loss (training data):  0.07054605003396407  Avg. loss (validation data):  -0.06802647867857756\n",
      "epoch is:  43  Avg. loss (training data):  0.0831483656043572  Avg. loss (validation data):  -0.13470627113855332\n",
      "epoch is:  44  Avg. loss (training data):  0.06828180345823077  Avg. loss (validation data):  -0.028092309240907585\n",
      "epoch is:  45  Avg. loss (training data):  0.07634875960540496  Avg. loss (validation data):  -0.080978051574247\n",
      "epoch is:  46  Avg. loss (training data):  0.06899138461858213  Avg. loss (validation data):  -0.021065884678752447\n",
      "epoch is:  47  Avg. loss (training data):  0.042839053702947306  Avg. loss (validation data):  -0.0854831973783025\n",
      "epoch is:  48  Avg. loss (training data):  0.06806582748660694  Avg. loss (validation data):  -0.13671234597923965\n",
      "epoch is:  49  Avg. loss (training data):  0.06027863211754729  Avg. loss (validation data):  -0.37652530450783406\n",
      "epoch is:  50  Avg. loss (training data):  0.0735459560095342  Avg. loss (validation data):  -0.3201157032549345\n",
      "epoch is:  51  Avg. loss (training data):  0.08949564101277215  Avg. loss (validation data):  -0.13920421010088724\n",
      "epoch is:  52  Avg. loss (training data):  0.09997202416497405  Avg. loss (validation data):  -0.11299255859793753\n",
      "epoch is:  53  Avg. loss (training data):  0.06599561857394422  Avg. loss (validation data):  -0.061221639760277204\n",
      "epoch is:  54  Avg. loss (training data):  0.0801481368943027  Avg. loss (validation data):  -0.4426389627229462\n",
      "epoch is:  55  Avg. loss (training data):  0.0806471951007201  Avg. loss (validation data):  -0.0806618200422464\n",
      "epoch is:  56  Avg. loss (training data):  0.07522865889144312  Avg. loss (validation data):  -0.053424997727468004\n",
      "epoch is:  57  Avg. loss (training data):  0.0832134374378362  Avg. loss (validation data):  -0.10285113001717616\n",
      "epoch is:  58  Avg. loss (training data):  0.06664921787869245  Avg. loss (validation data):  -0.38440459921758324\n",
      "epoch is:  59  Avg. loss (training data):  0.1007835110845258  Avg. loss (validation data):  -0.13729083572939596\n",
      "epoch is:  60  Avg. loss (training data):  0.08752182105962553  Avg. loss (validation data):  0.010011707088644803\n",
      "epoch is:  61  Avg. loss (training data):  0.08713565716015698  Avg. loss (validation data):  -0.06832763152749376\n",
      "epoch is:  62  Avg. loss (training data):  0.053672049324653893  Avg. loss (validation data):  -0.023627784713303908\n",
      "epoch is:  63  Avg. loss (training data):  0.07378908663452241  Avg. loss (validation data):  -0.1745210361580583\n",
      "epoch is:  64  Avg. loss (training data):  0.09573983664129282  Avg. loss (validation data):  -0.11222010978213119\n",
      "epoch is:  65  Avg. loss (training data):  0.07368940237009192  Avg. loss (validation data):  -0.08512006258885042\n",
      "epoch is:  66  Avg. loss (training data):  0.10826977720359166  Avg. loss (validation data):  -0.04639771843614753\n",
      "epoch is:  67  Avg. loss (training data):  0.10209314131754307  Avg. loss (validation data):  -0.06552767872724884\n",
      "epoch is:  68  Avg. loss (training data):  0.08588207307721227  Avg. loss (validation data):  -0.08241000974185222\n",
      "epoch is:  69  Avg. loss (training data):  0.09371792876453952  Avg. loss (validation data):  -0.04343193501056792\n",
      "epoch is:  70  Avg. loss (training data):  0.07627406492641144  Avg. loss (validation data):  -0.09373346822634779\n",
      "epoch is:  71  Avg. loss (training data):  0.09582009154211082  Avg. loss (validation data):  -0.1448025117053437\n",
      "epoch is:  72  Avg. loss (training data):  0.08402967063755881  Avg. loss (validation data):  -0.09177144904481331\n",
      "epoch is:  73  Avg. loss (training data):  0.10083952974068755  Avg. loss (validation data):  -0.059514696535295016\n",
      "epoch is:  74  Avg. loss (training data):  0.10993827193093429  Avg. loss (validation data):  -0.1380817354840536\n",
      "epoch is:  75  Avg. loss (training data):  0.0812635431428399  Avg. loss (validation data):  -0.08800197794527079\n",
      "epoch is:  76  Avg. loss (training data):  0.07067058287612728  Avg. loss (validation data):  -0.1672693146016512\n",
      "epoch is:  77  Avg. loss (training data):  0.11665679677352513  Avg. loss (validation data):  -0.15132298144172332\n",
      "epoch is:  78  Avg. loss (training data):  0.11323246845443374  Avg. loss (validation data):  -0.06165354235486805\n",
      "epoch is:  79  Avg. loss (training data):  0.10131571358674087  Avg. loss (validation data):  -0.18138603792848243\n",
      "epoch is:  80  Avg. loss (training data):  0.09352794949648142  Avg. loss (validation data):  -0.22842721479237754\n",
      "epoch is:  81  Avg. loss (training data):  0.10771446835039925  Avg. loss (validation data):  -0.022657059013940852\n",
      "epoch is:  82  Avg. loss (training data):  0.11301719240558103  Avg. loss (validation data):  -0.06208928899568178\n",
      "epoch is:  83  Avg. loss (training data):  0.10428074186658046  Avg. loss (validation data):  -0.13631595272472047\n",
      "epoch is:  84  Avg. loss (training data):  0.11404443623972597  Avg. loss (validation data):  -0.01659728104735996\n",
      "epoch is:  85  Avg. loss (training data):  0.09794798360628638  Avg. loss (validation data):  -0.07612851497798499\n",
      "epoch is:  86  Avg. loss (training data):  0.10487761080003967  Avg. loss (validation data):  -0.0630131527714707\n",
      "epoch is:  87  Avg. loss (training data):  0.08915143024659251  Avg. loss (validation data):  -0.06745027009422662\n",
      "epoch is:  88  Avg. loss (training data):  0.1161052549825356  Avg. loss (validation data):  -0.07375472586757534\n",
      "epoch is:  89  Avg. loss (training data):  0.09070161386074382  Avg. loss (validation data):  -0.07936172090498486\n",
      "epoch is:  90  Avg. loss (training data):  0.07793009544090411  Avg. loss (validation data):  -0.06791631631571653\n",
      "epoch is:  91  Avg. loss (training data):  0.12546295216732928  Avg. loss (validation data):  -0.45786129893463406\n",
      "epoch is:  92  Avg. loss (training data):  0.10681136264376737  Avg. loss (validation data):  -0.049384541240415754\n",
      "epoch is:  93  Avg. loss (training data):  0.08878027051901259  Avg. loss (validation data):  -0.10139508793465182\n",
      "epoch is:  94  Avg. loss (training data):  0.1321728741674543  Avg. loss (validation data):  -0.08011787345346198\n",
      "epoch is:  95  Avg. loss (training data):  0.11957056750350492  Avg. loss (validation data):  -0.13224451439037815\n",
      "epoch is:  96  Avg. loss (training data):  0.10498542538264775  Avg. loss (validation data):  -0.04714573768199459\n",
      "epoch is:  97  Avg. loss (training data):  0.1233804138267564  Avg. loss (validation data):  0.021437605359828193\n",
      "epoch is:  98  Avg. loss (training data):  0.08882219039254831  Avg. loss (validation data):  -0.05731199449184711\n",
      "epoch is:  99  Avg. loss (training data):  0.13480809817084222  Avg. loss (validation data):  -0.025773019486917743\n",
      "epoch is:  100  Avg. loss (training data):  0.10811598262657268  Avg. loss (validation data):  -0.046635639501747\n",
      "epoch is:  101  Avg. loss (training data):  0.03557313313742313  Avg. loss (validation data):  -0.10847819690926952\n",
      "epoch is:  102  Avg. loss (training data):  0.11681608918531369  Avg. loss (validation data):  0.0200855961064251\n",
      "epoch is:  103  Avg. loss (training data):  0.11612496149146036  Avg. loss (validation data):  -0.07250700592940464\n",
      "epoch is:  104  Avg. loss (training data):  0.11324792345960435  Avg. loss (validation data):  -0.11830252085723303\n",
      "epoch is:  105  Avg. loss (training data):  0.11718135638376408  Avg. loss (validation data):  -0.03535170186532831\n",
      "epoch is:  106  Avg. loss (training data):  0.12562569077987626  Avg. loss (validation data):  -0.036133540787783844\n",
      "epoch is:  107  Avg. loss (training data):  0.12850715289703818  Avg. loss (validation data):  0.005544292108902663\n",
      "epoch is:  108  Avg. loss (training data):  0.11274119448319705  Avg. loss (validation data):  0.03847516471385694\n",
      "epoch is:  109  Avg. loss (training data):  0.12405524932769212  Avg. loss (validation data):  -0.05500533677292726\n",
      "epoch is:  110  Avg. loss (training data):  0.10524721965819889  Avg. loss (validation data):  0.012803175155393389\n",
      "epoch is:  111  Avg. loss (training data):  0.14675078409293815  Avg. loss (validation data):  -0.03426127689866227\n",
      "epoch is:  112  Avg. loss (training data):  0.10096527974460208  Avg. loss (validation data):  -0.06530982523843705\n",
      "epoch is:  113  Avg. loss (training data):  0.12505249508105373  Avg. loss (validation data):  -0.028391750301884993\n",
      "epoch is:  114  Avg. loss (training data):  0.11385328762901878  Avg. loss (validation data):  -0.05798754328134213\n",
      "epoch is:  115  Avg. loss (training data):  0.1107360615326639  Avg. loss (validation data):  0.0025264262527965636\n",
      "epoch is:  116  Avg. loss (training data):  0.134201459844042  Avg. loss (validation data):  -0.17108270004720655\n",
      "epoch is:  117  Avg. loss (training data):  0.11604096736047657  Avg. loss (validation data):  -0.011130288497653993\n",
      "epoch is:  118  Avg. loss (training data):  0.11971646682346475  Avg. loss (validation data):  -1.0273753696116668\n",
      "epoch is:  119  Avg. loss (training data):  0.11070931063570855  Avg. loss (validation data):  -0.08977994811883683\n",
      "epoch is:  120  Avg. loss (training data):  0.14257997538781264  Avg. loss (validation data):  0.07299514955624496\n",
      "epoch is:  121  Avg. loss (training data):  0.13614367888725176  Avg. loss (validation data):  -0.03337846446019521\n",
      "epoch is:  122  Avg. loss (training data):  0.14883714460872738  Avg. loss (validation data):  -0.021521784016416183\n",
      "epoch is:  123  Avg. loss (training data):  0.132233112419615  Avg. loss (validation data):  0.03973967817676132\n",
      "epoch is:  124  Avg. loss (training data):  0.15071139415405604  Avg. loss (validation data):  -0.003923014889148654\n",
      "epoch is:  125  Avg. loss (training data):  0.14006049538741136  Avg. loss (validation data):  -0.31201979567978455\n",
      "epoch is:  126  Avg. loss (training data):  0.11612140827925418  Avg. loss (validation data):  -0.03452712776928243\n",
      "epoch is:  127  Avg. loss (training data):  0.13261233857054713  Avg. loss (validation data):  -0.02747318602329623\n",
      "epoch is:  128  Avg. loss (training data):  0.14218811370484669  Avg. loss (validation data):  -0.04260346058928382\n",
      "epoch is:  129  Avg. loss (training data):  0.12706094380527627  Avg. loss (validation data):  -0.03352268262210535\n",
      "epoch is:  130  Avg. loss (training data):  0.14482770005857953  Avg. loss (validation data):  0.01888327395468078\n",
      "epoch is:  131  Avg. loss (training data):  0.13623452138273914  Avg. loss (validation data):  0.008964640787802094\n",
      "epoch is:  132  Avg. loss (training data):  0.11152894807608985  Avg. loss (validation data):  -0.09918504238906045\n",
      "epoch is:  133  Avg. loss (training data):  0.11998597849985576  Avg. loss (validation data):  -0.01265262537070544\n",
      "epoch is:  134  Avg. loss (training data):  0.14840462306029945  Avg. loss (validation data):  -0.23459578652776253\n",
      "epoch is:  135  Avg. loss (training data):  0.13417668997189044  Avg. loss (validation data):  -0.13274176890203243\n",
      "epoch is:  136  Avg. loss (training data):  0.15027421732056775  Avg. loss (validation data):  -0.10282093160695628\n",
      "epoch is:  137  Avg. loss (training data):  0.14811238347206113  Avg. loss (validation data):  -0.2597298168161898\n",
      "epoch is:  138  Avg. loss (training data):  0.12423063065974396  Avg. loss (validation data):  -0.10039238364264448\n",
      "epoch is:  139  Avg. loss (training data):  0.14581154686622363  Avg. loss (validation data):  -0.07335354369235479\n",
      "epoch is:  140  Avg. loss (training data):  0.12192348084655133  Avg. loss (validation data):  -0.20440828058865693\n",
      "epoch is:  141  Avg. loss (training data):  0.14414154703263446  Avg. loss (validation data):  -0.014521780851798545\n",
      "epoch is:  142  Avg. loss (training data):  0.13198711379707612  Avg. loss (validation data):  -0.016601229868065146\n",
      "epoch is:  143  Avg. loss (training data):  0.14860020327641482  Avg. loss (validation data):  -0.029694338335918977\n",
      "epoch is:  144  Avg. loss (training data):  0.15016429029764308  Avg. loss (validation data):  -0.07852998844473066\n",
      "epoch is:  145  Avg. loss (training data):  0.14720770279774925  Avg. loss (validation data):  -0.00788671992481119\n",
      "epoch is:  146  Avg. loss (training data):  0.15024646846003142  Avg. loss (validation data):  -0.05253008651618626\n",
      "epoch is:  147  Avg. loss (training data):  0.1610659206170655  Avg. loss (validation data):  -0.0211155381451249\n",
      "epoch is:  148  Avg. loss (training data):  0.13905123943511785  Avg. loss (validation data):  -0.037779608476255104\n",
      "epoch is:  149  Avg. loss (training data):  0.1482880871203192  Avg. loss (validation data):  -0.08363396513733115\n",
      "epoch is:  150  Avg. loss (training data):  0.14994146816845513  Avg. loss (validation data):  0.04117640166842899\n",
      "epoch is:  151  Avg. loss (training data):  0.14150406689077488  Avg. loss (validation data):  0.011243757810205686\n",
      "epoch is:  152  Avg. loss (training data):  0.11664831276758499  Avg. loss (validation data):  0.0031259781843243468\n",
      "epoch is:  153  Avg. loss (training data):  0.13569968395082177  Avg. loss (validation data):  -0.12577357095468591\n",
      "epoch is:  154  Avg. loss (training data):  0.1535779563601408  Avg. loss (validation data):  -0.018651542440118667\n",
      "epoch is:  155  Avg. loss (training data):  0.15184246687041542  Avg. loss (validation data):  -0.06368565471269642\n",
      "epoch is:  156  Avg. loss (training data):  0.1429044379337122  Avg. loss (validation data):  -0.008564596902969592\n",
      "epoch is:  157  Avg. loss (training data):  0.1654926799015299  Avg. loss (validation data):  -0.08814361247734614\n",
      "epoch is:  158  Avg. loss (training data):  0.14428084914866457  Avg. loss (validation data):  -0.014440252365872763\n",
      "epoch is:  159  Avg. loss (training data):  0.14662900419080724  Avg. loss (validation data):  0.008918585464789868\n",
      "epoch is:  160  Avg. loss (training data):  0.12836733555723584  Avg. loss (validation data):  -0.018045084496544406\n",
      "epoch is:  161  Avg. loss (training data):  0.1581589409528279  Avg. loss (validation data):  -0.03492566126760804\n",
      "epoch is:  162  Avg. loss (training data):  0.14884517497082086  Avg. loss (validation data):  -0.16635161562707146\n",
      "epoch is:  163  Avg. loss (training data):  0.13135276199640175  Avg. loss (validation data):  -0.20867238838188604\n",
      "epoch is:  164  Avg. loss (training data):  0.138440313336217  Avg. loss (validation data):  -0.061341358701832535\n",
      "epoch is:  165  Avg. loss (training data):  0.15041711640203587  Avg. loss (validation data):  0.006316697937067335\n",
      "epoch is:  166  Avg. loss (training data):  0.13638782910319114  Avg. loss (validation data):  -0.09683108653939106\n",
      "epoch is:  167  Avg. loss (training data):  0.13000245920497827  Avg. loss (validation data):  -0.010383645676773396\n",
      "epoch is:  168  Avg. loss (training data):  0.15599789832675737  Avg. loss (validation data):  -0.035405547731126016\n",
      "epoch is:  169  Avg. loss (training data):  0.1542137554405949  Avg. loss (validation data):  -0.4014891278825308\n",
      "epoch is:  170  Avg. loss (training data):  0.15843349529533557  Avg. loss (validation data):  -0.07054033267524472\n",
      "epoch is:  171  Avg. loss (training data):  0.14359034501819554  Avg. loss (validation data):  -0.0009841660933311053\n",
      "epoch is:  172  Avg. loss (training data):  0.13653804569381495  Avg. loss (validation data):  -0.15669554109920922\n",
      "epoch is:  173  Avg. loss (training data):  0.1556773364962708  Avg. loss (validation data):  0.0586535339999091\n",
      "epoch is:  174  Avg. loss (training data):  0.16319997398995856  Avg. loss (validation data):  -0.42216853465015003\n",
      "epoch is:  175  Avg. loss (training data):  0.14299805390413617  Avg. loss (validation data):  -0.033616325282961955\n",
      "epoch is:  176  Avg. loss (training data):  0.1588103445917278  Avg. loss (validation data):  0.020283619828982174\n",
      "epoch is:  177  Avg. loss (training data):  0.14252274756264247  Avg. loss (validation data):  0.013823006767589376\n",
      "epoch is:  178  Avg. loss (training data):  0.1480564738865046  Avg. loss (validation data):  -0.02110297645606109\n",
      "epoch is:  179  Avg. loss (training data):  0.14668034436124752  Avg. loss (validation data):  0.026277496494236607\n",
      "epoch is:  180  Avg. loss (training data):  0.1493768178397984  Avg. loss (validation data):  -0.1436849774630742\n",
      "epoch is:  181  Avg. loss (training data):  0.14651973557100617  Avg. loss (validation data):  -0.021809412709851754\n",
      "epoch is:  182  Avg. loss (training data):  0.1509865451067106  Avg. loss (validation data):  -0.056863974813160176\n",
      "epoch is:  183  Avg. loss (training data):  0.12552998081755523  Avg. loss (validation data):  -0.0292057623056947\n",
      "epoch is:  184  Avg. loss (training data):  0.15661943389181532  Avg. loss (validation data):  0.03388803141526713\n",
      "epoch is:  185  Avg. loss (training data):  0.12662934877757825  Avg. loss (validation data):  0.006206619367659745\n",
      "epoch is:  186  Avg. loss (training data):  0.15597011295715973  Avg. loss (validation data):  -0.034628860750541994\n",
      "epoch is:  187  Avg. loss (training data):  0.15855062439771508  Avg. loss (validation data):  -0.0015645873900924803\n",
      "epoch is:  188  Avg. loss (training data):  0.17560731379141026  Avg. loss (validation data):  -0.027177872095548845\n",
      "epoch is:  189  Avg. loss (training data):  0.1393508303372683  Avg. loss (validation data):  -0.06068185061205696\n",
      "epoch is:  190  Avg. loss (training data):  0.15036946737263157  Avg. loss (validation data):  -0.021917293723486022\n",
      "epoch is:  191  Avg. loss (training data):  0.14439656809475332  Avg. loss (validation data):  -0.028016571301291333\n",
      "epoch is:  192  Avg. loss (training data):  0.14592287349348737  Avg. loss (validation data):  0.011819717200284185\n",
      "epoch is:  193  Avg. loss (training data):  0.1449250480829587  Avg. loss (validation data):  -0.1570677410821522\n",
      "epoch is:  194  Avg. loss (training data):  0.14462012121312945  Avg. loss (validation data):  -0.03634014099152245\n",
      "epoch is:  195  Avg. loss (training data):  0.1759544427472336  Avg. loss (validation data):  0.00015719401574835042\n",
      "epoch is:  196  Avg. loss (training data):  0.15909305689428413  Avg. loss (validation data):  -0.06111657262489662\n",
      "epoch is:  197  Avg. loss (training data):  0.1436349521549923  Avg. loss (validation data):  -0.028426129403811173\n",
      "epoch is:  198  Avg. loss (training data):  0.15627099025768562  Avg. loss (validation data):  0.04743703835400686\n",
      "epoch is:  199  Avg. loss (training data):  0.15158865610324773  Avg. loss (validation data):  -0.07946867399643757\n",
      "epoch is:  200  Avg. loss (training data):  0.14294364461907488  Avg. loss (validation data):  0.01031247732943549\n",
      "epoch is:  201  Avg. loss (training data):  0.15417342398177952  Avg. loss (validation data):  -0.020829802276438714\n",
      "epoch is:  202  Avg. loss (training data):  0.1654055212622045  Avg. loss (validation data):  0.06715656499027668\n",
      "epoch is:  203  Avg. loss (training data):  0.16164089113617863  Avg. loss (validation data):  -0.04166052319711723\n",
      "epoch is:  204  Avg. loss (training data):  0.17178461359000757  Avg. loss (validation data):  -0.035713689928739974\n",
      "epoch is:  205  Avg. loss (training data):  0.1537722876364821  Avg. loss (validation data):  -0.13134260556642813\n",
      "epoch is:  206  Avg. loss (training data):  0.1522492889295042  Avg. loss (validation data):  0.06770330370959822\n",
      "epoch is:  207  Avg. loss (training data):  0.159845587206001  Avg. loss (validation data):  -0.3999353305128868\n",
      "epoch is:  208  Avg. loss (training data):  0.1392326572760016  Avg. loss (validation data):  0.06876401770331442\n",
      "epoch is:  209  Avg. loss (training data):  0.17305075599638237  Avg. loss (validation data):  -0.049032901199703084\n",
      "epoch is:  210  Avg. loss (training data):  0.15354126513198538  Avg. loss (validation data):  0.013438846329172789\n",
      "epoch is:  211  Avg. loss (training data):  0.1710985481552286  Avg. loss (validation data):  -0.04344351233655024\n",
      "epoch is:  212  Avg. loss (training data):  0.15189711781555404  Avg. loss (validation data):  -0.11432191773237711\n",
      "epoch is:  213  Avg. loss (training data):  0.1497951309179319  Avg. loss (validation data):  -0.017212825274709416\n",
      "epoch is:  214  Avg. loss (training data):  0.1387260350159248  Avg. loss (validation data):  -0.024063765998967042\n",
      "epoch is:  215  Avg. loss (training data):  0.15903655462440197  Avg. loss (validation data):  -0.032437875071428444\n",
      "epoch is:  216  Avg. loss (training data):  0.15859128220243432  Avg. loss (validation data):  -0.22167975975672466\n",
      "epoch is:  217  Avg. loss (training data):  0.14994854160509472  Avg. loss (validation data):  -0.06592307827236676\n",
      "epoch is:  218  Avg. loss (training data):  0.16426576323604558  Avg. loss (validation data):  -0.037469935488849915\n",
      "epoch is:  219  Avg. loss (training data):  0.15517555197345734  Avg. loss (validation data):  -0.017858183033722472\n",
      "epoch is:  220  Avg. loss (training data):  0.1437480020730647  Avg. loss (validation data):  0.0018250486961311088\n",
      "epoch is:  221  Avg. loss (training data):  0.16322080147331852  Avg. loss (validation data):  0.03494553237067672\n",
      "epoch is:  222  Avg. loss (training data):  0.165720636215408  Avg. loss (validation data):  -0.08117985577565144\n",
      "epoch is:  223  Avg. loss (training data):  0.16577830768957252  Avg. loss (validation data):  -0.09039114085186147\n",
      "epoch is:  224  Avg. loss (training data):  0.12947433369172454  Avg. loss (validation data):  0.011357642612367316\n",
      "epoch is:  225  Avg. loss (training data):  0.12804020893793905  Avg. loss (validation data):  -0.0981624610384219\n",
      "epoch is:  226  Avg. loss (training data):  0.15405676296268003  Avg. loss (validation data):  0.0018062711332682716\n",
      "epoch is:  227  Avg. loss (training data):  0.1654361309058138  Avg. loss (validation data):  0.026582529101472137\n",
      "epoch is:  228  Avg. loss (training data):  0.15489059603969188  Avg. loss (validation data):  0.014951075267382772\n",
      "epoch is:  229  Avg. loss (training data):  0.1374278983667228  Avg. loss (validation data):  -0.09334061971629856\n",
      "epoch is:  230  Avg. loss (training data):  0.13136410240671892  Avg. loss (validation data):  -0.10571967834595121\n",
      "epoch is:  231  Avg. loss (training data):  0.15887822253446562  Avg. loss (validation data):  -0.014594153517669064\n",
      "epoch is:  232  Avg. loss (training data):  0.15936493745106983  Avg. loss (validation data):  -0.016959778120944197\n",
      "epoch is:  233  Avg. loss (training data):  0.16129119209216686  Avg. loss (validation data):  -0.03176413582118682\n",
      "epoch is:  234  Avg. loss (training data):  0.1515437658638883  Avg. loss (validation data):  0.0023795402127042725\n",
      "epoch is:  235  Avg. loss (training data):  0.14737919838102312  Avg. loss (validation data):  -0.03828773743540232\n",
      "epoch is:  236  Avg. loss (training data):  0.1570174729639654  Avg. loss (validation data):  0.03207256353049243\n",
      "epoch is:  237  Avg. loss (training data):  0.17318133530854823  Avg. loss (validation data):  0.04802916661475744\n",
      "epoch is:  238  Avg. loss (training data):  0.15544973380620564  Avg. loss (validation data):  -0.09680622802095573\n",
      "epoch is:  239  Avg. loss (training data):  0.11504362326330395  Avg. loss (validation data):  -0.018938116591920826\n",
      "epoch is:  240  Avg. loss (training data):  0.14106248546622294  Avg. loss (validation data):  -0.0988196150940247\n",
      "epoch is:  241  Avg. loss (training data):  0.13774999569049937  Avg. loss (validation data):  -0.11548326676821065\n",
      "epoch is:  242  Avg. loss (training data):  0.1603569671884168  Avg. loss (validation data):  0.0014606459476607261\n",
      "epoch is:  243  Avg. loss (training data):  0.14176750838165803  Avg. loss (validation data):  0.029667974490307145\n",
      "epoch is:  244  Avg. loss (training data):  0.15456524549087153  Avg. loss (validation data):  -0.05235579727509606\n",
      "epoch is:  245  Avg. loss (training data):  0.13621385154724985  Avg. loss (validation data):  -0.059547199003784294\n",
      "epoch is:  246  Avg. loss (training data):  0.1662673691941469  Avg. loss (validation data):  -0.0048755626933419316\n",
      "epoch is:  247  Avg. loss (training data):  0.14692907889501705  Avg. loss (validation data):  0.000269379638185233\n",
      "epoch is:  248  Avg. loss (training data):  0.16370277727335064  Avg. loss (validation data):  0.035942341529997646\n",
      "epoch is:  249  Avg. loss (training data):  0.155434943476663  Avg. loss (validation data):  0.008600449341356684\n",
      "epoch is:  250  Avg. loss (training data):  0.1621870411342144  Avg. loss (validation data):  0.04736869951160124\n",
      "epoch is:  251  Avg. loss (training data):  0.16085962623936656  Avg. loss (validation data):  -0.011796536851184472\n",
      "epoch is:  252  Avg. loss (training data):  0.14378510171451764  Avg. loss (validation data):  0.0067179476947213535\n",
      "epoch is:  253  Avg. loss (training data):  0.16355318979072145  Avg. loss (validation data):  -0.029870833658049194\n",
      "epoch is:  254  Avg. loss (training data):  0.15169054902726775  Avg. loss (validation data):  -0.012747562971620338\n",
      "epoch is:  255  Avg. loss (training data):  0.17061090177130367  Avg. loss (validation data):  0.029925157323940712\n",
      "epoch is:  256  Avg. loss (training data):  0.14790829901086766  Avg. loss (validation data):  0.041385489446364075\n",
      "epoch is:  257  Avg. loss (training data):  0.16673255474285414  Avg. loss (validation data):  -0.04677373303023778\n",
      "epoch is:  258  Avg. loss (training data):  0.16239594914683664  Avg. loss (validation data):  -0.015073664401298648\n",
      "epoch is:  259  Avg. loss (training data):  0.12279045106376492  Avg. loss (validation data):  -0.008720702517075971\n",
      "epoch is:  260  Avg. loss (training data):  0.13826149228429596  Avg. loss (validation data):  -0.03376674989362224\n",
      "epoch is:  261  Avg. loss (training data):  0.14741633002944846  Avg. loss (validation data):  -0.018096140057527195\n",
      "epoch is:  262  Avg. loss (training data):  0.15271932064744095  Avg. loss (validation data):  -0.029536919210018553\n",
      "epoch is:  263  Avg. loss (training data):  0.14606522621267687  Avg. loss (validation data):  -0.041411652784398116\n",
      "epoch is:  264  Avg. loss (training data):  0.16228255795243482  Avg. loss (validation data):  -0.011996490282382493\n",
      "epoch is:  265  Avg. loss (training data):  0.144910067850111  Avg. loss (validation data):  -0.005284883740866838\n",
      "epoch is:  266  Avg. loss (training data):  0.1627182249401478  Avg. loss (validation data):  -0.05476600878937659\n",
      "epoch is:  267  Avg. loss (training data):  0.15716913432224364  Avg. loss (validation data):  -0.141070927705626\n",
      "epoch is:  268  Avg. loss (training data):  0.15371241698352514  Avg. loss (validation data):  0.10069846809751848\n",
      "epoch is:  269  Avg. loss (training data):  0.17568935284731568  Avg. loss (validation data):  -0.022344649997281554\n",
      "epoch is:  270  Avg. loss (training data):  0.14775632945938597  Avg. loss (validation data):  -0.042520247271428065\n",
      "epoch is:  271  Avg. loss (training data):  0.11513028321790163  Avg. loss (validation data):  0.041538360594754145\n",
      "epoch is:  272  Avg. loss (training data):  0.15651666646381865  Avg. loss (validation data):  -0.06054892026609658\n",
      "epoch is:  273  Avg. loss (training data):  0.1580821128265411  Avg. loss (validation data):  -0.11000583292922826\n",
      "epoch is:  274  Avg. loss (training data):  0.1659687604476181  Avg. loss (validation data):  -0.05999627210754878\n",
      "epoch is:  275  Avg. loss (training data):  0.15967890397708068  Avg. loss (validation data):  -0.023066333623952513\n",
      "epoch is:  276  Avg. loss (training data):  0.15744351694886613  Avg. loss (validation data):  -0.014532334270800631\n",
      "epoch is:  277  Avg. loss (training data):  0.15185951307880174  Avg. loss (validation data):  -0.13554418958497735\n",
      "epoch is:  278  Avg. loss (training data):  0.15138532817413833  Avg. loss (validation data):  -0.019443053138690294\n",
      "epoch is:  279  Avg. loss (training data):  0.17918370372141626  Avg. loss (validation data):  -0.02676110300196577\n",
      "epoch is:  280  Avg. loss (training data):  0.16631552451503356  Avg. loss (validation data):  -0.20528835612629912\n",
      "epoch is:  281  Avg. loss (training data):  0.14146467106301  Avg. loss (validation data):  0.017891344925342372\n",
      "epoch is:  282  Avg. loss (training data):  0.16991597336944367  Avg. loss (validation data):  3.782598684251174e-05\n",
      "epoch is:  283  Avg. loss (training data):  0.15100231869534064  Avg. loss (validation data):  0.0020077661677547765\n",
      "epoch is:  284  Avg. loss (training data):  0.15362158663255024  Avg. loss (validation data):  -0.023816748417790152\n",
      "epoch is:  285  Avg. loss (training data):  0.15973809219549553  Avg. loss (validation data):  -0.03227146821939356\n",
      "epoch is:  286  Avg. loss (training data):  0.17645314459387998  Avg. loss (validation data):  -0.05301379970378765\n",
      "epoch is:  287  Avg. loss (training data):  0.16281034719930543  Avg. loss (validation data):  -0.010969436208844227\n",
      "epoch is:  288  Avg. loss (training data):  0.11021820211926409  Avg. loss (validation data):  -0.10417034617928156\n",
      "epoch is:  289  Avg. loss (training data):  0.1604302573723795  Avg. loss (validation data):  -0.03222198533381539\n",
      "epoch is:  290  Avg. loss (training data):  0.15318445322787977  Avg. loss (validation data):  -0.3147420212169424\n",
      "epoch is:  291  Avg. loss (training data):  0.14524813133742132  Avg. loss (validation data):  -0.05626261447261122\n",
      "epoch is:  292  Avg. loss (training data):  0.16033140408703145  Avg. loss (validation data):  -0.03976532993290614\n",
      "epoch is:  293  Avg. loss (training data):  0.15857945128088555  Avg. loss (validation data):  -0.04349061259288029\n",
      "epoch is:  294  Avg. loss (training data):  0.15787199046167147  Avg. loss (validation data):  0.05215896987315621\n",
      "epoch is:  295  Avg. loss (training data):  0.16518051740849682  Avg. loss (validation data):  -0.10730977322224657\n",
      "epoch is:  296  Avg. loss (training data):  0.14637340008739974  Avg. loss (validation data):  -0.056644553680480776\n",
      "epoch is:  297  Avg. loss (training data):  0.1683593906698596  Avg. loss (validation data):  -0.27400576279441985\n",
      "epoch is:  298  Avg. loss (training data):  0.1387721445759284  Avg. loss (validation data):  0.009467701397167285\n",
      "epoch is:  299  Avg. loss (training data):  0.13258499544753055  Avg. loss (validation data):  0.005661210449652161\n",
      "epoch is:  300  Avg. loss (training data):  0.1480877817781005  Avg. loss (validation data):  0.07263308092763608\n",
      "epoch is:  301  Avg. loss (training data):  0.14998377397292914  Avg. loss (validation data):  0.02624182735153175\n",
      "epoch is:  302  Avg. loss (training data):  0.16563444978324401  Avg. loss (validation data):  0.024308840988111924\n",
      "epoch is:  303  Avg. loss (training data):  0.16694038748972306  Avg. loss (validation data):  -0.01804807813197887\n",
      "epoch is:  304  Avg. loss (training data):  0.1372735036876032  Avg. loss (validation data):  -0.012939940168055584\n",
      "epoch is:  305  Avg. loss (training data):  0.1452918148797252  Avg. loss (validation data):  -0.08089306928822737\n",
      "epoch is:  306  Avg. loss (training data):  0.1613331513544642  Avg. loss (validation data):  -0.02732026301829785\n",
      "epoch is:  307  Avg. loss (training data):  0.16566904012892214  Avg. loss (validation data):  -0.5108766037079563\n",
      "epoch is:  308  Avg. loss (training data):  0.16414015506969165  Avg. loss (validation data):  -0.0007764750828782109\n",
      "epoch is:  309  Avg. loss (training data):  0.16133993411144507  Avg. loss (validation data):  0.0323447111667151\n",
      "epoch is:  310  Avg. loss (training data):  0.1638765062212485  Avg. loss (validation data):  -0.06140136892258979\n",
      "epoch is:  311  Avg. loss (training data):  0.16935959817238733  Avg. loss (validation data):  0.020194342908227542\n",
      "epoch is:  312  Avg. loss (training data):  0.16636782044299359  Avg. loss (validation data):  0.0016972984283359122\n",
      "epoch is:  313  Avg. loss (training data):  0.15103042594762534  Avg. loss (validation data):  -0.09420079629835336\n",
      "epoch is:  314  Avg. loss (training data):  0.11618335529785086  Avg. loss (validation data):  -0.052335752908402595\n",
      "epoch is:  315  Avg. loss (training data):  0.17573923165753377  Avg. loss (validation data):  -0.026186016265570853\n",
      "epoch is:  316  Avg. loss (training data):  0.17782822462985426  Avg. loss (validation data):  -0.0023718912231489903\n",
      "epoch is:  317  Avg. loss (training data):  0.16186880707249457  Avg. loss (validation data):  0.00439508422928763\n",
      "epoch is:  318  Avg. loss (training data):  0.1486616701923119  Avg. loss (validation data):  0.020692957659991636\n",
      "epoch is:  319  Avg. loss (training data):  0.16985937812438323  Avg. loss (validation data):  0.02243481190366181\n",
      "epoch is:  320  Avg. loss (training data):  0.16639480891897496  Avg. loss (validation data):  -0.04397462486230556\n",
      "epoch is:  321  Avg. loss (training data):  0.16682635538024437  Avg. loss (validation data):  0.0014866631975990158\n",
      "epoch is:  322  Avg. loss (training data):  0.16600890207031857  Avg. loss (validation data):  -0.015081518757857173\n",
      "epoch is:  323  Avg. loss (training data):  0.1547199224524909  Avg. loss (validation data):  -0.03687088437711561\n",
      "epoch is:  324  Avg. loss (training data):  0.1496024087486474  Avg. loss (validation data):  -0.04079134570381239\n",
      "epoch is:  325  Avg. loss (training data):  0.16634520981101925  Avg. loss (validation data):  0.0023284066265588494\n",
      "epoch is:  326  Avg. loss (training data):  0.1616057248376164  Avg. loss (validation data):  -0.011601155152004026\n",
      "epoch is:  327  Avg. loss (training data):  0.16943001460553492  Avg. loss (validation data):  -0.04564627531260047\n",
      "epoch is:  328  Avg. loss (training data):  0.15390228910831022  Avg. loss (validation data):  -0.12002441748839524\n",
      "epoch is:  329  Avg. loss (training data):  0.17287036661525984  Avg. loss (validation data):  0.017679664195741074\n",
      "epoch is:  330  Avg. loss (training data):  0.17512372754409225  Avg. loss (validation data):  -0.021782629746188862\n",
      "epoch is:  331  Avg. loss (training data):  0.16227960573868105  Avg. loss (validation data):  -0.19891127991934\n",
      "epoch is:  332  Avg. loss (training data):  0.15760803486749506  Avg. loss (validation data):  -0.04808331119890882\n",
      "epoch is:  333  Avg. loss (training data):  0.16038637363134486  Avg. loss (validation data):  -0.11819565225914776\n",
      "epoch is:  334  Avg. loss (training data):  0.14687279195940156  Avg. loss (validation data):  -0.008343484850651712\n",
      "epoch is:  335  Avg. loss (training data):  0.17120806026031452  Avg. loss (validation data):  0.016742817071163412\n",
      "epoch is:  336  Avg. loss (training data):  0.15791686580909176  Avg. loss (validation data):  -0.14819427734302631\n",
      "epoch is:  337  Avg. loss (training data):  0.1659289207129416  Avg. loss (validation data):  -0.09102417641559575\n",
      "epoch is:  338  Avg. loss (training data):  0.16216233679528094  Avg. loss (validation data):  -0.09981767967735908\n",
      "epoch is:  339  Avg. loss (training data):  0.16078579534154944  Avg. loss (validation data):  -0.027303975925554873\n",
      "epoch is:  340  Avg. loss (training data):  0.16263096828277523  Avg. loss (validation data):  -0.04911478747860127\n",
      "epoch is:  341  Avg. loss (training data):  0.16447458110746802  Avg. loss (validation data):  -0.026958350744481416\n",
      "epoch is:  342  Avg. loss (training data):  0.1524299911841428  Avg. loss (validation data):  0.012308252929225565\n",
      "epoch is:  343  Avg. loss (training data):  0.159523278669599  Avg. loss (validation data):  0.06166562058395613\n",
      "epoch is:  344  Avg. loss (training data):  0.17011849310425906  Avg. loss (validation data):  -0.013104518902581368\n",
      "epoch is:  345  Avg. loss (training data):  0.17204060890499132  Avg. loss (validation data):  0.00821406207531932\n",
      "epoch is:  346  Avg. loss (training data):  0.15967236418827263  Avg. loss (validation data):  -0.2284810861849489\n",
      "epoch is:  347  Avg. loss (training data):  0.17048055495836364  Avg. loss (validation data):  -0.17221121942652928\n",
      "epoch is:  348  Avg. loss (training data):  0.16266982946997607  Avg. loss (validation data):  -0.5360126693496235\n",
      "epoch is:  349  Avg. loss (training data):  0.17482406309208479  Avg. loss (validation data):  -0.032384077211740525\n",
      "epoch is:  350  Avg. loss (training data):  0.1484946018398783  Avg. loss (validation data):  -0.05802618667346948\n",
      "epoch is:  351  Avg. loss (training data):  0.1578714067060608  Avg. loss (validation data):  -0.023248964226610998\n",
      "epoch is:  352  Avg. loss (training data):  0.17183468620422612  Avg. loss (validation data):  0.03666896005506348\n",
      "epoch is:  353  Avg. loss (training data):  0.16008307359100168  Avg. loss (validation data):  -0.040710266321711756\n",
      "epoch is:  354  Avg. loss (training data):  0.1659184115075504  Avg. loss (validation data):  -0.08448064189655233\n",
      "epoch is:  355  Avg. loss (training data):  0.15402314846658455  Avg. loss (validation data):  -0.08523572599647578\n",
      "epoch is:  356  Avg. loss (training data):  0.08232473691396795  Avg. loss (validation data):  -0.023373902860667668\n",
      "epoch is:  357  Avg. loss (training data):  0.15168817817815436  Avg. loss (validation data):  0.009360405557047933\n",
      "epoch is:  358  Avg. loss (training data):  0.1525625898894913  Avg. loss (validation data):  -0.290214407987937\n",
      "epoch is:  359  Avg. loss (training data):  0.15874554414151276  Avg. loss (validation data):  -0.05286969995512187\n",
      "epoch is:  360  Avg. loss (training data):  0.1840136472346445  Avg. loss (validation data):  -0.14270438709639938\n",
      "epoch is:  361  Avg. loss (training data):  0.1592549911191057  Avg. loss (validation data):  0.010106495160154636\n",
      "epoch is:  362  Avg. loss (training data):  0.17002488537758198  Avg. loss (validation data):  -0.0012520772921878237\n",
      "epoch is:  363  Avg. loss (training data):  0.14456770476444247  Avg. loss (validation data):  0.01776091426515331\n",
      "epoch is:  364  Avg. loss (training data):  0.177706091150019  Avg. loss (validation data):  -0.013681979434950784\n",
      "epoch is:  365  Avg. loss (training data):  0.17771051955907546  Avg. loss (validation data):  -0.05864432326991664\n",
      "epoch is:  366  Avg. loss (training data):  0.1694495911029132  Avg. loss (validation data):  0.009410930543473766\n",
      "epoch is:  367  Avg. loss (training data):  0.17298169955769788  Avg. loss (validation data):  -0.24279712063504516\n",
      "epoch is:  368  Avg. loss (training data):  0.17382453363794376  Avg. loss (validation data):  -0.038670104741552316\n",
      "epoch is:  369  Avg. loss (training data):  0.17300304550681986  Avg. loss (validation data):  -0.020148498536159347\n",
      "epoch is:  370  Avg. loss (training data):  0.1609784040793638  Avg. loss (validation data):  -0.0417981986017012\n",
      "epoch is:  371  Avg. loss (training data):  0.1670663785656397  Avg. loss (validation data):  -0.01703002929812739\n",
      "epoch is:  372  Avg. loss (training data):  0.17178646108575407  Avg. loss (validation data):  -0.03232940135267115\n",
      "epoch is:  373  Avg. loss (training data):  0.16956426324202561  Avg. loss (validation data):  -0.02741770287775252\n",
      "epoch is:  374  Avg. loss (training data):  0.16090772210450827  Avg. loss (validation data):  -0.008781960398886537\n",
      "epoch is:  375  Avg. loss (training data):  0.1744028350606169  Avg. loss (validation data):  -0.010204580556487541\n",
      "epoch is:  376  Avg. loss (training data):  0.17543422235841175  Avg. loss (validation data):  -0.010180179321799234\n",
      "epoch is:  377  Avg. loss (training data):  0.16945622710104716  Avg. loss (validation data):  -0.012196804628922522\n",
      "epoch is:  378  Avg. loss (training data):  0.17098325402576753  Avg. loss (validation data):  -0.044009331305092166\n",
      "epoch is:  379  Avg. loss (training data):  0.14750518438869084  Avg. loss (validation data):  -0.025584910537524177\n",
      "epoch is:  380  Avg. loss (training data):  0.18422751704925155  Avg. loss (validation data):  0.043844528334888784\n",
      "epoch is:  381  Avg. loss (training data):  0.16472636250753137  Avg. loss (validation data):  -0.043823597630610785\n",
      "epoch is:  382  Avg. loss (training data):  0.1669151963973777  Avg. loss (validation data):  -0.03570790804248484\n",
      "epoch is:  383  Avg. loss (training data):  0.16224760645867495  Avg. loss (validation data):  0.014218667082654781\n",
      "epoch is:  384  Avg. loss (training data):  0.153828904000005  Avg. loss (validation data):  -0.049932302264040294\n",
      "epoch is:  385  Avg. loss (training data):  0.14945007903458252  Avg. loss (validation data):  0.023186284266157858\n",
      "epoch is:  386  Avg. loss (training data):  0.1559321741593194  Avg. loss (validation data):  -0.05470072348550684\n",
      "epoch is:  387  Avg. loss (training data):  0.16178065274811076  Avg. loss (validation data):  -0.04400560356817155\n",
      "epoch is:  388  Avg. loss (training data):  0.16467300738186885  Avg. loss (validation data):  -0.12150414771306774\n",
      "epoch is:  389  Avg. loss (training data):  0.13747974584767245  Avg. loss (validation data):  -0.051877966738512256\n",
      "epoch is:  390  Avg. loss (training data):  0.1630245781177124  Avg. loss (validation data):  0.00603119588506551\n",
      "epoch is:  391  Avg. loss (training data):  0.16413374527940827  Avg. loss (validation data):  0.014891655632348098\n",
      "epoch is:  392  Avg. loss (training data):  0.1788922267824566  Avg. loss (validation data):  -0.16736213100304112\n",
      "epoch is:  393  Avg. loss (training data):  0.16902650967669366  Avg. loss (validation data):  0.016451731501792275\n",
      "epoch is:  394  Avg. loss (training data):  0.16931162564282257  Avg. loss (validation data):  0.00654262707800641\n",
      "epoch is:  395  Avg. loss (training data):  0.16089884726240564  Avg. loss (validation data):  -0.016124026911706953\n",
      "epoch is:  396  Avg. loss (training data):  0.16130794661701395  Avg. loss (validation data):  -0.004389533575732399\n",
      "epoch is:  397  Avg. loss (training data):  0.1633122511182941  Avg. loss (validation data):  -0.04056463626510227\n",
      "epoch is:  398  Avg. loss (training data):  0.16257562619126312  Avg. loss (validation data):  -0.031040191419242098\n",
      "epoch is:  399  Avg. loss (training data):  0.17232343967747268  Avg. loss (validation data):  -0.08723101905806964\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "model = model1\n",
    "N_train = len(dataset_train)\n",
    "N_val = len(dataset_test)\n",
    "\n",
    "avg_loss_per_epoch_train = []\n",
    "avg_loss_per_epoch_val = []\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    model.train() # Put the model in \"training mode\"\n",
    "    total_loss = []\n",
    "\n",
    "    for x_batch, y_batch in dataloader_train:\n",
    "\n",
    "    # These lines move the current batch of data to the GPU, if we're using the GPU.\n",
    "\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "# Each item in the current batch is fed into the neural network\n",
    "        avg_loss_for_this_batch = criterion(outputs, y_batch)\n",
    "\n",
    "        model.zero_grad() # Wipe the slate clean, preparing for a new gradient calculation\n",
    "        avg_loss_for_this_batch.backward() # Compute a gradient using the current batch\n",
    "                                        # A more logical name for this method might be \"compute_gradient\"\n",
    "\n",
    "    # Now we take one step of stochastic gradient descent or Adam.\n",
    "    # (or whichever optimization algorithm we're using)\n",
    "    # This short line of code updates all of the weights in our neural network.\n",
    "        optimizer.step() \n",
    "\n",
    "    # We can see how powerful PyTorch is now.  In the previous two lines of code,\n",
    "    # PyTorch did a very complicated gradient calculation for us,\n",
    "    # shielding us from the details.\n",
    "    # Then PyTorch updated the neural network weights, again shielding us from the details.\n",
    "        outputs = model(x_batch)\n",
    "        loss = r2_score( y_batch.detach().numpy(),outputs.detach().numpy())\n",
    "        total_loss.append(loss)\n",
    "    avg_training = np.mean(total_loss) \n",
    "\n",
    "\n",
    "    # We just finished one epoch of training.\n",
    "    # Let's check how well our model is performing on the validation dataset.\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    for x_batch, y_batch in dataloader_test:\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # This line tells PyTorch it doesn't need to worry \n",
    "                            # about computing any gradients, for the moment\n",
    "            outputs = model(x_batch)\n",
    "            outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "\n",
    "            loss = r2_score( y_batch.detach().numpy(), outputs.detach().numpy())\n",
    "            total_loss.append(loss)\n",
    "    avg = np.mean(total_loss)\n",
    "    \n",
    "    print('epoch is: ', ep, ' Avg. loss (training data): ', avg_training, ' Avg. loss (validation data): ', avg.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'project-group-6/test_kaggle.pickle'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    test_data = pickle.load(file)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "X_test = test_df.values  # Convert the relevant feature columns to a NumPy array\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float) \n",
    "pred = model(X_test_tensor)\n",
    "pred1 = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is:  0  Avg. loss (training data):  -5.589963077268203  Avg. loss (validation data):  -7.8368581909575425\n",
      "epoch is:  1  Avg. loss (training data):  -5.566495903756947  Avg. loss (validation data):  -9.666287221668316\n",
      "epoch is:  2  Avg. loss (training data):  -5.6792456717317075  Avg. loss (validation data):  -4.870285552013639\n",
      "epoch is:  3  Avg. loss (training data):  -5.636748088362592  Avg. loss (validation data):  -5.599286931789622\n",
      "epoch is:  4  Avg. loss (training data):  -5.285063565488253  Avg. loss (validation data):  -4.824305523176963\n",
      "epoch is:  5  Avg. loss (training data):  -5.6556723339072095  Avg. loss (validation data):  -6.911743312860092\n",
      "epoch is:  6  Avg. loss (training data):  -5.494496242575103  Avg. loss (validation data):  -4.871034360616192\n",
      "epoch is:  7  Avg. loss (training data):  -5.926229439788617  Avg. loss (validation data):  -8.030767845935399\n",
      "epoch is:  8  Avg. loss (training data):  -5.762673551392588  Avg. loss (validation data):  -8.762669809685717\n",
      "epoch is:  9  Avg. loss (training data):  -6.41608956973864  Avg. loss (validation data):  -8.694013462954015\n",
      "epoch is:  10  Avg. loss (training data):  -5.482432543550375  Avg. loss (validation data):  -4.841699748559607\n",
      "epoch is:  11  Avg. loss (training data):  -5.395181009811332  Avg. loss (validation data):  -9.765393851232398\n",
      "epoch is:  12  Avg. loss (training data):  -5.522798844443739  Avg. loss (validation data):  -4.840678068516846\n",
      "epoch is:  13  Avg. loss (training data):  -5.691131587915713  Avg. loss (validation data):  -4.75106846196202\n",
      "epoch is:  14  Avg. loss (training data):  -5.826699401474799  Avg. loss (validation data):  -9.306263726497894\n",
      "epoch is:  15  Avg. loss (training data):  -6.34330863422074  Avg. loss (validation data):  -4.820560689222075\n",
      "epoch is:  16  Avg. loss (training data):  -5.947596124405903  Avg. loss (validation data):  -5.3192368167281385\n",
      "epoch is:  17  Avg. loss (training data):  -5.691587408979951  Avg. loss (validation data):  -4.967285078383037\n",
      "epoch is:  18  Avg. loss (training data):  -5.768724526452282  Avg. loss (validation data):  -4.545490214168454\n",
      "epoch is:  19  Avg. loss (training data):  -6.052065578983388  Avg. loss (validation data):  -6.176914833205799\n",
      "epoch is:  20  Avg. loss (training data):  -5.973218637724146  Avg. loss (validation data):  -4.834291583232388\n",
      "epoch is:  21  Avg. loss (training data):  -5.590550145820236  Avg. loss (validation data):  -4.702561208966839\n",
      "epoch is:  22  Avg. loss (training data):  -5.370503532650205  Avg. loss (validation data):  -5.759564739530303\n",
      "epoch is:  23  Avg. loss (training data):  -5.41527258654774  Avg. loss (validation data):  -4.884087351027431\n",
      "epoch is:  24  Avg. loss (training data):  -5.941760079524422  Avg. loss (validation data):  -4.715006114757481\n",
      "epoch is:  25  Avg. loss (training data):  -5.699046049745649  Avg. loss (validation data):  -5.239183197354556\n",
      "epoch is:  26  Avg. loss (training data):  -6.344480232384834  Avg. loss (validation data):  -6.955427422903116\n",
      "epoch is:  27  Avg. loss (training data):  -5.778289583184139  Avg. loss (validation data):  -4.853171508289898\n",
      "epoch is:  28  Avg. loss (training data):  -5.876318444530679  Avg. loss (validation data):  -4.852992184166816\n",
      "epoch is:  29  Avg. loss (training data):  -5.634301985582201  Avg. loss (validation data):  -4.783204470927042\n",
      "epoch is:  30  Avg. loss (training data):  -6.0909230412338715  Avg. loss (validation data):  -5.176455711862076\n",
      "epoch is:  31  Avg. loss (training data):  -5.816019427740233  Avg. loss (validation data):  -5.229838138957329\n",
      "epoch is:  32  Avg. loss (training data):  -5.591120864630731  Avg. loss (validation data):  -4.831380895251314\n",
      "epoch is:  33  Avg. loss (training data):  -5.571731220270351  Avg. loss (validation data):  -4.920168164600624\n",
      "epoch is:  34  Avg. loss (training data):  -5.837118272066845  Avg. loss (validation data):  -5.046961066393008\n",
      "epoch is:  35  Avg. loss (training data):  -5.688283839729528  Avg. loss (validation data):  -4.647379857554074\n",
      "epoch is:  36  Avg. loss (training data):  -5.572428577106481  Avg. loss (validation data):  -5.3592390789571125\n",
      "epoch is:  37  Avg. loss (training data):  -5.178453480185369  Avg. loss (validation data):  -4.8225817856360775\n",
      "epoch is:  38  Avg. loss (training data):  -5.8250151005350155  Avg. loss (validation data):  -5.161660916138734\n",
      "epoch is:  39  Avg. loss (training data):  -5.847084476540666  Avg. loss (validation data):  -4.7487028705101935\n",
      "epoch is:  40  Avg. loss (training data):  -6.666147049499493  Avg. loss (validation data):  -5.249216167354889\n",
      "epoch is:  41  Avg. loss (training data):  -5.463306215344672  Avg. loss (validation data):  -6.088853232987276\n",
      "epoch is:  42  Avg. loss (training data):  -6.221016403456266  Avg. loss (validation data):  -4.82299671550223\n",
      "epoch is:  43  Avg. loss (training data):  -5.567501909258685  Avg. loss (validation data):  -4.896077975053367\n",
      "epoch is:  44  Avg. loss (training data):  -5.698853875950482  Avg. loss (validation data):  -6.0020781300848025\n",
      "epoch is:  45  Avg. loss (training data):  -5.7894195421001236  Avg. loss (validation data):  -4.9825775318032965\n",
      "epoch is:  46  Avg. loss (training data):  -6.247061245667558  Avg. loss (validation data):  -6.5324045333903955\n",
      "epoch is:  47  Avg. loss (training data):  -5.600687909583679  Avg. loss (validation data):  -8.810611688804164\n",
      "epoch is:  48  Avg. loss (training data):  -5.747966350117626  Avg. loss (validation data):  -5.014550449192889\n",
      "epoch is:  49  Avg. loss (training data):  -5.685756825042896  Avg. loss (validation data):  -4.968069892369619\n",
      "epoch is:  50  Avg. loss (training data):  -6.2614803257561436  Avg. loss (validation data):  -4.772945351571363\n",
      "epoch is:  51  Avg. loss (training data):  -5.493882317241937  Avg. loss (validation data):  -5.163702954625372\n",
      "epoch is:  52  Avg. loss (training data):  -5.790274118029052  Avg. loss (validation data):  -4.6419915353038315\n",
      "epoch is:  53  Avg. loss (training data):  -5.711182743887334  Avg. loss (validation data):  -6.20168850347814\n",
      "epoch is:  54  Avg. loss (training data):  -5.944838933321749  Avg. loss (validation data):  -6.547892890488362\n",
      "epoch is:  55  Avg. loss (training data):  -6.099593272795745  Avg. loss (validation data):  -6.338569205524457\n",
      "epoch is:  56  Avg. loss (training data):  -5.587429244999108  Avg. loss (validation data):  -10.200387102129648\n",
      "epoch is:  57  Avg. loss (training data):  -5.656745753309864  Avg. loss (validation data):  -5.08122757105573\n",
      "epoch is:  58  Avg. loss (training data):  -5.8320126029179  Avg. loss (validation data):  -5.234554735796814\n",
      "epoch is:  59  Avg. loss (training data):  -5.530110240254341  Avg. loss (validation data):  -8.708634363267896\n",
      "epoch is:  60  Avg. loss (training data):  -5.8243616408664165  Avg. loss (validation data):  -7.284742249343937\n",
      "epoch is:  61  Avg. loss (training data):  -6.076270413895941  Avg. loss (validation data):  -5.046549645076999\n",
      "epoch is:  62  Avg. loss (training data):  -6.057246868899714  Avg. loss (validation data):  -7.803570277268035\n",
      "epoch is:  63  Avg. loss (training data):  -5.390645418701986  Avg. loss (validation data):  -5.074488131759933\n",
      "epoch is:  64  Avg. loss (training data):  -5.625602257201724  Avg. loss (validation data):  -6.940708637066903\n",
      "epoch is:  65  Avg. loss (training data):  -7.340108861592479  Avg. loss (validation data):  -5.158765330078765\n",
      "epoch is:  66  Avg. loss (training data):  -5.418028836027262  Avg. loss (validation data):  -4.822474069637278\n",
      "epoch is:  67  Avg. loss (training data):  -6.106567110160486  Avg. loss (validation data):  -4.92244094650299\n",
      "epoch is:  68  Avg. loss (training data):  -5.971013792175776  Avg. loss (validation data):  -8.056689385854323\n",
      "epoch is:  69  Avg. loss (training data):  -6.0010519394534585  Avg. loss (validation data):  -5.665274342550508\n",
      "epoch is:  70  Avg. loss (training data):  -5.641342526119388  Avg. loss (validation data):  -4.76253264097363\n",
      "epoch is:  71  Avg. loss (training data):  -5.703304629655336  Avg. loss (validation data):  -4.759281312565277\n",
      "epoch is:  72  Avg. loss (training data):  -5.38992671585366  Avg. loss (validation data):  -5.006183576207635\n",
      "epoch is:  73  Avg. loss (training data):  -5.739194782203448  Avg. loss (validation data):  -5.4683087867730915\n",
      "epoch is:  74  Avg. loss (training data):  -5.5251652257800785  Avg. loss (validation data):  -4.603380818562587\n",
      "epoch is:  75  Avg. loss (training data):  -5.6207857060557425  Avg. loss (validation data):  -4.987666257341181\n",
      "epoch is:  76  Avg. loss (training data):  -6.046345744715896  Avg. loss (validation data):  -4.608239411031858\n",
      "epoch is:  77  Avg. loss (training data):  -5.555708263133417  Avg. loss (validation data):  -5.4811690268770965\n",
      "epoch is:  78  Avg. loss (training data):  -6.342050610238586  Avg. loss (validation data):  -4.5754224402688095\n",
      "epoch is:  79  Avg. loss (training data):  -5.588345376746295  Avg. loss (validation data):  -4.878744265011306\n",
      "epoch is:  80  Avg. loss (training data):  -5.814614597549918  Avg. loss (validation data):  -4.915148223033421\n",
      "epoch is:  81  Avg. loss (training data):  -5.435938414862899  Avg. loss (validation data):  -5.0622525010267125\n",
      "epoch is:  82  Avg. loss (training data):  -5.910672638927848  Avg. loss (validation data):  -4.7297280356173275\n",
      "epoch is:  83  Avg. loss (training data):  -5.872631099769937  Avg. loss (validation data):  -4.873186231604494\n",
      "epoch is:  84  Avg. loss (training data):  -5.813992936105776  Avg. loss (validation data):  -5.138476913145395\n",
      "epoch is:  85  Avg. loss (training data):  -6.167364129922309  Avg. loss (validation data):  -7.368247238311969\n",
      "epoch is:  86  Avg. loss (training data):  -5.714644085954667  Avg. loss (validation data):  -4.99789369288898\n",
      "epoch is:  87  Avg. loss (training data):  -5.875410960177975  Avg. loss (validation data):  -4.507450355794002\n",
      "epoch is:  88  Avg. loss (training data):  -5.671024625418723  Avg. loss (validation data):  -4.918532011736327\n",
      "epoch is:  89  Avg. loss (training data):  -5.9547284026210585  Avg. loss (validation data):  -5.000807557862743\n",
      "epoch is:  90  Avg. loss (training data):  -5.3819248583961485  Avg. loss (validation data):  -5.115138341503463\n",
      "epoch is:  91  Avg. loss (training data):  -5.672904762540461  Avg. loss (validation data):  -4.655540164496741\n",
      "epoch is:  92  Avg. loss (training data):  -5.876666917050312  Avg. loss (validation data):  -5.166350466675114\n",
      "epoch is:  93  Avg. loss (training data):  -6.5758023332773305  Avg. loss (validation data):  -4.933360008422841\n",
      "epoch is:  94  Avg. loss (training data):  -6.047098549208109  Avg. loss (validation data):  -4.752183111083347\n",
      "epoch is:  95  Avg. loss (training data):  -5.856271067389948  Avg. loss (validation data):  -5.051946413252057\n",
      "epoch is:  96  Avg. loss (training data):  -5.57035692525197  Avg. loss (validation data):  -5.211060356936178\n",
      "epoch is:  97  Avg. loss (training data):  -6.37942049893882  Avg. loss (validation data):  -13.934230152975354\n",
      "epoch is:  98  Avg. loss (training data):  -5.9203143898381585  Avg. loss (validation data):  -5.257269658069396\n",
      "epoch is:  99  Avg. loss (training data):  -5.542407328511104  Avg. loss (validation data):  -6.410974168559666\n",
      "epoch is:  100  Avg. loss (training data):  -5.9746436165318695  Avg. loss (validation data):  -4.642200298413052\n",
      "epoch is:  101  Avg. loss (training data):  -6.385159493129047  Avg. loss (validation data):  -5.464677109995918\n",
      "epoch is:  102  Avg. loss (training data):  -5.636620462900043  Avg. loss (validation data):  -5.139378055624084\n",
      "epoch is:  103  Avg. loss (training data):  -5.576302811915616  Avg. loss (validation data):  -5.247171833481511\n",
      "epoch is:  104  Avg. loss (training data):  -6.277405350127412  Avg. loss (validation data):  -5.449300887993788\n",
      "epoch is:  105  Avg. loss (training data):  -5.884484173123521  Avg. loss (validation data):  -9.374950480199876\n",
      "epoch is:  106  Avg. loss (training data):  -5.8668246529458115  Avg. loss (validation data):  -5.456794691253896\n",
      "epoch is:  107  Avg. loss (training data):  -5.478115720001628  Avg. loss (validation data):  -6.648039312961752\n",
      "epoch is:  108  Avg. loss (training data):  -5.802526559308503  Avg. loss (validation data):  -4.618917834735447\n",
      "epoch is:  109  Avg. loss (training data):  -6.076226069999626  Avg. loss (validation data):  -4.732988388019497\n",
      "epoch is:  110  Avg. loss (training data):  -5.890381700050724  Avg. loss (validation data):  -5.003700156937361\n",
      "epoch is:  111  Avg. loss (training data):  -5.618490592734138  Avg. loss (validation data):  -4.474741037276392\n",
      "epoch is:  112  Avg. loss (training data):  -5.724903808253973  Avg. loss (validation data):  -5.214413092612081\n",
      "epoch is:  113  Avg. loss (training data):  -5.99103177889156  Avg. loss (validation data):  -5.014850419150191\n",
      "epoch is:  114  Avg. loss (training data):  -5.941442253388117  Avg. loss (validation data):  -5.278729446713499\n",
      "epoch is:  115  Avg. loss (training data):  -5.983925722406518  Avg. loss (validation data):  -5.805643739454432\n",
      "epoch is:  116  Avg. loss (training data):  -6.700887538524003  Avg. loss (validation data):  -6.3887073683692694\n",
      "epoch is:  117  Avg. loss (training data):  -5.624166832792839  Avg. loss (validation data):  -4.636602456717246\n",
      "epoch is:  118  Avg. loss (training data):  -5.923924958969929  Avg. loss (validation data):  -7.995354045489033\n",
      "epoch is:  119  Avg. loss (training data):  -5.578510558126856  Avg. loss (validation data):  -4.937726424914762\n",
      "epoch is:  120  Avg. loss (training data):  -6.00736634523068  Avg. loss (validation data):  -4.486528481422631\n",
      "epoch is:  121  Avg. loss (training data):  -6.247806309932279  Avg. loss (validation data):  -6.247868537750874\n",
      "epoch is:  122  Avg. loss (training data):  -5.608549932972579  Avg. loss (validation data):  -4.729022170147166\n",
      "epoch is:  123  Avg. loss (training data):  -5.855205448828852  Avg. loss (validation data):  -5.8331412391952755\n",
      "epoch is:  124  Avg. loss (training data):  -6.453838861109553  Avg. loss (validation data):  -8.231780658931955\n",
      "epoch is:  125  Avg. loss (training data):  -5.663099770169989  Avg. loss (validation data):  -5.579501899017484\n",
      "epoch is:  126  Avg. loss (training data):  -6.643470626027318  Avg. loss (validation data):  -4.6445462170931275\n",
      "epoch is:  127  Avg. loss (training data):  -6.517538901274282  Avg. loss (validation data):  -5.222327412377446\n",
      "epoch is:  128  Avg. loss (training data):  -5.479794808517423  Avg. loss (validation data):  -7.889790209621274\n",
      "epoch is:  129  Avg. loss (training data):  -5.6637829961875745  Avg. loss (validation data):  -5.172281702079347\n",
      "epoch is:  130  Avg. loss (training data):  -5.720861672340684  Avg. loss (validation data):  -7.019789511317035\n",
      "epoch is:  131  Avg. loss (training data):  -5.625787595491124  Avg. loss (validation data):  -8.015675710108928\n",
      "epoch is:  132  Avg. loss (training data):  -5.7445474103232606  Avg. loss (validation data):  -5.624660198025749\n",
      "epoch is:  133  Avg. loss (training data):  -5.466673786227204  Avg. loss (validation data):  -6.286977072747107\n",
      "epoch is:  134  Avg. loss (training data):  -5.429544538399602  Avg. loss (validation data):  -4.910650344467588\n",
      "epoch is:  135  Avg. loss (training data):  -5.775353729209131  Avg. loss (validation data):  -4.7178874189863125\n",
      "epoch is:  136  Avg. loss (training data):  -5.439125303006547  Avg. loss (validation data):  -4.690569092467443\n",
      "epoch is:  137  Avg. loss (training data):  -5.719268776939382  Avg. loss (validation data):  -4.949057043036013\n",
      "epoch is:  138  Avg. loss (training data):  -5.447813854668275  Avg. loss (validation data):  -4.650162818782232\n",
      "epoch is:  139  Avg. loss (training data):  -6.27887114536847  Avg. loss (validation data):  -8.074902330787095\n",
      "epoch is:  140  Avg. loss (training data):  -5.9711910439978375  Avg. loss (validation data):  -8.016529033306366\n",
      "epoch is:  141  Avg. loss (training data):  -6.420409081867016  Avg. loss (validation data):  -4.704403064479876\n",
      "epoch is:  142  Avg. loss (training data):  -5.782423659577932  Avg. loss (validation data):  -5.485843209645189\n",
      "epoch is:  143  Avg. loss (training data):  -5.904929519890736  Avg. loss (validation data):  -5.576694175153347\n",
      "epoch is:  144  Avg. loss (training data):  -6.212999575812591  Avg. loss (validation data):  -6.923238610956524\n",
      "epoch is:  145  Avg. loss (training data):  -6.156521388518066  Avg. loss (validation data):  -20.694815569212327\n",
      "epoch is:  146  Avg. loss (training data):  -5.524247940669319  Avg. loss (validation data):  -5.166119849998511\n",
      "epoch is:  147  Avg. loss (training data):  -5.589931768410695  Avg. loss (validation data):  -4.630674570463656\n",
      "epoch is:  148  Avg. loss (training data):  -5.910951870234891  Avg. loss (validation data):  -8.06109695710129\n",
      "epoch is:  149  Avg. loss (training data):  -6.090675579016516  Avg. loss (validation data):  -5.866284284826407\n",
      "epoch is:  150  Avg. loss (training data):  -5.893569605038979  Avg. loss (validation data):  -4.857756276553884\n",
      "epoch is:  151  Avg. loss (training data):  -6.023386766346717  Avg. loss (validation data):  -4.732803941348183\n",
      "epoch is:  152  Avg. loss (training data):  -5.66194328880226  Avg. loss (validation data):  -4.578995162949218\n",
      "epoch is:  153  Avg. loss (training data):  -5.591428267437677  Avg. loss (validation data):  -5.015148025605817\n",
      "epoch is:  154  Avg. loss (training data):  -6.1539945562252125  Avg. loss (validation data):  -4.853661476175055\n",
      "epoch is:  155  Avg. loss (training data):  -6.276680982542711  Avg. loss (validation data):  -5.2172652249784335\n",
      "epoch is:  156  Avg. loss (training data):  -6.409532521339943  Avg. loss (validation data):  -5.757978165528341\n",
      "epoch is:  157  Avg. loss (training data):  -5.3699860473091245  Avg. loss (validation data):  -4.839299005612857\n",
      "epoch is:  158  Avg. loss (training data):  -5.950000892040823  Avg. loss (validation data):  -7.796438125471894\n",
      "epoch is:  159  Avg. loss (training data):  -5.929931790386592  Avg. loss (validation data):  -4.869814431714993\n",
      "epoch is:  160  Avg. loss (training data):  -5.993091305162697  Avg. loss (validation data):  -5.449093344178223\n",
      "epoch is:  161  Avg. loss (training data):  -5.417561468893749  Avg. loss (validation data):  -12.322386602295653\n",
      "epoch is:  162  Avg. loss (training data):  -5.685157517166728  Avg. loss (validation data):  -6.798850923566941\n",
      "epoch is:  163  Avg. loss (training data):  -5.78099866811793  Avg. loss (validation data):  -4.5012141247196285\n",
      "epoch is:  164  Avg. loss (training data):  -5.791717600062243  Avg. loss (validation data):  -5.477837160803527\n",
      "epoch is:  165  Avg. loss (training data):  -5.519704974180249  Avg. loss (validation data):  -6.5377521373361835\n",
      "epoch is:  166  Avg. loss (training data):  -6.504976868337073  Avg. loss (validation data):  -6.373255987693085\n",
      "epoch is:  167  Avg. loss (training data):  -6.243605694470708  Avg. loss (validation data):  -11.235170502791565\n",
      "epoch is:  168  Avg. loss (training data):  -5.938628969515985  Avg. loss (validation data):  -5.026872553443189\n",
      "epoch is:  169  Avg. loss (training data):  -5.653446076899711  Avg. loss (validation data):  -4.923228796641581\n",
      "epoch is:  170  Avg. loss (training data):  -5.91176117635402  Avg. loss (validation data):  -5.201193579995339\n",
      "epoch is:  171  Avg. loss (training data):  -5.88333874808303  Avg. loss (validation data):  -5.138386201224132\n",
      "epoch is:  172  Avg. loss (training data):  -5.906951627021985  Avg. loss (validation data):  -5.594113839540078\n",
      "epoch is:  173  Avg. loss (training data):  -5.892593164293316  Avg. loss (validation data):  -5.547203120548097\n",
      "epoch is:  174  Avg. loss (training data):  -5.770128731177807  Avg. loss (validation data):  -7.127298985940661\n",
      "epoch is:  175  Avg. loss (training data):  -5.847268773825744  Avg. loss (validation data):  -11.804670395859972\n",
      "epoch is:  176  Avg. loss (training data):  -6.279284301549625  Avg. loss (validation data):  -4.67094429167905\n",
      "epoch is:  177  Avg. loss (training data):  -5.673050507195617  Avg. loss (validation data):  -4.718868446089642\n",
      "epoch is:  178  Avg. loss (training data):  -5.433639099042406  Avg. loss (validation data):  -4.5962071225821735\n",
      "epoch is:  179  Avg. loss (training data):  -5.8120220693975115  Avg. loss (validation data):  -4.771090911219853\n",
      "epoch is:  180  Avg. loss (training data):  -5.432184730284325  Avg. loss (validation data):  -5.518851658137995\n",
      "epoch is:  181  Avg. loss (training data):  -6.034250231566608  Avg. loss (validation data):  -5.159039818966273\n",
      "epoch is:  182  Avg. loss (training data):  -5.951727807017961  Avg. loss (validation data):  -4.755636838875803\n",
      "epoch is:  183  Avg. loss (training data):  -5.999863292533154  Avg. loss (validation data):  -7.9032844716804\n",
      "epoch is:  184  Avg. loss (training data):  -5.797493265142233  Avg. loss (validation data):  -5.263689035575774\n",
      "epoch is:  185  Avg. loss (training data):  -5.7336216177692885  Avg. loss (validation data):  -14.826811495230658\n",
      "epoch is:  186  Avg. loss (training data):  -5.872294955576496  Avg. loss (validation data):  -5.011361666069531\n",
      "epoch is:  187  Avg. loss (training data):  -5.818340100039315  Avg. loss (validation data):  -8.045581970002324\n",
      "epoch is:  188  Avg. loss (training data):  -5.849594035070377  Avg. loss (validation data):  -6.95907047412726\n",
      "epoch is:  189  Avg. loss (training data):  -5.69731669894155  Avg. loss (validation data):  -4.687824378388255\n",
      "epoch is:  190  Avg. loss (training data):  -7.708038569324055  Avg. loss (validation data):  -7.344824729126963\n",
      "epoch is:  191  Avg. loss (training data):  -6.00367660641028  Avg. loss (validation data):  -5.963941583189305\n",
      "epoch is:  192  Avg. loss (training data):  -6.150173125747552  Avg. loss (validation data):  -5.001841442102708\n",
      "epoch is:  193  Avg. loss (training data):  -6.038567736062014  Avg. loss (validation data):  -9.503736443811318\n",
      "epoch is:  194  Avg. loss (training data):  -5.683443571157226  Avg. loss (validation data):  -4.931292058258996\n",
      "epoch is:  195  Avg. loss (training data):  -5.61345230103032  Avg. loss (validation data):  -6.595370194096516\n",
      "epoch is:  196  Avg. loss (training data):  -6.262452343313846  Avg. loss (validation data):  -5.419943459509431\n",
      "epoch is:  197  Avg. loss (training data):  -6.138361069802123  Avg. loss (validation data):  -4.909617348546084\n",
      "epoch is:  198  Avg. loss (training data):  -5.591088629920736  Avg. loss (validation data):  -4.74762314641175\n",
      "epoch is:  199  Avg. loss (training data):  -5.954694683871618  Avg. loss (validation data):  -9.62098499877049\n",
      "epoch is:  200  Avg. loss (training data):  -7.038734800599388  Avg. loss (validation data):  -5.54527293476177\n",
      "epoch is:  201  Avg. loss (training data):  -6.2635912390415065  Avg. loss (validation data):  -4.85863850050171\n",
      "epoch is:  202  Avg. loss (training data):  -6.233464317488849  Avg. loss (validation data):  -6.247028369098707\n",
      "epoch is:  203  Avg. loss (training data):  -6.0414923170952886  Avg. loss (validation data):  -5.189813783078381\n",
      "epoch is:  204  Avg. loss (training data):  -6.022983628130577  Avg. loss (validation data):  -7.121084394967022\n",
      "epoch is:  205  Avg. loss (training data):  -5.525902237334577  Avg. loss (validation data):  -4.9323563693020605\n",
      "epoch is:  206  Avg. loss (training data):  -5.653127959339548  Avg. loss (validation data):  -4.528015636366054\n",
      "epoch is:  207  Avg. loss (training data):  -5.7989981376327435  Avg. loss (validation data):  -7.888329201989192\n",
      "epoch is:  208  Avg. loss (training data):  -5.813906899746766  Avg. loss (validation data):  -4.800893800668283\n",
      "epoch is:  209  Avg. loss (training data):  -5.784507563325036  Avg. loss (validation data):  -5.31569715167389\n",
      "epoch is:  210  Avg. loss (training data):  -6.007852241264322  Avg. loss (validation data):  -5.9970115525902825\n",
      "epoch is:  211  Avg. loss (training data):  -6.302845823265854  Avg. loss (validation data):  -5.046751006283175\n",
      "epoch is:  212  Avg. loss (training data):  -5.478269470445807  Avg. loss (validation data):  -4.937995079383584\n",
      "epoch is:  213  Avg. loss (training data):  -6.844204516194809  Avg. loss (validation data):  -4.930026144668461\n",
      "epoch is:  214  Avg. loss (training data):  -5.554939452212548  Avg. loss (validation data):  -4.690417257610197\n",
      "epoch is:  215  Avg. loss (training data):  -6.728827918899941  Avg. loss (validation data):  -6.609227250408132\n",
      "epoch is:  216  Avg. loss (training data):  -5.52782660101543  Avg. loss (validation data):  -5.967406825046789\n",
      "epoch is:  217  Avg. loss (training data):  -5.827134951962067  Avg. loss (validation data):  -4.548970281076888\n",
      "epoch is:  218  Avg. loss (training data):  -5.720208370011277  Avg. loss (validation data):  -8.133221323123744\n",
      "epoch is:  219  Avg. loss (training data):  -5.796286908957233  Avg. loss (validation data):  -4.9937263947422155\n",
      "epoch is:  220  Avg. loss (training data):  -6.473997866924578  Avg. loss (validation data):  -5.572155801684915\n",
      "epoch is:  221  Avg. loss (training data):  -6.0702063039918945  Avg. loss (validation data):  -5.624166613887063\n",
      "epoch is:  222  Avg. loss (training data):  -6.105622088497894  Avg. loss (validation data):  -4.680027685536655\n",
      "epoch is:  223  Avg. loss (training data):  -5.647156191130578  Avg. loss (validation data):  -4.744271544016944\n",
      "epoch is:  224  Avg. loss (training data):  -5.9304244019275885  Avg. loss (validation data):  -4.72406028482458\n",
      "epoch is:  225  Avg. loss (training data):  -5.826445341837542  Avg. loss (validation data):  -4.727217387670884\n",
      "epoch is:  226  Avg. loss (training data):  -5.901726992079476  Avg. loss (validation data):  -5.886773196890787\n",
      "epoch is:  227  Avg. loss (training data):  -6.407354368884056  Avg. loss (validation data):  -4.741440308538472\n",
      "epoch is:  228  Avg. loss (training data):  -5.6982942201287665  Avg. loss (validation data):  -6.914345750870282\n",
      "epoch is:  229  Avg. loss (training data):  -5.716328619896408  Avg. loss (validation data):  -4.924437279946595\n",
      "epoch is:  230  Avg. loss (training data):  -5.438928624995296  Avg. loss (validation data):  -5.0461399533184865\n",
      "epoch is:  231  Avg. loss (training data):  -5.7042374830273195  Avg. loss (validation data):  -5.551511224783138\n",
      "epoch is:  232  Avg. loss (training data):  -5.48833838910559  Avg. loss (validation data):  -10.769059156126534\n",
      "epoch is:  233  Avg. loss (training data):  -5.701080928808012  Avg. loss (validation data):  -5.33151519421655\n",
      "epoch is:  234  Avg. loss (training data):  -5.599541961810354  Avg. loss (validation data):  -5.158194087980599\n",
      "epoch is:  235  Avg. loss (training data):  -5.738050563305976  Avg. loss (validation data):  -6.9445529394233345\n",
      "epoch is:  236  Avg. loss (training data):  -6.146833125662405  Avg. loss (validation data):  -5.841812921198753\n",
      "epoch is:  237  Avg. loss (training data):  -5.574726135652709  Avg. loss (validation data):  -7.381828565994176\n",
      "epoch is:  238  Avg. loss (training data):  -6.030527510866181  Avg. loss (validation data):  -4.753509748454194\n",
      "epoch is:  239  Avg. loss (training data):  -5.727015194840729  Avg. loss (validation data):  -5.209480351774721\n",
      "epoch is:  240  Avg. loss (training data):  -6.395581164314148  Avg. loss (validation data):  -4.686810489628257\n",
      "epoch is:  241  Avg. loss (training data):  -6.293839904797386  Avg. loss (validation data):  -9.314529081978108\n",
      "epoch is:  242  Avg. loss (training data):  -5.297546033869667  Avg. loss (validation data):  -4.971237940674103\n",
      "epoch is:  243  Avg. loss (training data):  -5.846196127065191  Avg. loss (validation data):  -4.7737484838836375\n",
      "epoch is:  244  Avg. loss (training data):  -5.495310406360428  Avg. loss (validation data):  -4.819183546511138\n",
      "epoch is:  245  Avg. loss (training data):  -5.924299935059472  Avg. loss (validation data):  -5.225053269510106\n",
      "epoch is:  246  Avg. loss (training data):  -5.4500542345707395  Avg. loss (validation data):  -5.93131201710367\n",
      "epoch is:  247  Avg. loss (training data):  -6.83219908158406  Avg. loss (validation data):  -9.244035037959536\n",
      "epoch is:  248  Avg. loss (training data):  -5.621661980426299  Avg. loss (validation data):  -4.868421335842172\n",
      "epoch is:  249  Avg. loss (training data):  -5.568514760033635  Avg. loss (validation data):  -4.852259388205696\n",
      "epoch is:  250  Avg. loss (training data):  -5.53315521791375  Avg. loss (validation data):  -5.193747522255748\n",
      "epoch is:  251  Avg. loss (training data):  -5.894255336469605  Avg. loss (validation data):  -4.834948472506381\n",
      "epoch is:  252  Avg. loss (training data):  -5.998008171749895  Avg. loss (validation data):  -4.913297183891991\n",
      "epoch is:  253  Avg. loss (training data):  -5.909112122545212  Avg. loss (validation data):  -5.178801414011944\n",
      "epoch is:  254  Avg. loss (training data):  -6.449441599458166  Avg. loss (validation data):  -5.248671387531161\n",
      "epoch is:  255  Avg. loss (training data):  -5.722647210570495  Avg. loss (validation data):  -8.434492779901378\n",
      "epoch is:  256  Avg. loss (training data):  -5.4178439823101705  Avg. loss (validation data):  -4.635673196202075\n",
      "epoch is:  257  Avg. loss (training data):  -5.7590684608904885  Avg. loss (validation data):  -9.53883996840173\n",
      "epoch is:  258  Avg. loss (training data):  -5.861702912055556  Avg. loss (validation data):  -6.927518012164766\n",
      "epoch is:  259  Avg. loss (training data):  -5.44506176782118  Avg. loss (validation data):  -5.192236124722998\n",
      "epoch is:  260  Avg. loss (training data):  -5.546194865232772  Avg. loss (validation data):  -4.4430064988842615\n",
      "epoch is:  261  Avg. loss (training data):  -5.605802342626164  Avg. loss (validation data):  -5.2439053457791776\n",
      "epoch is:  262  Avg. loss (training data):  -5.7302215823773395  Avg. loss (validation data):  -5.279956943268376\n",
      "epoch is:  263  Avg. loss (training data):  -5.429732340968688  Avg. loss (validation data):  -5.826479989812691\n",
      "epoch is:  264  Avg. loss (training data):  -6.005287592100764  Avg. loss (validation data):  -5.669609475247105\n",
      "epoch is:  265  Avg. loss (training data):  -6.399515173807616  Avg. loss (validation data):  -4.81634707651685\n",
      "epoch is:  266  Avg. loss (training data):  -5.730360230874602  Avg. loss (validation data):  -11.433156308639509\n",
      "epoch is:  267  Avg. loss (training data):  -5.613673332241644  Avg. loss (validation data):  -6.450334722177191\n",
      "epoch is:  268  Avg. loss (training data):  -5.7747062195302306  Avg. loss (validation data):  -4.663101845989695\n",
      "epoch is:  269  Avg. loss (training data):  -5.463950922677429  Avg. loss (validation data):  -4.789374497451081\n",
      "epoch is:  270  Avg. loss (training data):  -6.337976165530246  Avg. loss (validation data):  -11.12156871687453\n",
      "epoch is:  271  Avg. loss (training data):  -5.649275079868018  Avg. loss (validation data):  -7.117985817118865\n",
      "epoch is:  272  Avg. loss (training data):  -7.2523081251612425  Avg. loss (validation data):  -5.2261643233816315\n",
      "epoch is:  273  Avg. loss (training data):  -5.519031918875737  Avg. loss (validation data):  -5.6311726044389205\n",
      "epoch is:  274  Avg. loss (training data):  -6.1483526155895  Avg. loss (validation data):  -5.31111457008907\n",
      "epoch is:  275  Avg. loss (training data):  -5.504314393744681  Avg. loss (validation data):  -4.952768829184419\n",
      "epoch is:  276  Avg. loss (training data):  -5.902484509309765  Avg. loss (validation data):  -6.229408582964205\n",
      "epoch is:  277  Avg. loss (training data):  -5.81979981401387  Avg. loss (validation data):  -4.808173496699202\n",
      "epoch is:  278  Avg. loss (training data):  -5.716679946578278  Avg. loss (validation data):  -5.350614021362792\n",
      "epoch is:  279  Avg. loss (training data):  -5.485927123776255  Avg. loss (validation data):  -4.623049836614283\n",
      "epoch is:  280  Avg. loss (training data):  -5.647499561340476  Avg. loss (validation data):  -5.810386145471639\n",
      "epoch is:  281  Avg. loss (training data):  -5.753463322472932  Avg. loss (validation data):  -7.9354080642805895\n",
      "epoch is:  282  Avg. loss (training data):  -5.860578339465711  Avg. loss (validation data):  -4.906362379679743\n",
      "epoch is:  283  Avg. loss (training data):  -5.623449587367883  Avg. loss (validation data):  -4.577602889492973\n",
      "epoch is:  284  Avg. loss (training data):  -6.619503768878485  Avg. loss (validation data):  -7.099114132532837\n",
      "epoch is:  285  Avg. loss (training data):  -5.549411678920469  Avg. loss (validation data):  -5.712882574590344\n",
      "epoch is:  286  Avg. loss (training data):  -5.549688544750253  Avg. loss (validation data):  -5.023155270116286\n",
      "epoch is:  287  Avg. loss (training data):  -6.68415343269351  Avg. loss (validation data):  -5.752841174846677\n",
      "epoch is:  288  Avg. loss (training data):  -6.37379534743483  Avg. loss (validation data):  -4.801296044980309\n",
      "epoch is:  289  Avg. loss (training data):  -6.011703622164083  Avg. loss (validation data):  -9.439730131058173\n",
      "epoch is:  290  Avg. loss (training data):  -5.708310318283148  Avg. loss (validation data):  -5.298086511138968\n",
      "epoch is:  291  Avg. loss (training data):  -5.910771999355753  Avg. loss (validation data):  -7.203770676539739\n",
      "epoch is:  292  Avg. loss (training data):  -5.67504345240355  Avg. loss (validation data):  -6.771575473308529\n",
      "epoch is:  293  Avg. loss (training data):  -5.836616060707524  Avg. loss (validation data):  -6.820552319730941\n",
      "epoch is:  294  Avg. loss (training data):  -5.551363142952942  Avg. loss (validation data):  -4.684286129457235\n",
      "epoch is:  295  Avg. loss (training data):  -5.495708757714332  Avg. loss (validation data):  -6.47540804301902\n",
      "epoch is:  296  Avg. loss (training data):  -7.005898142423441  Avg. loss (validation data):  -8.675260588620946\n",
      "epoch is:  297  Avg. loss (training data):  -5.461592295428307  Avg. loss (validation data):  -4.705625140601353\n",
      "epoch is:  298  Avg. loss (training data):  -6.0121132014459695  Avg. loss (validation data):  -5.248677805467211\n",
      "epoch is:  299  Avg. loss (training data):  -5.443302378843751  Avg. loss (validation data):  -5.256232390590192\n",
      "epoch is:  300  Avg. loss (training data):  -5.956851229387284  Avg. loss (validation data):  -7.4280850577815585\n",
      "epoch is:  301  Avg. loss (training data):  -5.52188658018302  Avg. loss (validation data):  -4.990442929272027\n",
      "epoch is:  302  Avg. loss (training data):  -5.59972741636455  Avg. loss (validation data):  -4.87255222748709\n",
      "epoch is:  303  Avg. loss (training data):  -5.8627236511012875  Avg. loss (validation data):  -6.390319744139072\n",
      "epoch is:  304  Avg. loss (training data):  -5.943803210448194  Avg. loss (validation data):  -5.343432286578766\n",
      "epoch is:  305  Avg. loss (training data):  -5.771294135515396  Avg. loss (validation data):  -5.486583813276527\n",
      "epoch is:  306  Avg. loss (training data):  -5.985548620183738  Avg. loss (validation data):  -5.2121755313442355\n",
      "epoch is:  307  Avg. loss (training data):  -5.43165451429337  Avg. loss (validation data):  -6.40066085786773\n",
      "epoch is:  308  Avg. loss (training data):  -6.303683233937001  Avg. loss (validation data):  -4.929517427573067\n",
      "epoch is:  309  Avg. loss (training data):  -5.541590547826812  Avg. loss (validation data):  -7.2665826388687735\n",
      "epoch is:  310  Avg. loss (training data):  -5.597473018785918  Avg. loss (validation data):  -4.983750247010971\n",
      "epoch is:  311  Avg. loss (training data):  -5.445793769243414  Avg. loss (validation data):  -10.100069825256627\n",
      "epoch is:  312  Avg. loss (training data):  -5.886923822761077  Avg. loss (validation data):  -4.95989951870637\n",
      "epoch is:  313  Avg. loss (training data):  -6.37771659947459  Avg. loss (validation data):  -4.921902697142607\n",
      "epoch is:  314  Avg. loss (training data):  -6.189058639824882  Avg. loss (validation data):  -6.544140829127258\n",
      "epoch is:  315  Avg. loss (training data):  -7.073565785063462  Avg. loss (validation data):  -5.0560429163141025\n",
      "epoch is:  316  Avg. loss (training data):  -5.744534004306804  Avg. loss (validation data):  -5.882851967003805\n",
      "epoch is:  317  Avg. loss (training data):  -5.848470796721033  Avg. loss (validation data):  -10.096927567640892\n",
      "epoch is:  318  Avg. loss (training data):  -5.548039898242699  Avg. loss (validation data):  -8.002159213303361\n",
      "epoch is:  319  Avg. loss (training data):  -5.789712785995356  Avg. loss (validation data):  -4.460407976161323\n",
      "epoch is:  320  Avg. loss (training data):  -6.408320516903633  Avg. loss (validation data):  -5.034208086829375\n",
      "epoch is:  321  Avg. loss (training data):  -5.709571842813788  Avg. loss (validation data):  -4.779274568215038\n",
      "epoch is:  322  Avg. loss (training data):  -5.882830528147531  Avg. loss (validation data):  -4.721383841687312\n",
      "epoch is:  323  Avg. loss (training data):  -6.350896686978782  Avg. loss (validation data):  -4.542685363840594\n",
      "epoch is:  324  Avg. loss (training data):  -6.224954854945423  Avg. loss (validation data):  -6.349461429146051\n",
      "epoch is:  325  Avg. loss (training data):  -5.329184828704993  Avg. loss (validation data):  -4.428112242406906\n",
      "epoch is:  326  Avg. loss (training data):  -5.6911358358258575  Avg. loss (validation data):  -5.542175269874212\n",
      "epoch is:  327  Avg. loss (training data):  -5.431518883075429  Avg. loss (validation data):  -6.516827326424683\n",
      "epoch is:  328  Avg. loss (training data):  -5.2850441329302615  Avg. loss (validation data):  -7.085410431789052\n",
      "epoch is:  329  Avg. loss (training data):  -5.49324009288936  Avg. loss (validation data):  -4.657834814956828\n",
      "epoch is:  330  Avg. loss (training data):  -5.848821586323653  Avg. loss (validation data):  -4.8267973614543305\n",
      "epoch is:  331  Avg. loss (training data):  -6.197157007624517  Avg. loss (validation data):  -5.091439509969719\n",
      "epoch is:  332  Avg. loss (training data):  -5.7874366073657795  Avg. loss (validation data):  -8.36464298825866\n",
      "epoch is:  333  Avg. loss (training data):  -5.755847154022019  Avg. loss (validation data):  -5.394013281627764\n",
      "epoch is:  334  Avg. loss (training data):  -5.887389903699841  Avg. loss (validation data):  -6.152914043678406\n",
      "epoch is:  335  Avg. loss (training data):  -5.325292062644702  Avg. loss (validation data):  -5.297982425233711\n",
      "epoch is:  336  Avg. loss (training data):  -6.0026242768317255  Avg. loss (validation data):  -5.936915649243761\n",
      "epoch is:  337  Avg. loss (training data):  -5.660633212596952  Avg. loss (validation data):  -7.220471989750065\n",
      "epoch is:  338  Avg. loss (training data):  -5.790874224384152  Avg. loss (validation data):  -4.816800553652196\n",
      "epoch is:  339  Avg. loss (training data):  -5.462330914277564  Avg. loss (validation data):  -5.046267331632955\n",
      "epoch is:  340  Avg. loss (training data):  -6.548611882604911  Avg. loss (validation data):  -8.014562715967104\n",
      "epoch is:  341  Avg. loss (training data):  -5.807503080129911  Avg. loss (validation data):  -6.775994536805383\n",
      "epoch is:  342  Avg. loss (training data):  -5.387477161540573  Avg. loss (validation data):  -5.48785454651014\n",
      "epoch is:  343  Avg. loss (training data):  -6.259378995766148  Avg. loss (validation data):  -5.505857358166361\n",
      "epoch is:  344  Avg. loss (training data):  -5.9250613967893715  Avg. loss (validation data):  -4.98394414910724\n",
      "epoch is:  345  Avg. loss (training data):  -5.921601801356089  Avg. loss (validation data):  -5.50443608138493\n",
      "epoch is:  346  Avg. loss (training data):  -5.540792332608187  Avg. loss (validation data):  -5.291822054368667\n",
      "epoch is:  347  Avg. loss (training data):  -5.656800374763335  Avg. loss (validation data):  -4.944456682298033\n",
      "epoch is:  348  Avg. loss (training data):  -5.965353022930787  Avg. loss (validation data):  -4.673560860545233\n",
      "epoch is:  349  Avg. loss (training data):  -6.086514819373491  Avg. loss (validation data):  -5.276998405306381\n",
      "epoch is:  350  Avg. loss (training data):  -6.2924933976635415  Avg. loss (validation data):  -5.876536225511635\n",
      "epoch is:  351  Avg. loss (training data):  -6.433445312435827  Avg. loss (validation data):  -5.143619792852837\n",
      "epoch is:  352  Avg. loss (training data):  -6.042044351581935  Avg. loss (validation data):  -9.873194995773861\n",
      "epoch is:  353  Avg. loss (training data):  -5.884522682399085  Avg. loss (validation data):  -5.105553901425588\n",
      "epoch is:  354  Avg. loss (training data):  -6.675852129289797  Avg. loss (validation data):  -7.59441141573488\n",
      "epoch is:  355  Avg. loss (training data):  -5.97237081792019  Avg. loss (validation data):  -5.316927454677308\n",
      "epoch is:  356  Avg. loss (training data):  -5.604029081580775  Avg. loss (validation data):  -4.774974090242446\n",
      "epoch is:  357  Avg. loss (training data):  -5.608726192014636  Avg. loss (validation data):  -8.667358202883117\n",
      "epoch is:  358  Avg. loss (training data):  -5.978063553640497  Avg. loss (validation data):  -4.967880921463714\n",
      "epoch is:  359  Avg. loss (training data):  -5.506485815785779  Avg. loss (validation data):  -5.511655007354022\n",
      "epoch is:  360  Avg. loss (training data):  -6.626303704912448  Avg. loss (validation data):  -4.985031506495528\n",
      "epoch is:  361  Avg. loss (training data):  -5.65693971164775  Avg. loss (validation data):  -7.193749240692781\n",
      "epoch is:  362  Avg. loss (training data):  -5.86622812593883  Avg. loss (validation data):  -17.382934806683547\n",
      "epoch is:  363  Avg. loss (training data):  -5.661969915283485  Avg. loss (validation data):  -7.436583476903771\n",
      "epoch is:  364  Avg. loss (training data):  -5.843271787286305  Avg. loss (validation data):  -4.754290814824559\n",
      "epoch is:  365  Avg. loss (training data):  -6.266206110186534  Avg. loss (validation data):  -5.814555234745969\n",
      "epoch is:  366  Avg. loss (training data):  -6.371046715751499  Avg. loss (validation data):  -4.7883203205271965\n",
      "epoch is:  367  Avg. loss (training data):  -5.679278245237125  Avg. loss (validation data):  -8.494801895032952\n",
      "epoch is:  368  Avg. loss (training data):  -5.428370839542933  Avg. loss (validation data):  -5.465266938817709\n",
      "epoch is:  369  Avg. loss (training data):  -5.456267685174977  Avg. loss (validation data):  -8.414568039059525\n",
      "epoch is:  370  Avg. loss (training data):  -5.682208087994102  Avg. loss (validation data):  -5.788061250268197\n",
      "epoch is:  371  Avg. loss (training data):  -5.633263483000575  Avg. loss (validation data):  -10.49196692742179\n",
      "epoch is:  372  Avg. loss (training data):  -5.552185122589829  Avg. loss (validation data):  -6.2641885921780585\n",
      "epoch is:  373  Avg. loss (training data):  -5.590418428243868  Avg. loss (validation data):  -5.495176430610327\n",
      "epoch is:  374  Avg. loss (training data):  -5.824928815942137  Avg. loss (validation data):  -4.6184461172749325\n",
      "epoch is:  375  Avg. loss (training data):  -5.92126039251297  Avg. loss (validation data):  -9.366178654248941\n",
      "epoch is:  376  Avg. loss (training data):  -6.301274927067908  Avg. loss (validation data):  -5.134838450869097\n",
      "epoch is:  377  Avg. loss (training data):  -6.004895966611148  Avg. loss (validation data):  -4.472540859072613\n",
      "epoch is:  378  Avg. loss (training data):  -5.855449219910087  Avg. loss (validation data):  -5.474187049724672\n",
      "epoch is:  379  Avg. loss (training data):  -5.815299924107509  Avg. loss (validation data):  -12.212650012942694\n",
      "epoch is:  380  Avg. loss (training data):  -5.8455851272786  Avg. loss (validation data):  -7.499574933863654\n",
      "epoch is:  381  Avg. loss (training data):  -5.651871945066115  Avg. loss (validation data):  -5.96861203983899\n",
      "epoch is:  382  Avg. loss (training data):  -5.815108252699994  Avg. loss (validation data):  -5.158784519557578\n",
      "epoch is:  383  Avg. loss (training data):  -5.553886776780647  Avg. loss (validation data):  -4.909421003809311\n",
      "epoch is:  384  Avg. loss (training data):  -5.409567094068901  Avg. loss (validation data):  -5.118363629175355\n",
      "epoch is:  385  Avg. loss (training data):  -5.338528568300319  Avg. loss (validation data):  -6.1208365541358365\n",
      "epoch is:  386  Avg. loss (training data):  -5.408927474859805  Avg. loss (validation data):  -7.396634661876028\n",
      "epoch is:  387  Avg. loss (training data):  -5.806409023569521  Avg. loss (validation data):  -5.192224658461138\n",
      "epoch is:  388  Avg. loss (training data):  -5.430916581150444  Avg. loss (validation data):  -5.376134567186637\n",
      "epoch is:  389  Avg. loss (training data):  -7.240603204734549  Avg. loss (validation data):  -4.903951692872403\n",
      "epoch is:  390  Avg. loss (training data):  -5.609413410008716  Avg. loss (validation data):  -4.873871981075474\n",
      "epoch is:  391  Avg. loss (training data):  -6.2116060375053905  Avg. loss (validation data):  -5.186303290945778\n",
      "epoch is:  392  Avg. loss (training data):  -5.394163977979453  Avg. loss (validation data):  -5.694015016648379\n",
      "epoch is:  393  Avg. loss (training data):  -5.9963240451550375  Avg. loss (validation data):  -7.170763344579066\n",
      "epoch is:  394  Avg. loss (training data):  -6.0520637450372705  Avg. loss (validation data):  -5.93929252820506\n",
      "epoch is:  395  Avg. loss (training data):  -5.417449199495734  Avg. loss (validation data):  -4.514481403505232\n",
      "epoch is:  396  Avg. loss (training data):  -5.6460972119707655  Avg. loss (validation data):  -5.318082917622087\n",
      "epoch is:  397  Avg. loss (training data):  -5.510522834684102  Avg. loss (validation data):  -5.521947521710341\n",
      "epoch is:  398  Avg. loss (training data):  -5.677604249405892  Avg. loss (validation data):  -4.895320590611839\n",
      "epoch is:  399  Avg. loss (training data):  -5.526879695278506  Avg. loss (validation data):  -4.645938700855541\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "model = model2\n",
    "N_train = len(dataset_train)\n",
    "N_val = len(dataset_test)\n",
    "\n",
    "avg_loss_per_epoch_train = []\n",
    "avg_loss_per_epoch_val = []\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    model.train() # Put the model in \"training mode\"\n",
    "    total_loss = []\n",
    "\n",
    "    for x_batch, y_batch in dataloader_train:\n",
    "\n",
    "    # These lines move the current batch of data to the GPU, if we're using the GPU.\n",
    "\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "# Each item in the current batch is fed into the neural network\n",
    "        avg_loss_for_this_batch = criterion(outputs, y_batch)\n",
    "\n",
    "        model.zero_grad() # Wipe the slate clean, preparing for a new gradient calculation\n",
    "        avg_loss_for_this_batch.backward() # Compute a gradient using the current batch\n",
    "                                        # A more logical name for this method might be \"compute_gradient\"\n",
    "\n",
    "    # Now we take one step of stochastic gradient descent or Adam.\n",
    "    # (or whichever optimization algorithm we're using)\n",
    "    # This short line of code updates all of the weights in our neural network.\n",
    "        optimizer.step() \n",
    "\n",
    "    # We can see how powerful PyTorch is now.  In the previous two lines of code,\n",
    "    # PyTorch did a very complicated gradient calculation for us,\n",
    "    # shielding us from the details.\n",
    "    # Then PyTorch updated the neural network weights, again shielding us from the details.\n",
    "        outputs = model(x_batch)\n",
    "        loss = r2_score( y_batch.detach().numpy(),outputs.detach().numpy())\n",
    "        total_loss.append(loss)\n",
    "    avg_training = np.mean(total_loss) \n",
    "\n",
    "\n",
    "    # We just finished one epoch of training.\n",
    "    # Let's check how well our model is performing on the validation dataset.\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    for x_batch, y_batch in dataloader_test:\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # This line tells PyTorch it doesn't need to worry \n",
    "                            # about computing any gradients, for the moment\n",
    "            outputs = model(x_batch)\n",
    "            outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "\n",
    "            loss = r2_score( y_batch.detach().numpy(), outputs.detach().numpy())\n",
    "            total_loss.append(loss)\n",
    "    avg = np.mean(total_loss)\n",
    "    \n",
    "    print('epoch is: ', ep, ' Avg. loss (training data): ', avg_training, ' Avg. loss (validation data): ', avg.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'project-group-6/test_kaggle.pickle'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    test_data = pickle.load(file)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "X_test = test_df.values  # Convert the relevant feature columns to a NumPy array\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float) \n",
    "pred = model(X_test_tensor)\n",
    "pred2 = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch is:  0  Avg. loss (training data):  -5.87597062573529  Avg. loss (validation data):  -5.1480358729370606\n",
      "epoch is:  1  Avg. loss (training data):  -7.104398193790626  Avg. loss (validation data):  -6.539245351049806\n",
      "epoch is:  2  Avg. loss (training data):  -6.061277516511614  Avg. loss (validation data):  -5.142361612075407\n",
      "epoch is:  3  Avg. loss (training data):  -5.283286077415467  Avg. loss (validation data):  -5.119171813029573\n",
      "epoch is:  4  Avg. loss (training data):  -6.0080451686956495  Avg. loss (validation data):  -4.574335950509266\n",
      "epoch is:  5  Avg. loss (training data):  -5.998786380114113  Avg. loss (validation data):  -8.392686706517066\n",
      "epoch is:  6  Avg. loss (training data):  -6.0970100888230965  Avg. loss (validation data):  -5.465769848880639\n",
      "epoch is:  7  Avg. loss (training data):  -5.811396625947307  Avg. loss (validation data):  -7.394546634881863\n",
      "epoch is:  8  Avg. loss (training data):  -5.915698165520176  Avg. loss (validation data):  -7.959017077130116\n",
      "epoch is:  9  Avg. loss (training data):  -6.442515127086645  Avg. loss (validation data):  -4.671961976167857\n",
      "epoch is:  10  Avg. loss (training data):  -5.753063239405818  Avg. loss (validation data):  -5.26234292407351\n",
      "epoch is:  11  Avg. loss (training data):  -5.744580258224684  Avg. loss (validation data):  -10.033596928190942\n",
      "epoch is:  12  Avg. loss (training data):  -5.7620641145929525  Avg. loss (validation data):  -4.821478383959412\n",
      "epoch is:  13  Avg. loss (training data):  -5.8037663039777305  Avg. loss (validation data):  -5.18171612658292\n",
      "epoch is:  14  Avg. loss (training data):  -6.07422020160943  Avg. loss (validation data):  -5.26898647637887\n",
      "epoch is:  15  Avg. loss (training data):  -5.645622044788406  Avg. loss (validation data):  -10.189981922547148\n",
      "epoch is:  16  Avg. loss (training data):  -6.3470801462318756  Avg. loss (validation data):  -5.783116845488961\n",
      "epoch is:  17  Avg. loss (training data):  -5.387315123391609  Avg. loss (validation data):  -4.925443171801596\n",
      "epoch is:  18  Avg. loss (training data):  -6.066053003321027  Avg. loss (validation data):  -9.387440316106522\n",
      "epoch is:  19  Avg. loss (training data):  -6.0899319018335065  Avg. loss (validation data):  -4.690897261509198\n",
      "epoch is:  20  Avg. loss (training data):  -6.63231306371195  Avg. loss (validation data):  -5.820026244461567\n",
      "epoch is:  21  Avg. loss (training data):  -5.820830351620145  Avg. loss (validation data):  -5.841750981122851\n",
      "epoch is:  22  Avg. loss (training data):  -5.884456838649811  Avg. loss (validation data):  -4.970875582619834\n",
      "epoch is:  23  Avg. loss (training data):  -5.605966265328561  Avg. loss (validation data):  -8.00562629334405\n",
      "epoch is:  24  Avg. loss (training data):  -6.586858123253274  Avg. loss (validation data):  -5.350121883641527\n",
      "epoch is:  25  Avg. loss (training data):  -5.63144029431448  Avg. loss (validation data):  -5.392526936703204\n",
      "epoch is:  26  Avg. loss (training data):  -6.234413577509778  Avg. loss (validation data):  -7.348916605280209\n",
      "epoch is:  27  Avg. loss (training data):  -5.9900511703414825  Avg. loss (validation data):  -4.905229652207887\n",
      "epoch is:  28  Avg. loss (training data):  -5.809467698425005  Avg. loss (validation data):  -7.067757541320061\n",
      "epoch is:  29  Avg. loss (training data):  -6.326943437803989  Avg. loss (validation data):  -4.8839965705473665\n",
      "epoch is:  30  Avg. loss (training data):  -5.657717580198847  Avg. loss (validation data):  -4.824237091359892\n",
      "epoch is:  31  Avg. loss (training data):  -5.4709607090091605  Avg. loss (validation data):  -13.000514371979913\n",
      "epoch is:  32  Avg. loss (training data):  -5.793866188942085  Avg. loss (validation data):  -5.093431394856434\n",
      "epoch is:  33  Avg. loss (training data):  -5.826833983720742  Avg. loss (validation data):  -5.254273442818176\n",
      "epoch is:  34  Avg. loss (training data):  -5.844710859859656  Avg. loss (validation data):  -5.151739345936262\n",
      "epoch is:  35  Avg. loss (training data):  -5.795380096715581  Avg. loss (validation data):  -4.57368953547833\n",
      "epoch is:  36  Avg. loss (training data):  -5.712754824013191  Avg. loss (validation data):  -5.1468384116152475\n",
      "epoch is:  37  Avg. loss (training data):  -5.728621693152434  Avg. loss (validation data):  -4.798353473495486\n",
      "epoch is:  38  Avg. loss (training data):  -6.879331085711057  Avg. loss (validation data):  -5.562187514892773\n",
      "epoch is:  39  Avg. loss (training data):  -5.693163511729871  Avg. loss (validation data):  -5.095362828736296\n",
      "epoch is:  40  Avg. loss (training data):  -6.335652495713777  Avg. loss (validation data):  -5.082957889269351\n",
      "epoch is:  41  Avg. loss (training data):  -6.371704168759835  Avg. loss (validation data):  -5.665137842238224\n",
      "epoch is:  42  Avg. loss (training data):  -6.346406460491752  Avg. loss (validation data):  -4.784577228651407\n",
      "epoch is:  43  Avg. loss (training data):  -5.847901526577158  Avg. loss (validation data):  -11.662888001477572\n",
      "epoch is:  44  Avg. loss (training data):  -5.609486342731717  Avg. loss (validation data):  -5.207506752385972\n",
      "epoch is:  45  Avg. loss (training data):  -6.1894501201864704  Avg. loss (validation data):  -4.757127445982363\n",
      "epoch is:  46  Avg. loss (training data):  -5.772678661478386  Avg. loss (validation data):  -4.877808107927045\n",
      "epoch is:  47  Avg. loss (training data):  -6.058193439021165  Avg. loss (validation data):  -6.242272090742566\n",
      "epoch is:  48  Avg. loss (training data):  -6.165390256389879  Avg. loss (validation data):  -4.86446022745511\n",
      "epoch is:  49  Avg. loss (training data):  -6.465228766558848  Avg. loss (validation data):  -6.853671557153975\n",
      "epoch is:  50  Avg. loss (training data):  -5.833472568509008  Avg. loss (validation data):  -5.374261286324894\n",
      "epoch is:  51  Avg. loss (training data):  -6.0285094908040415  Avg. loss (validation data):  -5.937182246183847\n",
      "epoch is:  52  Avg. loss (training data):  -5.787178542076994  Avg. loss (validation data):  -5.265500449195834\n",
      "epoch is:  53  Avg. loss (training data):  -6.028778001131968  Avg. loss (validation data):  -5.397618053880024\n",
      "epoch is:  54  Avg. loss (training data):  -5.59752575150066  Avg. loss (validation data):  -4.7402958312855725\n",
      "epoch is:  55  Avg. loss (training data):  -6.235922715024558  Avg. loss (validation data):  -4.706645012950957\n",
      "epoch is:  56  Avg. loss (training data):  -5.77565432833662  Avg. loss (validation data):  -5.512141216764405\n",
      "epoch is:  57  Avg. loss (training data):  -5.929900016149442  Avg. loss (validation data):  -4.830142713994266\n",
      "epoch is:  58  Avg. loss (training data):  -6.48840778638528  Avg. loss (validation data):  -7.184347281925811\n",
      "epoch is:  59  Avg. loss (training data):  -5.938623719455867  Avg. loss (validation data):  -6.499611632701248\n",
      "epoch is:  60  Avg. loss (training data):  -6.338463992760759  Avg. loss (validation data):  -5.689327858052609\n",
      "epoch is:  61  Avg. loss (training data):  -6.204991932508274  Avg. loss (validation data):  -5.125665800132002\n",
      "epoch is:  62  Avg. loss (training data):  -6.095495479408003  Avg. loss (validation data):  -4.913333879023357\n",
      "epoch is:  63  Avg. loss (training data):  -6.186493278710076  Avg. loss (validation data):  -4.863182838974102\n",
      "epoch is:  64  Avg. loss (training data):  -6.455778527900566  Avg. loss (validation data):  -7.3173868456363875\n",
      "epoch is:  65  Avg. loss (training data):  -6.332244560381043  Avg. loss (validation data):  -4.747240933549015\n",
      "epoch is:  66  Avg. loss (training data):  -5.897675320237079  Avg. loss (validation data):  -5.3572290493432515\n",
      "epoch is:  67  Avg. loss (training data):  -6.235917020938125  Avg. loss (validation data):  -16.230009825454104\n",
      "epoch is:  68  Avg. loss (training data):  -5.96537152828102  Avg. loss (validation data):  -5.835112635929911\n",
      "epoch is:  69  Avg. loss (training data):  -6.660344244160683  Avg. loss (validation data):  -7.357437462569595\n",
      "epoch is:  70  Avg. loss (training data):  -5.496352429882918  Avg. loss (validation data):  -4.681232190128794\n",
      "epoch is:  71  Avg. loss (training data):  -5.783205783320279  Avg. loss (validation data):  -4.9682570794342436\n",
      "epoch is:  72  Avg. loss (training data):  -5.996995843950706  Avg. loss (validation data):  -5.290999104498325\n",
      "epoch is:  73  Avg. loss (training data):  -6.325126791789804  Avg. loss (validation data):  -7.312666308060673\n",
      "epoch is:  74  Avg. loss (training data):  -5.835423764403538  Avg. loss (validation data):  -4.705818710529269\n",
      "epoch is:  75  Avg. loss (training data):  -5.739669762901086  Avg. loss (validation data):  -8.775020427215171\n",
      "epoch is:  76  Avg. loss (training data):  -6.023422336582501  Avg. loss (validation data):  -5.375455121471333\n",
      "epoch is:  77  Avg. loss (training data):  -5.8295781378773555  Avg. loss (validation data):  -6.092653871221294\n",
      "epoch is:  78  Avg. loss (training data):  -6.055348512503377  Avg. loss (validation data):  -6.8805581708501915\n",
      "epoch is:  79  Avg. loss (training data):  -6.154207892424027  Avg. loss (validation data):  -7.877744959372416\n",
      "epoch is:  80  Avg. loss (training data):  -5.598186769157251  Avg. loss (validation data):  -6.1050888039979245\n",
      "epoch is:  81  Avg. loss (training data):  -6.073177980002497  Avg. loss (validation data):  -5.144421726194089\n",
      "epoch is:  82  Avg. loss (training data):  -6.492456391067106  Avg. loss (validation data):  -5.1890925998143596\n",
      "epoch is:  83  Avg. loss (training data):  -5.985478400551987  Avg. loss (validation data):  -5.2257498148663615\n",
      "epoch is:  84  Avg. loss (training data):  -5.936042500618181  Avg. loss (validation data):  -4.727545603117554\n",
      "epoch is:  85  Avg. loss (training data):  -6.04139605710966  Avg. loss (validation data):  -10.54632151708787\n",
      "epoch is:  86  Avg. loss (training data):  -5.618495766384159  Avg. loss (validation data):  -5.17152544294153\n",
      "epoch is:  87  Avg. loss (training data):  -5.948697399414459  Avg. loss (validation data):  -6.823578723931084\n",
      "epoch is:  88  Avg. loss (training data):  -5.600763152445815  Avg. loss (validation data):  -8.815169025938058\n",
      "epoch is:  89  Avg. loss (training data):  -6.323681177939541  Avg. loss (validation data):  -4.925754799516346\n",
      "epoch is:  90  Avg. loss (training data):  -5.665903878179202  Avg. loss (validation data):  -5.42313567113169\n",
      "epoch is:  91  Avg. loss (training data):  -6.767601572230767  Avg. loss (validation data):  -4.573435150506799\n",
      "epoch is:  92  Avg. loss (training data):  -5.929413502045213  Avg. loss (validation data):  -4.902004374680169\n",
      "epoch is:  93  Avg. loss (training data):  -6.45452350597963  Avg. loss (validation data):  -5.013711679815194\n",
      "epoch is:  94  Avg. loss (training data):  -6.3631460730089255  Avg. loss (validation data):  -5.071297006637949\n",
      "epoch is:  95  Avg. loss (training data):  -5.957258379274112  Avg. loss (validation data):  -4.783349485599331\n",
      "epoch is:  96  Avg. loss (training data):  -6.175044228441524  Avg. loss (validation data):  -5.151834141774878\n",
      "epoch is:  97  Avg. loss (training data):  -5.450355498543192  Avg. loss (validation data):  -7.383086243926239\n",
      "epoch is:  98  Avg. loss (training data):  -6.483116718686569  Avg. loss (validation data):  -10.032988768334329\n",
      "epoch is:  99  Avg. loss (training data):  -6.080223398059214  Avg. loss (validation data):  -4.77766076233958\n",
      "epoch is:  100  Avg. loss (training data):  -6.199017362848403  Avg. loss (validation data):  -20.399872443854612\n",
      "epoch is:  101  Avg. loss (training data):  -5.7714133835751955  Avg. loss (validation data):  -4.928629704123419\n",
      "epoch is:  102  Avg. loss (training data):  -5.64581282965055  Avg. loss (validation data):  -6.41834178085056\n",
      "epoch is:  103  Avg. loss (training data):  -5.538312756269237  Avg. loss (validation data):  -5.076029571034551\n",
      "epoch is:  104  Avg. loss (training data):  -6.051254994266998  Avg. loss (validation data):  -8.07336265397281\n",
      "epoch is:  105  Avg. loss (training data):  -6.195538985472584  Avg. loss (validation data):  -9.573825884535156\n",
      "epoch is:  106  Avg. loss (training data):  -6.028234927329041  Avg. loss (validation data):  -4.862443639121976\n",
      "epoch is:  107  Avg. loss (training data):  -5.6973750217931185  Avg. loss (validation data):  -4.779286125709821\n",
      "epoch is:  108  Avg. loss (training data):  -6.266030596987535  Avg. loss (validation data):  -5.374020027650507\n",
      "epoch is:  109  Avg. loss (training data):  -5.673450077904189  Avg. loss (validation data):  -6.353425935851532\n",
      "epoch is:  110  Avg. loss (training data):  -5.650232933440584  Avg. loss (validation data):  -4.836172516025309\n",
      "epoch is:  111  Avg. loss (training data):  -7.067041164062784  Avg. loss (validation data):  -4.824444650423405\n",
      "epoch is:  112  Avg. loss (training data):  -6.266108111598816  Avg. loss (validation data):  -5.789385327104207\n",
      "epoch is:  113  Avg. loss (training data):  -5.469821437307188  Avg. loss (validation data):  -6.570675358448104\n",
      "epoch is:  114  Avg. loss (training data):  -6.264660202521029  Avg. loss (validation data):  -5.021028312236369\n",
      "epoch is:  115  Avg. loss (training data):  -6.971642289798606  Avg. loss (validation data):  -5.557154067261571\n",
      "epoch is:  116  Avg. loss (training data):  -5.996026743626983  Avg. loss (validation data):  -4.98473026457324\n",
      "epoch is:  117  Avg. loss (training data):  -5.620997143835824  Avg. loss (validation data):  -4.887016665532479\n",
      "epoch is:  118  Avg. loss (training data):  -6.395971594086743  Avg. loss (validation data):  -5.400625466801963\n",
      "epoch is:  119  Avg. loss (training data):  -5.877980987935523  Avg. loss (validation data):  -7.444758971232545\n",
      "epoch is:  120  Avg. loss (training data):  -5.559531826218898  Avg. loss (validation data):  -4.9403013912297284\n",
      "epoch is:  121  Avg. loss (training data):  -5.7510834171765906  Avg. loss (validation data):  -6.654983299280191\n",
      "epoch is:  122  Avg. loss (training data):  -6.097402794409095  Avg. loss (validation data):  -4.873291784381243\n",
      "epoch is:  123  Avg. loss (training data):  -6.679712839235347  Avg. loss (validation data):  -4.749252152504583\n",
      "epoch is:  124  Avg. loss (training data):  -5.635493707570122  Avg. loss (validation data):  -4.636105170612424\n",
      "epoch is:  125  Avg. loss (training data):  -5.959940021365915  Avg. loss (validation data):  -4.856613431415073\n",
      "epoch is:  126  Avg. loss (training data):  -5.730216757664382  Avg. loss (validation data):  -12.289496787493883\n",
      "epoch is:  127  Avg. loss (training data):  -5.75102580871119  Avg. loss (validation data):  -6.712238303487784\n",
      "epoch is:  128  Avg. loss (training data):  -6.353580820030299  Avg. loss (validation data):  -5.3905055103626776\n",
      "epoch is:  129  Avg. loss (training data):  -7.015219078736619  Avg. loss (validation data):  -8.903204340025477\n",
      "epoch is:  130  Avg. loss (training data):  -5.676226200374106  Avg. loss (validation data):  -5.165174285276228\n",
      "epoch is:  131  Avg. loss (training data):  -5.381031489940713  Avg. loss (validation data):  -5.25293522341031\n",
      "epoch is:  132  Avg. loss (training data):  -6.507218455973194  Avg. loss (validation data):  -5.435061880451777\n",
      "epoch is:  133  Avg. loss (training data):  -6.095200817863229  Avg. loss (validation data):  -4.8464912875364305\n",
      "epoch is:  134  Avg. loss (training data):  -5.433279570740626  Avg. loss (validation data):  -5.256462699025927\n",
      "epoch is:  135  Avg. loss (training data):  -6.343276064321649  Avg. loss (validation data):  -7.286115893026554\n",
      "epoch is:  136  Avg. loss (training data):  -5.860263638310549  Avg. loss (validation data):  -4.996356250082175\n",
      "epoch is:  137  Avg. loss (training data):  -5.7823773817079065  Avg. loss (validation data):  -7.205514662442939\n",
      "epoch is:  138  Avg. loss (training data):  -5.624393215083448  Avg. loss (validation data):  -4.899175802874167\n",
      "epoch is:  139  Avg. loss (training data):  -6.348306622228123  Avg. loss (validation data):  -11.380133900468804\n",
      "epoch is:  140  Avg. loss (training data):  -5.553083742492298  Avg. loss (validation data):  -5.814290978871262\n",
      "epoch is:  141  Avg. loss (training data):  -5.571425215763379  Avg. loss (validation data):  -4.922155889576359\n",
      "epoch is:  142  Avg. loss (training data):  -6.167935008280213  Avg. loss (validation data):  -4.9245668355641214\n",
      "epoch is:  143  Avg. loss (training data):  -5.868672536124375  Avg. loss (validation data):  -4.661625612035784\n",
      "epoch is:  144  Avg. loss (training data):  -5.654168875143817  Avg. loss (validation data):  -4.857170384038205\n",
      "epoch is:  145  Avg. loss (training data):  -6.110927266863817  Avg. loss (validation data):  -10.118942860063813\n",
      "epoch is:  146  Avg. loss (training data):  -5.751480468772168  Avg. loss (validation data):  -5.654379374222892\n",
      "epoch is:  147  Avg. loss (training data):  -6.889584240105341  Avg. loss (validation data):  -4.892696708099743\n",
      "epoch is:  148  Avg. loss (training data):  -5.951626489957672  Avg. loss (validation data):  -6.055674968050946\n",
      "epoch is:  149  Avg. loss (training data):  -6.006092901660852  Avg. loss (validation data):  -5.520501137148842\n",
      "epoch is:  150  Avg. loss (training data):  -6.224151212303867  Avg. loss (validation data):  -4.81558346465866\n",
      "epoch is:  151  Avg. loss (training data):  -5.769514698902813  Avg. loss (validation data):  -5.341474017295965\n",
      "epoch is:  152  Avg. loss (training data):  -5.777982321687025  Avg. loss (validation data):  -4.765060475636375\n",
      "epoch is:  153  Avg. loss (training data):  -6.982730760592236  Avg. loss (validation data):  -4.983600024485256\n",
      "epoch is:  154  Avg. loss (training data):  -6.281100701446993  Avg. loss (validation data):  -7.99095480974566\n",
      "epoch is:  155  Avg. loss (training data):  -6.44323814043833  Avg. loss (validation data):  -4.722825592384102\n",
      "epoch is:  156  Avg. loss (training data):  -5.760604674103963  Avg. loss (validation data):  -5.426980359853034\n",
      "epoch is:  157  Avg. loss (training data):  -6.378228418272994  Avg. loss (validation data):  -5.127642012401756\n",
      "epoch is:  158  Avg. loss (training data):  -6.505724360989074  Avg. loss (validation data):  -7.711676792523745\n",
      "epoch is:  159  Avg. loss (training data):  -5.932042380939001  Avg. loss (validation data):  -9.781111374607304\n",
      "epoch is:  160  Avg. loss (training data):  -6.142350614430495  Avg. loss (validation data):  -4.703991986188641\n",
      "epoch is:  161  Avg. loss (training data):  -5.966658438918348  Avg. loss (validation data):  -4.967166955044932\n",
      "epoch is:  162  Avg. loss (training data):  -5.4600098661556276  Avg. loss (validation data):  -7.871204631908113\n",
      "epoch is:  163  Avg. loss (training data):  -5.698379646698059  Avg. loss (validation data):  -7.070081134575389\n",
      "epoch is:  164  Avg. loss (training data):  -6.178462023998903  Avg. loss (validation data):  -5.196562978962247\n",
      "epoch is:  165  Avg. loss (training data):  -6.8004501051356705  Avg. loss (validation data):  -4.777687312453641\n",
      "epoch is:  166  Avg. loss (training data):  -6.075682068171481  Avg. loss (validation data):  -5.200377091867254\n",
      "epoch is:  167  Avg. loss (training data):  -6.16284008502441  Avg. loss (validation data):  -6.234488090683548\n",
      "epoch is:  168  Avg. loss (training data):  -5.779166421652199  Avg. loss (validation data):  -4.969852195602873\n",
      "epoch is:  169  Avg. loss (training data):  -7.308551342945213  Avg. loss (validation data):  -6.611752880074581\n",
      "epoch is:  170  Avg. loss (training data):  -5.652108166297951  Avg. loss (validation data):  -4.789860662426357\n",
      "epoch is:  171  Avg. loss (training data):  -5.721487789664963  Avg. loss (validation data):  -7.686348722104809\n",
      "epoch is:  172  Avg. loss (training data):  -5.64846801108381  Avg. loss (validation data):  -4.891539857319885\n",
      "epoch is:  173  Avg. loss (training data):  -6.790255652347598  Avg. loss (validation data):  -7.5435308215019585\n",
      "epoch is:  174  Avg. loss (training data):  -5.668326037785607  Avg. loss (validation data):  -9.006159509654578\n",
      "epoch is:  175  Avg. loss (training data):  -5.902983187728567  Avg. loss (validation data):  -4.814267914291988\n",
      "epoch is:  176  Avg. loss (training data):  -6.082018727311785  Avg. loss (validation data):  -5.853161888256805\n",
      "epoch is:  177  Avg. loss (training data):  -6.665476352272598  Avg. loss (validation data):  -4.689606504333573\n",
      "epoch is:  178  Avg. loss (training data):  -6.082106241206297  Avg. loss (validation data):  -5.060203324535062\n",
      "epoch is:  179  Avg. loss (training data):  -5.922385047294648  Avg. loss (validation data):  -4.9978553635291165\n",
      "epoch is:  180  Avg. loss (training data):  -6.13045751041676  Avg. loss (validation data):  -17.917150877046986\n",
      "epoch is:  181  Avg. loss (training data):  -6.204971110440715  Avg. loss (validation data):  -5.142490453105181\n",
      "epoch is:  182  Avg. loss (training data):  -5.699834999432183  Avg. loss (validation data):  -6.790671703871589\n",
      "epoch is:  183  Avg. loss (training data):  -5.976324139028507  Avg. loss (validation data):  -6.914401796849569\n",
      "epoch is:  184  Avg. loss (training data):  -6.1075610013628685  Avg. loss (validation data):  -8.036148202899733\n",
      "epoch is:  185  Avg. loss (training data):  -6.123656766300399  Avg. loss (validation data):  -5.394518252247884\n",
      "epoch is:  186  Avg. loss (training data):  -6.025026667249401  Avg. loss (validation data):  -5.925822157983398\n",
      "epoch is:  187  Avg. loss (training data):  -5.4118866826226455  Avg. loss (validation data):  -6.585183208884741\n",
      "epoch is:  188  Avg. loss (training data):  -5.708324044736295  Avg. loss (validation data):  -5.002439609118207\n",
      "epoch is:  189  Avg. loss (training data):  -6.070419955662686  Avg. loss (validation data):  -6.806137094585664\n",
      "epoch is:  190  Avg. loss (training data):  -5.97296547105322  Avg. loss (validation data):  -4.689445733396221\n",
      "epoch is:  191  Avg. loss (training data):  -6.404294003187914  Avg. loss (validation data):  -8.686362087723728\n",
      "epoch is:  192  Avg. loss (training data):  -6.308279440307803  Avg. loss (validation data):  -5.045099875787849\n",
      "epoch is:  193  Avg. loss (training data):  -5.644263179819266  Avg. loss (validation data):  -10.554014271023817\n",
      "epoch is:  194  Avg. loss (training data):  -5.723435527972615  Avg. loss (validation data):  -5.102349016257483\n",
      "epoch is:  195  Avg. loss (training data):  -5.81109054617867  Avg. loss (validation data):  -6.25279794316034\n",
      "epoch is:  196  Avg. loss (training data):  -5.871426659297422  Avg. loss (validation data):  -8.849032147557915\n",
      "epoch is:  197  Avg. loss (training data):  -5.900752098805429  Avg. loss (validation data):  -6.2765155490579\n",
      "epoch is:  198  Avg. loss (training data):  -5.884801830516223  Avg. loss (validation data):  -4.976741831918043\n",
      "epoch is:  199  Avg. loss (training data):  -5.651766436514298  Avg. loss (validation data):  -5.230457200916388\n",
      "epoch is:  200  Avg. loss (training data):  -5.947996364667535  Avg. loss (validation data):  -4.909045724107892\n",
      "epoch is:  201  Avg. loss (training data):  -6.0046932428824675  Avg. loss (validation data):  -8.482640473264905\n",
      "epoch is:  202  Avg. loss (training data):  -7.540782108181116  Avg. loss (validation data):  -6.440788574373897\n",
      "epoch is:  203  Avg. loss (training data):  -5.887255079979678  Avg. loss (validation data):  -11.824961659146307\n",
      "epoch is:  204  Avg. loss (training data):  -6.659383673024998  Avg. loss (validation data):  -6.258429662524301\n",
      "epoch is:  205  Avg. loss (training data):  -5.966118994411615  Avg. loss (validation data):  -5.14979848270351\n",
      "epoch is:  206  Avg. loss (training data):  -5.813279468983966  Avg. loss (validation data):  -13.434874315647315\n",
      "epoch is:  207  Avg. loss (training data):  -5.967778903351131  Avg. loss (validation data):  -7.039996183923923\n",
      "epoch is:  208  Avg. loss (training data):  -5.786880095040073  Avg. loss (validation data):  -5.0986310851410375\n",
      "epoch is:  209  Avg. loss (training data):  -5.5507034589159225  Avg. loss (validation data):  -7.793558451319888\n",
      "epoch is:  210  Avg. loss (training data):  -5.976304878267205  Avg. loss (validation data):  -4.796194875734038\n",
      "epoch is:  211  Avg. loss (training data):  -5.473872436887621  Avg. loss (validation data):  -4.858724666333077\n",
      "epoch is:  212  Avg. loss (training data):  -5.859079984900244  Avg. loss (validation data):  -6.07145674855186\n",
      "epoch is:  213  Avg. loss (training data):  -6.48446412465415  Avg. loss (validation data):  -4.823387100222432\n",
      "epoch is:  214  Avg. loss (training data):  -6.0280741028561975  Avg. loss (validation data):  -7.805360353435684\n",
      "epoch is:  215  Avg. loss (training data):  -6.462234854576301  Avg. loss (validation data):  -5.383071081610053\n",
      "epoch is:  216  Avg. loss (training data):  -5.765829278932461  Avg. loss (validation data):  -5.040516232337078\n",
      "epoch is:  217  Avg. loss (training data):  -5.911386605498454  Avg. loss (validation data):  -7.499853812333973\n",
      "epoch is:  218  Avg. loss (training data):  -5.696896281620518  Avg. loss (validation data):  -5.0635818923036116\n",
      "epoch is:  219  Avg. loss (training data):  -5.83636933626733  Avg. loss (validation data):  -4.609014591546922\n",
      "epoch is:  220  Avg. loss (training data):  -6.191901521751471  Avg. loss (validation data):  -4.934425180325098\n",
      "epoch is:  221  Avg. loss (training data):  -6.324001732441973  Avg. loss (validation data):  -5.217784253326535\n",
      "epoch is:  222  Avg. loss (training data):  -5.61849415489101  Avg. loss (validation data):  -5.1162388300846695\n",
      "epoch is:  223  Avg. loss (training data):  -5.524062492569481  Avg. loss (validation data):  -5.085699219118354\n",
      "epoch is:  224  Avg. loss (training data):  -6.004419590506315  Avg. loss (validation data):  -6.757290102282509\n",
      "epoch is:  225  Avg. loss (training data):  -6.1544603974203325  Avg. loss (validation data):  -4.735103631285158\n",
      "epoch is:  226  Avg. loss (training data):  -5.997112155430594  Avg. loss (validation data):  -5.13852758697371\n",
      "epoch is:  227  Avg. loss (training data):  -5.966345033311197  Avg. loss (validation data):  -5.296870126171325\n",
      "epoch is:  228  Avg. loss (training data):  -5.355709737224074  Avg. loss (validation data):  -4.9894511458160355\n",
      "epoch is:  229  Avg. loss (training data):  -5.589197809493113  Avg. loss (validation data):  -5.942415661909594\n",
      "epoch is:  230  Avg. loss (training data):  -5.844049914279683  Avg. loss (validation data):  -5.998283185293838\n",
      "epoch is:  231  Avg. loss (training data):  -6.260818470615067  Avg. loss (validation data):  -5.288930269490938\n",
      "epoch is:  232  Avg. loss (training data):  -5.979804637630997  Avg. loss (validation data):  -5.396907395580363\n",
      "epoch is:  233  Avg. loss (training data):  -6.324689642698454  Avg. loss (validation data):  -4.800369145091879\n",
      "epoch is:  234  Avg. loss (training data):  -5.868182395481151  Avg. loss (validation data):  -4.821751564865516\n",
      "epoch is:  235  Avg. loss (training data):  -5.810599611322415  Avg. loss (validation data):  -9.206771016019632\n",
      "epoch is:  236  Avg. loss (training data):  -5.824160332089553  Avg. loss (validation data):  -4.882427096633279\n",
      "epoch is:  237  Avg. loss (training data):  -6.105580063700849  Avg. loss (validation data):  -4.850746522141504\n",
      "epoch is:  238  Avg. loss (training data):  -5.710635597395664  Avg. loss (validation data):  -8.626030089176446\n",
      "epoch is:  239  Avg. loss (training data):  -5.663557231741613  Avg. loss (validation data):  -6.011807877755239\n",
      "epoch is:  240  Avg. loss (training data):  -6.241930248145042  Avg. loss (validation data):  -21.649360961310858\n",
      "epoch is:  241  Avg. loss (training data):  -6.143891435737515  Avg. loss (validation data):  -4.829359055681686\n",
      "epoch is:  242  Avg. loss (training data):  -5.8680775433209496  Avg. loss (validation data):  -4.984406197025312\n",
      "epoch is:  243  Avg. loss (training data):  -5.497331760083661  Avg. loss (validation data):  -7.938025329118675\n",
      "epoch is:  244  Avg. loss (training data):  -6.26948000916565  Avg. loss (validation data):  -5.02480872393091\n",
      "epoch is:  245  Avg. loss (training data):  -5.876527362928486  Avg. loss (validation data):  -4.919817995083598\n",
      "epoch is:  246  Avg. loss (training data):  -5.790728320008636  Avg. loss (validation data):  -10.422289575230135\n",
      "epoch is:  247  Avg. loss (training data):  -5.8215515594151315  Avg. loss (validation data):  -5.371820010143744\n",
      "epoch is:  248  Avg. loss (training data):  -5.79525786736165  Avg. loss (validation data):  -4.76908854893252\n",
      "epoch is:  249  Avg. loss (training data):  -6.549369924106534  Avg. loss (validation data):  -5.256037660352241\n",
      "epoch is:  250  Avg. loss (training data):  -5.786331887439721  Avg. loss (validation data):  -4.868864620479899\n",
      "epoch is:  251  Avg. loss (training data):  -7.041841822717978  Avg. loss (validation data):  -12.132728747580853\n",
      "epoch is:  252  Avg. loss (training data):  -5.62800300395669  Avg. loss (validation data):  -5.6709359906376875\n",
      "epoch is:  253  Avg. loss (training data):  -6.201229411732118  Avg. loss (validation data):  -5.219900260731455\n",
      "epoch is:  254  Avg. loss (training data):  -6.650071868774477  Avg. loss (validation data):  -6.855723272715588\n",
      "epoch is:  255  Avg. loss (training data):  -5.896550789230556  Avg. loss (validation data):  -5.0845007558282305\n",
      "epoch is:  256  Avg. loss (training data):  -6.596930679236846  Avg. loss (validation data):  -5.220377403033246\n",
      "epoch is:  257  Avg. loss (training data):  -5.842533806902631  Avg. loss (validation data):  -4.966175480900755\n",
      "epoch is:  258  Avg. loss (training data):  -6.189897581818626  Avg. loss (validation data):  -6.694267188843276\n",
      "epoch is:  259  Avg. loss (training data):  -5.559956581246064  Avg. loss (validation data):  -4.722361722671971\n",
      "epoch is:  260  Avg. loss (training data):  -5.630029246100415  Avg. loss (validation data):  -8.553511085967658\n",
      "epoch is:  261  Avg. loss (training data):  -5.971556523785116  Avg. loss (validation data):  -4.8956789596217645\n",
      "epoch is:  262  Avg. loss (training data):  -5.779965418641471  Avg. loss (validation data):  -7.49488068655979\n",
      "epoch is:  263  Avg. loss (training data):  -5.6219370361234215  Avg. loss (validation data):  -8.94334552857944\n",
      "epoch is:  264  Avg. loss (training data):  -5.667091095831981  Avg. loss (validation data):  -4.633964021634123\n",
      "epoch is:  265  Avg. loss (training data):  -5.7119750478978695  Avg. loss (validation data):  -5.376472213896088\n",
      "epoch is:  266  Avg. loss (training data):  -6.265989537781105  Avg. loss (validation data):  -5.502707252367011\n",
      "epoch is:  267  Avg. loss (training data):  -6.247934684438957  Avg. loss (validation data):  -17.729382177058817\n",
      "epoch is:  268  Avg. loss (training data):  -5.727298209855714  Avg. loss (validation data):  -4.893950414615672\n",
      "epoch is:  269  Avg. loss (training data):  -5.493458533186783  Avg. loss (validation data):  -5.277172917542827\n",
      "epoch is:  270  Avg. loss (training data):  -5.8879351676232  Avg. loss (validation data):  -5.096703323601644\n",
      "epoch is:  271  Avg. loss (training data):  -6.091522160314738  Avg. loss (validation data):  -9.908032723654804\n",
      "epoch is:  272  Avg. loss (training data):  -5.990525216389485  Avg. loss (validation data):  -4.971268201559846\n",
      "epoch is:  273  Avg. loss (training data):  -5.567533018207972  Avg. loss (validation data):  -4.733084686766716\n",
      "epoch is:  274  Avg. loss (training data):  -5.86355535996095  Avg. loss (validation data):  -7.834131638945203\n",
      "epoch is:  275  Avg. loss (training data):  -5.7646295466746516  Avg. loss (validation data):  -4.699194126970113\n",
      "epoch is:  276  Avg. loss (training data):  -5.798546226910529  Avg. loss (validation data):  -4.978811907563977\n",
      "epoch is:  277  Avg. loss (training data):  -5.619275497408589  Avg. loss (validation data):  -4.982051104134371\n",
      "epoch is:  278  Avg. loss (training data):  -6.185665442114227  Avg. loss (validation data):  -4.702664085432099\n",
      "epoch is:  279  Avg. loss (training data):  -5.855099461142995  Avg. loss (validation data):  -10.152750079776743\n",
      "epoch is:  280  Avg. loss (training data):  -5.79585775616869  Avg. loss (validation data):  -4.9984386387835995\n",
      "epoch is:  281  Avg. loss (training data):  -6.053600452062524  Avg. loss (validation data):  -5.197508674181818\n",
      "epoch is:  282  Avg. loss (training data):  -5.424425297572419  Avg. loss (validation data):  -5.325707920792789\n",
      "epoch is:  283  Avg. loss (training data):  -5.844110909791673  Avg. loss (validation data):  -4.587131162181319\n",
      "epoch is:  284  Avg. loss (training data):  -6.210774053493647  Avg. loss (validation data):  -7.059123700831663\n",
      "epoch is:  285  Avg. loss (training data):  -6.320912502699672  Avg. loss (validation data):  -13.024945806964748\n",
      "epoch is:  286  Avg. loss (training data):  -5.634195781970647  Avg. loss (validation data):  -4.6918057644402476\n",
      "epoch is:  287  Avg. loss (training data):  -5.564671194475991  Avg. loss (validation data):  -4.653447500337326\n",
      "epoch is:  288  Avg. loss (training data):  -5.361973958290929  Avg. loss (validation data):  -4.821757760825979\n",
      "epoch is:  289  Avg. loss (training data):  -6.2168521438441955  Avg. loss (validation data):  -4.5650026971635\n",
      "epoch is:  290  Avg. loss (training data):  -6.425848374393014  Avg. loss (validation data):  -5.277377585865196\n",
      "epoch is:  291  Avg. loss (training data):  -5.908058315053279  Avg. loss (validation data):  -5.589051045515963\n",
      "epoch is:  292  Avg. loss (training data):  -6.0728321247295005  Avg. loss (validation data):  -5.020280066196375\n",
      "epoch is:  293  Avg. loss (training data):  -5.739461089687029  Avg. loss (validation data):  -5.274813044740646\n",
      "epoch is:  294  Avg. loss (training data):  -5.879773505450264  Avg. loss (validation data):  -5.499479976212896\n",
      "epoch is:  295  Avg. loss (training data):  -5.697883934037038  Avg. loss (validation data):  -5.352985663382568\n",
      "epoch is:  296  Avg. loss (training data):  -5.714537682055451  Avg. loss (validation data):  -5.236965579968691\n",
      "epoch is:  297  Avg. loss (training data):  -5.5700909468938065  Avg. loss (validation data):  -5.536711065636399\n",
      "epoch is:  298  Avg. loss (training data):  -5.514924663601456  Avg. loss (validation data):  -7.172206297350653\n",
      "epoch is:  299  Avg. loss (training data):  -6.345821587106956  Avg. loss (validation data):  -4.6562007447275615\n",
      "epoch is:  300  Avg. loss (training data):  -6.113188809790148  Avg. loss (validation data):  -5.357610009688216\n",
      "epoch is:  301  Avg. loss (training data):  -6.123734228800787  Avg. loss (validation data):  -5.153129765513788\n",
      "epoch is:  302  Avg. loss (training data):  -5.743052052949897  Avg. loss (validation data):  -7.556741382906163\n",
      "epoch is:  303  Avg. loss (training data):  -5.938975408787505  Avg. loss (validation data):  -4.874312705951495\n",
      "epoch is:  304  Avg. loss (training data):  -5.555646738137515  Avg. loss (validation data):  -7.951801296326584\n",
      "epoch is:  305  Avg. loss (training data):  -5.789955778483736  Avg. loss (validation data):  -7.48244093177982\n",
      "epoch is:  306  Avg. loss (training data):  -6.001291773885972  Avg. loss (validation data):  -6.444776347000043\n",
      "epoch is:  307  Avg. loss (training data):  -6.196302717259001  Avg. loss (validation data):  -4.576762118630172\n",
      "epoch is:  308  Avg. loss (training data):  -5.592396803953807  Avg. loss (validation data):  -7.9320175883232436\n",
      "epoch is:  309  Avg. loss (training data):  -5.818354318537213  Avg. loss (validation data):  -6.676711185114779\n",
      "epoch is:  310  Avg. loss (training data):  -6.712062299760436  Avg. loss (validation data):  -8.67962854677681\n",
      "epoch is:  311  Avg. loss (training data):  -6.035730336179686  Avg. loss (validation data):  -7.94738899312673\n",
      "epoch is:  312  Avg. loss (training data):  -5.810234434771357  Avg. loss (validation data):  -6.382027125315416\n",
      "epoch is:  313  Avg. loss (training data):  -5.852319778493583  Avg. loss (validation data):  -4.968923649385935\n",
      "epoch is:  314  Avg. loss (training data):  -5.770950417802923  Avg. loss (validation data):  -5.318416655685472\n",
      "epoch is:  315  Avg. loss (training data):  -5.878071487735719  Avg. loss (validation data):  -5.17964239985533\n",
      "epoch is:  316  Avg. loss (training data):  -5.743411120452732  Avg. loss (validation data):  -4.707770085328973\n",
      "epoch is:  317  Avg. loss (training data):  -5.622501883250327  Avg. loss (validation data):  -5.068008207861522\n",
      "epoch is:  318  Avg. loss (training data):  -6.705018059735288  Avg. loss (validation data):  -5.291542058288806\n",
      "epoch is:  319  Avg. loss (training data):  -6.370656062218372  Avg. loss (validation data):  -5.613012165260964\n",
      "epoch is:  320  Avg. loss (training data):  -5.950534871123094  Avg. loss (validation data):  -4.575219149991676\n",
      "epoch is:  321  Avg. loss (training data):  -5.855849445516411  Avg. loss (validation data):  -6.09816451342535\n",
      "epoch is:  322  Avg. loss (training data):  -5.7702122975075865  Avg. loss (validation data):  -5.263710779396975\n",
      "epoch is:  323  Avg. loss (training data):  -6.282637934860044  Avg. loss (validation data):  -6.2672656245498315\n",
      "epoch is:  324  Avg. loss (training data):  -6.9665612079508765  Avg. loss (validation data):  -5.604105677901241\n",
      "epoch is:  325  Avg. loss (training data):  -5.4075521266291  Avg. loss (validation data):  -4.972911334003123\n",
      "epoch is:  326  Avg. loss (training data):  -5.551394185975355  Avg. loss (validation data):  -7.230372917505158\n",
      "epoch is:  327  Avg. loss (training data):  -6.166541089324948  Avg. loss (validation data):  -8.644935935813695\n",
      "epoch is:  328  Avg. loss (training data):  -5.543812192116003  Avg. loss (validation data):  -6.859157676150834\n",
      "epoch is:  329  Avg. loss (training data):  -6.6189598417956255  Avg. loss (validation data):  -5.230664832052918\n",
      "epoch is:  330  Avg. loss (training data):  -5.5500814316898905  Avg. loss (validation data):  -9.38359619770919\n",
      "epoch is:  331  Avg. loss (training data):  -5.6688181074501225  Avg. loss (validation data):  -4.785974574221314\n",
      "epoch is:  332  Avg. loss (training data):  -5.940603683428095  Avg. loss (validation data):  -5.652774710488593\n",
      "epoch is:  333  Avg. loss (training data):  -5.665437134754757  Avg. loss (validation data):  -7.8566176479694105\n",
      "epoch is:  334  Avg. loss (training data):  -6.047189106427556  Avg. loss (validation data):  -8.64795296946174\n",
      "epoch is:  335  Avg. loss (training data):  -5.775297955390021  Avg. loss (validation data):  -5.498437822385207\n",
      "epoch is:  336  Avg. loss (training data):  -5.630455895976898  Avg. loss (validation data):  -4.745625061857022\n",
      "epoch is:  337  Avg. loss (training data):  -5.906023858646506  Avg. loss (validation data):  -5.116429589991107\n",
      "epoch is:  338  Avg. loss (training data):  -5.6884466436888195  Avg. loss (validation data):  -4.705378600930415\n",
      "epoch is:  339  Avg. loss (training data):  -6.058930868717043  Avg. loss (validation data):  -5.173362722094645\n",
      "epoch is:  340  Avg. loss (training data):  -5.82562474218999  Avg. loss (validation data):  -7.216171711214393\n",
      "epoch is:  341  Avg. loss (training data):  -6.45589341695548  Avg. loss (validation data):  -5.235829566958275\n",
      "epoch is:  342  Avg. loss (training data):  -5.621965308592795  Avg. loss (validation data):  -6.736258838277843\n",
      "epoch is:  343  Avg. loss (training data):  -5.881708928026231  Avg. loss (validation data):  -5.690160109693158\n",
      "epoch is:  344  Avg. loss (training data):  -6.159122040239628  Avg. loss (validation data):  -4.9752055078998785\n",
      "epoch is:  345  Avg. loss (training data):  -5.868079906710509  Avg. loss (validation data):  -9.3889568986307\n",
      "epoch is:  346  Avg. loss (training data):  -5.456301470362183  Avg. loss (validation data):  -5.354622532779111\n",
      "epoch is:  347  Avg. loss (training data):  -5.973000547154709  Avg. loss (validation data):  -7.817875724417847\n",
      "epoch is:  348  Avg. loss (training data):  -5.870082912369811  Avg. loss (validation data):  -5.376943179669655\n",
      "epoch is:  349  Avg. loss (training data):  -5.914902091640407  Avg. loss (validation data):  -6.400143219377843\n",
      "epoch is:  350  Avg. loss (training data):  -6.1279010338440365  Avg. loss (validation data):  -5.695783242527106\n",
      "epoch is:  351  Avg. loss (training data):  -5.891572137986263  Avg. loss (validation data):  -5.4339380097562\n",
      "epoch is:  352  Avg. loss (training data):  -6.213472974563709  Avg. loss (validation data):  -7.045601781734715\n",
      "epoch is:  353  Avg. loss (training data):  -5.727707416721173  Avg. loss (validation data):  -5.237009237665445\n",
      "epoch is:  354  Avg. loss (training data):  -6.3394063265605265  Avg. loss (validation data):  -5.096656924685601\n",
      "epoch is:  355  Avg. loss (training data):  -6.607864821483897  Avg. loss (validation data):  -5.489300399254794\n",
      "epoch is:  356  Avg. loss (training data):  -5.866476583830181  Avg. loss (validation data):  -5.097205943094044\n",
      "epoch is:  357  Avg. loss (training data):  -5.890000532402166  Avg. loss (validation data):  -5.012767858505968\n",
      "epoch is:  358  Avg. loss (training data):  -5.625229209230184  Avg. loss (validation data):  -8.279491996161003\n",
      "epoch is:  359  Avg. loss (training data):  -5.586535189272338  Avg. loss (validation data):  -5.755506281911768\n",
      "epoch is:  360  Avg. loss (training data):  -6.11747885997097  Avg. loss (validation data):  -6.529306131200793\n",
      "epoch is:  361  Avg. loss (training data):  -6.36642471180238  Avg. loss (validation data):  -6.703376810437141\n",
      "epoch is:  362  Avg. loss (training data):  -6.029980566059204  Avg. loss (validation data):  -6.60403653590122\n",
      "epoch is:  363  Avg. loss (training data):  -5.718808116363384  Avg. loss (validation data):  -4.908113612828312\n",
      "epoch is:  364  Avg. loss (training data):  -5.554679466725061  Avg. loss (validation data):  -5.650248991182025\n",
      "epoch is:  365  Avg. loss (training data):  -6.440918735106185  Avg. loss (validation data):  -5.992667037121895\n",
      "epoch is:  366  Avg. loss (training data):  -6.656313793050731  Avg. loss (validation data):  -5.635527998191564\n",
      "epoch is:  367  Avg. loss (training data):  -6.120033108246094  Avg. loss (validation data):  -5.313887118321651\n",
      "epoch is:  368  Avg. loss (training data):  -6.026070281410628  Avg. loss (validation data):  -6.645985838186531\n",
      "epoch is:  369  Avg. loss (training data):  -5.455013662079949  Avg. loss (validation data):  -6.462196557941501\n",
      "epoch is:  370  Avg. loss (training data):  -5.987649154414007  Avg. loss (validation data):  -4.707027898548962\n",
      "epoch is:  371  Avg. loss (training data):  -5.66780407436733  Avg. loss (validation data):  -9.44406599373482\n",
      "epoch is:  372  Avg. loss (training data):  -5.769507301910781  Avg. loss (validation data):  -4.829731279561888\n",
      "epoch is:  373  Avg. loss (training data):  -5.459636798824087  Avg. loss (validation data):  -4.683797685217841\n",
      "epoch is:  374  Avg. loss (training data):  -5.77518533150966  Avg. loss (validation data):  -5.465331738622646\n",
      "epoch is:  375  Avg. loss (training data):  -5.891871410480305  Avg. loss (validation data):  -4.67760594406776\n",
      "epoch is:  376  Avg. loss (training data):  -6.011486919302973  Avg. loss (validation data):  -4.75004455144913\n",
      "epoch is:  377  Avg. loss (training data):  -5.667510390124168  Avg. loss (validation data):  -4.878454650271183\n",
      "epoch is:  378  Avg. loss (training data):  -5.71491177903857  Avg. loss (validation data):  -4.781270695918249\n",
      "epoch is:  379  Avg. loss (training data):  -5.475306156089995  Avg. loss (validation data):  -5.454307895834552\n",
      "epoch is:  380  Avg. loss (training data):  -6.182653281106445  Avg. loss (validation data):  -4.794028857475098\n",
      "epoch is:  381  Avg. loss (training data):  -6.700791758151754  Avg. loss (validation data):  -5.635569651155007\n",
      "epoch is:  382  Avg. loss (training data):  -5.773943014509272  Avg. loss (validation data):  -6.946859248044579\n",
      "epoch is:  383  Avg. loss (training data):  -6.133917624640475  Avg. loss (validation data):  -4.965213349052305\n",
      "epoch is:  384  Avg. loss (training data):  -6.2436764134556775  Avg. loss (validation data):  -4.90463525118286\n",
      "epoch is:  385  Avg. loss (training data):  -5.8442535709105075  Avg. loss (validation data):  -5.629104663849973\n",
      "epoch is:  386  Avg. loss (training data):  -5.96006654222927  Avg. loss (validation data):  -5.4259382826197164\n",
      "epoch is:  387  Avg. loss (training data):  -5.798562610301673  Avg. loss (validation data):  -9.867023854076189\n",
      "epoch is:  388  Avg. loss (training data):  -5.605709924078494  Avg. loss (validation data):  -5.009842386173743\n",
      "epoch is:  389  Avg. loss (training data):  -5.90887452298901  Avg. loss (validation data):  -5.204460381109099\n",
      "epoch is:  390  Avg. loss (training data):  -6.453234497552461  Avg. loss (validation data):  -4.738710427921033\n",
      "epoch is:  391  Avg. loss (training data):  -5.805333260350908  Avg. loss (validation data):  -25.49696807726951\n",
      "epoch is:  392  Avg. loss (training data):  -5.990130444823052  Avg. loss (validation data):  -4.94345566893738\n",
      "epoch is:  393  Avg. loss (training data):  -5.7730597079747294  Avg. loss (validation data):  -5.077470687077431\n",
      "epoch is:  394  Avg. loss (training data):  -6.575416961721742  Avg. loss (validation data):  -5.215645644899316\n",
      "epoch is:  395  Avg. loss (training data):  -5.73419028401749  Avg. loss (validation data):  -4.523849988619993\n",
      "epoch is:  396  Avg. loss (training data):  -6.129998997697144  Avg. loss (validation data):  -8.240638275431376\n",
      "epoch is:  397  Avg. loss (training data):  -5.6274670406829985  Avg. loss (validation data):  -5.727297892579322\n",
      "epoch is:  398  Avg. loss (training data):  -6.162792076009791  Avg. loss (validation data):  -4.616077507710456\n",
      "epoch is:  399  Avg. loss (training data):  -6.364491398759294  Avg. loss (validation data):  -7.182893890520843\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "model = model3\n",
    "N_train = len(dataset_train)\n",
    "N_val = len(dataset_test)\n",
    "\n",
    "avg_loss_per_epoch_train = []\n",
    "avg_loss_per_epoch_val = []\n",
    "\n",
    "for ep in range(num_epochs):\n",
    "\n",
    "    model.train() # Put the model in \"training mode\"\n",
    "    total_loss = []\n",
    "\n",
    "    for x_batch, y_batch in dataloader_train:\n",
    "\n",
    "    # These lines move the current batch of data to the GPU, if we're using the GPU.\n",
    "\n",
    "\n",
    "        outputs = model(x_batch)\n",
    "        outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "# Each item in the current batch is fed into the neural network\n",
    "        avg_loss_for_this_batch = criterion(outputs, y_batch)\n",
    "\n",
    "        model.zero_grad() # Wipe the slate clean, preparing for a new gradient calculation\n",
    "        avg_loss_for_this_batch.backward() # Compute a gradient using the current batch\n",
    "                                        # A more logical name for this method might be \"compute_gradient\"\n",
    "\n",
    "    # Now we take one step of stochastic gradient descent or Adam.\n",
    "    # (or whichever optimization algorithm we're using)\n",
    "    # This short line of code updates all of the weights in our neural network.\n",
    "        optimizer.step() \n",
    "\n",
    "    # We can see how powerful PyTorch is now.  In the previous two lines of code,\n",
    "    # PyTorch did a very complicated gradient calculation for us,\n",
    "    # shielding us from the details.\n",
    "    # Then PyTorch updated the neural network weights, again shielding us from the details.\n",
    "        outputs = model(x_batch)\n",
    "        loss = r2_score( y_batch.detach().numpy(),outputs.detach().numpy())\n",
    "        total_loss.append(loss)\n",
    "    avg_training = np.mean(total_loss) \n",
    "\n",
    "\n",
    "    # We just finished one epoch of training.\n",
    "    # Let's check how well our model is performing on the validation dataset.\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    for x_batch, y_batch in dataloader_test:\n",
    "\n",
    "\n",
    "        with torch.no_grad(): # This line tells PyTorch it doesn't need to worry \n",
    "                            # about computing any gradients, for the moment\n",
    "            outputs = model(x_batch)\n",
    "            outputs = outputs.squeeze()  # This removes any singleton dimensions\n",
    "\n",
    "            loss = r2_score( y_batch.detach().numpy(), outputs.detach().numpy())\n",
    "            total_loss.append(loss)\n",
    "    avg = np.mean(total_loss)\n",
    "    \n",
    "    print('epoch is: ', ep, ' Avg. loss (training data): ', avg_training, ' Avg. loss (validation data): ', avg.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file_path = 'project-group-6/test_kaggle.pickle'\n",
    "with open(pickle_file_path, 'rb') as file:\n",
    "    # Load the data from the file\n",
    "    test_data = pickle.load(file)\n",
    "test_data = pd.DataFrame(test_data)\n",
    "X_test = test_df.values  # Convert the relevant feature columns to a NumPy array\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float) \n",
    "pred = model(X_test_tensor)\n",
    "pred3 = pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame({'Column1': pred1.flatten(), 'Column2': pred2.flatten(), 'Column3': pred3.flatten()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions['avg_pred'] = df_predictions.mean(axis=1)\n",
    "predic = df_predictions['avg_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['price'] = predic\n",
    "predictions = test_data[['id','price']]\n",
    "predictions.to_csv('prediction2.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
